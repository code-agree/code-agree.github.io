[{"content":"","date":null,"permalink":"/tags/hft-system-design/","section":"Tags","summary":"","title":"HFT System Design"},{"content":"","date":null,"permalink":"/tags/memeoy/","section":"Tags","summary":"","title":"Memeoy"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":null,"permalink":"/","section":"Yu's Space","summary":"","title":"Yu's Space"},{"content":"内存映射（mmap）与零拷贝技术：深入理解和实践 #1. 概述 #内存映射（mmap）是一种将文件或设备映射到内存的方法，而零拷贝是一种减少或避免数据在内核空间和用户空间之间不必要复制的技术。这两个概念密切相关，但又有所不同。\n2. mmap 是零拷贝吗？ #答案是：mmap 本身不是零拷贝技术，但它可以实现零拷贝的效果。\n2.1 mmap 的工作原理 # 当调用 mmap 时，操作系统会在虚拟内存中创建一个新的内存区域。 这个内存区域会映射到文件系统缓存（page cache）中的物理页面。 当程序访问这个内存区域时，如果相应的页面不在内存中，会触发缺页中断，操作系统会从磁盘加载数据到内存。 2.2 为什么 mmap 可以实现零拷贝 # 一旦映射建立，用户进程可以直接读写这个内存区域，而无需在用户空间和内核空间之间进行数据复制。 对于读操作，数据从磁盘读入 page cache 后，可以直接被用户进程访问，无需额外复制。 对于写操作，修改直接发生在 page cache 上，操作系统会在适当的时候将修改同步到磁盘。 3. mmap 与传统 I/O 的比较 #3.1 传统 read 系统调用 #char buffer[4096]; ssize_t bytes_read = read(fd, buffer, sizeof(buffer)); 这个过程涉及两次数据拷贝：\n从磁盘到内核缓冲区 从内核缓冲区到用户空间缓冲区 3.2 使用 mmap #void* addr = mmap(NULL, file_size, PROT_READ, MAP_PRIVATE, fd, 0); // 直接访问 addr 指向的内存 mmap 减少了一次数据拷贝，数据直接从磁盘到用户可访问的内存。\n4. mmap 的优势和注意事项 #4.1 优势 # 减少数据拷贝，提高I/O效率 支持随机访问大文件 可以实现进程间通信 4.2 注意事项 # 大文件映射可能导致地址空间碎片 写操作可能触发写时复制（Copy-on-Write），影响性能 需要谨慎处理文件大小变化的情况 5. 真正的零拷贝技术 #链接文本\n虽然 mmap 可以减少拷贝，但真正的零拷贝技术通常指的是：\nsendfile() 系统调用：直接在内核空间完成文件到网络套接字的数据传输。 支持 scatter-gather 的 DMA 传输：允许硬件直接在磁盘和网络接口之间传输数据，完全绕过 CPU。 6. 示例：使用 mmap 实现高效文件复制 ##include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/mman.h\u0026gt; #include \u0026lt;sys/stat.h\u0026gt; #include \u0026lt;iostream\u0026gt; void copy_file(const char* src, const char* dst) { int src_fd = open(src, O_RDONLY); if (src_fd == -1) { std::cerr \u0026lt;\u0026lt; \u0026#34;Error opening source file\u0026#34; \u0026lt;\u0026lt; std::endl; return; } struct stat sb; if (fstat(src_fd, \u0026amp;sb) == -1) { std::cerr \u0026lt;\u0026lt; \u0026#34;Error getting file size\u0026#34; \u0026lt;\u0026lt; std::endl; close(src_fd); return; } void* src_addr = mmap(NULL, sb.st_size, PROT_READ, MAP_PRIVATE, src_fd, 0); if (src_addr == MAP_FAILED) { std::cerr \u0026lt;\u0026lt; \u0026#34;Error mapping source file\u0026#34; \u0026lt;\u0026lt; std::endl; close(src_fd); return; } int dst_fd = open(dst, O_RDWR | O_CREAT | O_TRUNC, 0644); if (dst_fd == -1) { std::cerr \u0026lt;\u0026lt; \u0026#34;Error creating destination file\u0026#34; \u0026lt;\u0026lt; std::endl; munmap(src_addr, sb.st_size); close(src_fd); return; } if (ftruncate(dst_fd, sb.st_size) == -1) { std::cerr \u0026lt;\u0026lt; \u0026#34;Error setting file size\u0026#34; \u0026lt;\u0026lt; std::endl; close(dst_fd); munmap(src_addr, sb.st_size); close(src_fd); return; } void* dst_addr = mmap(NULL, sb.st_size, PROT_WRITE, MAP_SHARED, dst_fd, 0); if (dst_addr == MAP_FAILED) { std::cerr \u0026lt;\u0026lt; \u0026#34;Error mapping destination file\u0026#34; \u0026lt;\u0026lt; std::endl; close(dst_fd); munmap(src_addr, sb.st_size); close(src_fd); return; } memcpy(dst_addr, src_addr, sb.st_size); munmap(dst_addr, sb.st_size); munmap(src_addr, sb.st_size); close(dst_fd); close(src_fd); } int main() { copy_file(\u0026#34;source.txt\u0026#34;, \u0026#34;destination.txt\u0026#34;); return 0; } 这个例子展示了如何使用 mmap 高效地复制文件，避免了传统 read/write 方法中的多次数据拷贝。\n7. 结论 #虽然 mmap 不是严格意义上的零拷贝技术，但它确实能显著减少数据拷贝次数，提高 I/O 效率。在处理大文件或需要频繁随机访问的场景中，mmap 可以成为非常有效的工具。然而，在使用 mmap 时，开发者需要权衡其优势和潜在的复杂性，以确保在特定应用场景中获得最佳性能。\n","date":"22 October 2024","permalink":"/blog/zero_copy/","section":"Blog","summary":"\u003ch1 id=\"内存映射mmap与零拷贝技术深入理解和实践\" class=\"relative group\"\u003e内存映射（mmap）与零拷贝技术：深入理解和实践 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e5%86%85%e5%ad%98%e6%98%a0%e5%b0%84mmap%e4%b8%8e%e9%9b%b6%e6%8b%b7%e8%b4%9d%e6%8a%80%e6%9c%af%e6%b7%b1%e5%85%a5%e7%90%86%e8%a7%a3%e5%92%8c%e5%ae%9e%e8%b7%b5\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h1\u003e\u003ch2 id=\"1-概述\" class=\"relative group\"\u003e1. 概述 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#1-%e6%a6%82%e8%bf%b0\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003e内存映射（mmap）是一种将文件或设备映射到内存的方法，而零拷贝是一种减少或避免数据在内核空间和用户空间之间不必要复制的技术。这两个概念密切相关，但又有所不同。\u003c/p\u003e","title":"内存映射（mmap）与零拷贝技术：深入理解和实践"},{"content":"目录 # 简介 仓库结构和分支策略 协作者权限管理 保护主分支 Pull Request 和代码审查流程 持续集成与部署 (CI/CD) 文档和沟通 最佳实践和注意事项 简介 #在没有高级 GitHub 功能的私有仓库中进行协同开发可能具有挑战性，但通过正确的实践和工具，我们可以建立一个高效、安全的开发环境。本指南总结了我们讨论的主要策略和技术。\n仓库结构和分支策略 # 主分支：main（稳定、可部署的代码） 开发分支：main_for_dev（日常开发工作） 特性分支：从 main_for_dev 分出，用于开发新功能 工作流程：\n从 main_for_dev 创建特性分支 在特性分支上开发 完成后，创建 Pull Request 到 main_for_dev 代码审查和测试 合并到 main_for_dev 定期将 main_for_dev 合并到 main 协作者权限管理 #GitHub 私有仓库提供以下权限级别：\nRead Triage Write Maintain Admin 设置步骤：\n进入仓库 \u0026ldquo;Settings\u0026rdquo; \u0026gt; \u0026ldquo;Collaborators and teams\u0026rdquo; 点击 \u0026ldquo;Add people\u0026rdquo; 或 \u0026ldquo;Add teams\u0026rdquo; 输入用户名并选择适当的权限级别 最佳实践：\n遵循最小权限原则 定期审查和更新权限 保护主分支 #由于缺乏高级分支保护功能，我们采用以下策略：\n团队约定：\n禁止直接推送到 main 分支 所有更改通过 PR 进行 Git Hooks： 创建 pre-push hook（.git/hooks/pre-push）：\n#!/bin/sh branch=$(git rev-parse --abbrev-ref HEAD) if [ \u0026#34;$branch\u0026#34; = \u0026#34;main\u0026#34; ]; then echo \u0026#34;Direct push to main branch is not allowed. Please create a Pull Request.\u0026#34; exit 1 fi 设置权限：chmod +x .git/hooks/pre-push\nGitHub Actions： 创建 .github/workflows/protect-main.yml：\nname: Protect Main Branch on: push: branches: - main jobs: check_push: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Check if push was direct run: | if [[ $(git log --format=%B -n 1 ${{ github.sha }}) != *\u0026#34;Merge pull request\u0026#34;* ]]; then echo \u0026#34;::error::Direct push to main branch detected. Please use Pull Requests.\u0026#34; exit 1 fi Pull Request 和代码审查流程 # 创建 PR 模板： 在 .github/pull_request_template.md 中定义模板。\n审查流程：\n至少一名审查者批准 通过所有自动化测试 遵循团队定义的代码规范 合并策略： 使用 \u0026ldquo;Squash and merge\u0026rdquo; 或 \u0026ldquo;Rebase and merge\u0026rdquo; 保持清晰的提交历史。\n持续集成与部署 (CI/CD) #使用 GitHub Actions 进行 CI/CD：\n在 PR 中运行测试和代码质量检查 只从 main 分支进行部署 自动化版本标记和发布流程 文档和沟通 # README.md：项目概述和快速开始指南 CONTRIBUTING.md：详细的贡献指南 代码注释：保持代码自文档化 定期团队会议：讨论项目进展和问题 最佳实践和注意事项 # 定期培训团队成员，确保everyone遵循协作流程 使用 GitHub Issues 进行任务跟踪和 bug 报告 考虑使用项目看板（Project Boards）进行任务管理 定期审查和更新工作流程，适应团队需求 鼓励知识共享和对等编程 重视代码质量，包括单元测试和文档 考虑实施持续反馈机制，不断改进协作流程 通过实施这些策略和最佳实践，即使在私有仓库的限制下，也能建立一个高效、安全的协作环境。记住，成功的协作不仅依赖于工具和流程，更依赖于团队的沟通和相互信任。\n","date":"16 October 2024","permalink":"/blog/project_manage/","section":"Blog","summary":"\u003ch2 id=\"目录\" class=\"relative group\"\u003e目录 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e7%9b%ae%e5%bd%95\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003col\u003e\n\u003cli\u003e\u003ca href=\"#%e7%ae%80%e4%bb%8b\"\u003e简介\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%e4%bb%93%e5%ba%93%e7%bb%93%e6%9e%84%e5%92%8c%e5%88%86%e6%94%af%e7%ad%96%e7%95%a5\"\u003e仓库结构和分支策略\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%e5%8d%8f%e4%bd%9c%e8%80%85%e6%9d%83%e9%99%90%e7%ae%a1%e7%90%86\"\u003e协作者权限管理\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%e4%bf%9d%e6%8a%a4%e4%b8%bb%e5%88%86%e6%94%af\"\u003e保护主分支\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#pull-request-%e5%92%8c%e4%bb%a3%e7%a0%81%e5%ae%a1%e6%9f%a5%e6%b5%81%e7%a8%8b\"\u003ePull Request 和代码审查流程\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%e6%8c%81%e7%bb%ad%e9%9b%86%e6%88%90%e4%b8%8e%e9%83%a8%e7%bd%b2-cicd\"\u003e持续集成与部署 (CI/CD)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%e6%96%87%e6%a1%a3%e5%92%8c%e6%b2%9f%e9%80%9a\"\u003e文档和沟通\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5%e5%92%8c%e6%b3%a8%e6%84%8f%e4%ba%8b%e9%a1%b9\"\u003e最佳实践和注意事项\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"简介\" class=\"relative group\"\u003e简介 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e7%ae%80%e4%bb%8b\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003e在没有高级 GitHub 功能的私有仓库中进行协同开发可能具有挑战性，但通过正确的实践和工具，我们可以建立一个高效、安全的开发环境。本指南总结了我们讨论的主要策略和技术。\u003c/p\u003e","title":"GitHub私有仓库协同开发指南"},{"content":"","date":null,"permalink":"/tags/project-management/","section":"Tags","summary":"","title":"Project Management"},{"content":"1. 引言 #Fork是Unix/Linux系统中最基本也是最强大的系统调用之一。它允许一个进程创建一个新的进程,这个新进程是原进程的一个几乎完全相同的副本。本次技术分享将深入探讨fork机制,从基本概念到高级应用。\n2. Fork的基本原理 #2.1 什么是Fork #Fork是一个系统调用,用于创建一个新的进程。新进程（称为子进程）是调用进程（称为父进程）的一个几乎完全相同的副本。\n2.2 Fork的工作原理 #当一个进程调用fork时:\n系统会创建一个新的进程。 新进程是父进程的一个副本,包括代码段、数据段、堆栈等。 子进程获得父进程数据空间、堆和栈的副本。 父进程和子进程继续执行fork调用之后的代码。 2.3 Fork的返回值 #Fork调用会返回两次:\n在父进程中,返回子进程的PID。 在子进程中,返回0。 这允许程序区分父进程和子进程。\npid_t pid = fork(); if (pid \u0026gt; 0) { printf(\u0026#34;父进程\\n\u0026#34;); } else if (pid == 0) { printf(\u0026#34;子进程\\n\u0026#34;); } else { perror(\u0026#34;fork失败\u0026#34;); exit(1); } 3. Fork的高级特性 #3.1 写时复制 (Copy-on-Write) #为了提高效率,现代操作系统使用\u0026quot;写时复制\u0026quot;技术:\n初始时,子进程与父进程共享同一物理内存。 只有当其中一个进程尝试修改内存时,才会创建该部分内存的副本。 这大大减少了fork的开销和内存使用。\n3.2 文件描述符的继承 #子进程继承父进程的文件描述符。这意味着:\n子进程可以访问父进程打开的文件。 父子进程共享文件偏移量。 int fd = open(\u0026#34;example.txt\u0026#34;, O_RDWR); if (fork() == 0) { // 子进程 write(fd, \u0026#34;Hello from child\u0026#34;, 16); } else { // 父进程 write(fd, \u0026#34;Hello from parent\u0026#34;, 17); } 3.3 内存独立性 #虽然子进程初始时与父进程共享内存,但它们的内存空间是独立的:\n一个进程对变量的修改不会影响另一个进程。 这适用于全局变量、堆、栈等所有内存区域。 4. Fork的高级应用 #4.1 多进程并行处理 #Fork常用于创建多个并行工作的进程,例如在服务器程序中:\nfor (int i = 0; i \u0026lt; NUM_WORKERS; i++) { if (fork() == 0) { worker_process(); exit(0); } } 4.2 实现管道 #Fork结合管道可以用于进程间通信:\nint pipefd[2]; pipe(pipefd); if (fork() == 0) { close(pipefd[1]); // 关闭写端 char buf[100]; read(pipefd[0], buf, 100); printf(\u0026#34;子进程读取: %s\\n\u0026#34;, buf); } else { close(pipefd[0]); // 关闭读端 write(pipefd[1], \u0026#34;Hello from parent\u0026#34;, 17); } 4.3 实现Shell命令 #Shell使用fork和exec来执行命令:\nif (fork() == 0) { execl(\u0026#34;/bin/ls\u0026#34;, \u0026#34;ls\u0026#34;, \u0026#34;-l\u0026#34;, NULL); exit(1); // 如果exec失败 } 5. Fork的性能考虑 #5.1 资源消耗 #每次fork都会创建一个新进程,这涉及:\n内存分配 复制进程信息 更新系统表 在资源受限的环境中,过度使用fork可能导致性能问题。\n5.2 上下文切换 #多个进程意味着更多的上下文切换,可能影响性能。在某些情况下,使用线程可能更为高效。\n6. Fork的高级技巧和注意事项 #6.1 信号处理 #Fork后,子进程继承父进程的信号处理程序。但在多线程程序中fork需要特别小心,因为子进程只包含调用fork的线程。\n6.2 清理资源 #在使用fork时,要注意适当地关闭不需要的文件描述符和释放资源,以防止资源泄漏。\n6.3 竞态条件 #需要注意父子进程之间可能的竞态条件,特别是在访问共享资源时。\n7. 实例分析：多重Fork #让我们回到最初的例子:\nvoid test(){ fork() \u0026amp;\u0026amp; fork() \u0026amp;\u0026amp; fork() \u0026amp;\u0026amp; sleep(10); printf(\u0026#34;hello\\n\u0026#34;); exit(0); } 这个例子展示了fork的几个关键特性:\n短路评估: 利用\u0026amp;\u0026amp;操作符的短路特性控制fork的执行。 进程创建: 每个成功的fork都创建一个新进程。 并发执行: 多个进程并发运行,导致多个\u0026quot;hello\u0026quot;输出。 7.1 Fork调用分析 #代码解析 #这段代码的关键在于 fork() \u0026amp;\u0026amp; fork() \u0026amp;\u0026amp; fork() \u0026amp;\u0026amp; sleep(10) 这一行。\nfork() 的行为 # fork() 创建一个新的子进程。 在父进程中，fork() 返回子进程的 PID（非零值）。 在子进程中，fork() 返回 0。 逻辑短路 #由于使用了 \u0026amp;\u0026amp;（逻辑与）操作符，这里涉及到短路评估：\n只有当前面的 fork() 返回非零值（在父进程中）时，后续的 fork() 才会执行。 如果任何 fork() 返回 0（在子进程中），后续的 fork() 和 sleep(10) 都不会执行。 执行流程 # 第一个 fork()：\n创建一个子进程 父进程继续执行下一个 fork() 子进程跳过后续 fork() 和 sleep()，直接打印 \u0026ldquo;hello\u0026rdquo; 第二个 fork()（只在父进程中执行）：\n再创建一个子进程 新的父进程继续执行第三个 fork() 新的子进程跳过后续 fork() 和 sleep()，打印 \u0026ldquo;hello\u0026rdquo; 第三个 fork()（只在最初的父进程中执行）：\n再创建一个子进程 最初的父进程执行 sleep(10) 新的子进程跳过 sleep()，打印 \u0026ldquo;hello\u0026rdquo; 10秒后，最初的父进程也会打印 \u0026ldquo;hello\u0026rdquo;\n进程树 #原始进程 ─── 子进程1 (打印\u0026#34;hello\u0026#34;) │ ├─── 子进程2 (打印\u0026#34;hello\u0026#34;) │ └─── 子进程3 (打印\u0026#34;hello\u0026#34;) │ └─── 父进程 (等待10秒后打印\u0026#34;hello\u0026#34;) 结果 #这段代码会输出 4 个 \u0026ldquo;hello\u0026rdquo;。\n3 个来自立即执行的子进程 1 个来自等待 10 秒后的父进程 8. 结论 #Fork是一个强大而复杂的系统调用,它为Unix/Linux系统提供了创建新进程的基本机制。理解和正确使用fork可以帮助开发者创建高效、可靠的多进程应用。然而,fork也带来了一些挑战,如资源管理和同步问题。在实际应用中,需要根据具体需求权衡使用fork、线程或其他并发机制。\n","date":"15 October 2024","permalink":"/blog/fork/","section":"Blog","summary":"\u003ch2 id=\"1-引言\" class=\"relative group\"\u003e1. 引言 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#1-%e5%bc%95%e8%a8%80\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003eFork是Unix/Linux系统中最基本也是最强大的系统调用之一。它允许一个进程创建一个新的进程,这个新进程是原进程的一个几乎完全相同的副本。本次技术分享将深入探讨fork机制,从基本概念到高级应用。\u003c/p\u003e","title":"Fork机制详解：从基础到高级应用"},{"content":"","date":null,"permalink":"/tags/system-programming/","section":"Tags","summary":"","title":"System Programming"},{"content":"","date":null,"permalink":"/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","section":"Tags","summary":"","title":"性能优化"},{"content":"1. 基础概念 #1.1 二进制表示 # 计算机使用二进制（0和1）存储和处理数据 1 byte = 8 bits 32位整数可以表示从 0 到 2^32 - 1 的数值 1.2 位操作基础 # 与操作 (\u0026amp;): 两位都为1时结果为1，否则为0 或操作 (|): 至少一位为1时结果为1，否则为0 异或操作 (^): 两位不同时结果为1，相同时为0 非操作 (~): 将每一位取反 左移 (\u0026laquo;): 将所有位向左移动，右侧补0 右移 (\u0026raquo;): 将所有位向右移动，左侧补0或符号位 示例：\nunsigned int a = 5; // 0101 unsigned int b = 3; // 0011 unsigned int and_result = a \u0026amp; b; // 0001 (1) unsigned int or_result = a | b; // 0111 (7) unsigned int xor_result = a ^ b; // 0110 (6) unsigned int not_result = ~a; // 11111111111111111111111111111010 (-6 in 2\u0026#39;s complement) unsigned int left_shift = a \u0026lt;\u0026lt; 1; // 1010 (10) unsigned int right_shift = a \u0026gt;\u0026gt; 1;// 0010 (2) 2. 掩码（Mask） #2.1 掩码定义 #掩码是用于选择或修改特定位的二进制模式\n2.2 常见掩码操作 # 提取位：value \u0026amp; mask 设置位：value | mask 清除位：value \u0026amp; ~mask 切换位：value ^ mask 示例：\nunsigned int value = 0xA5; // 10100101 unsigned int mask = 0x0F; // 00001111 unsigned int extract = value \u0026amp; mask; // 00000101 (5) unsigned int set = value | mask; // 10101111 (175) unsigned int clear = value \u0026amp; ~mask; // 10100000 (160) unsigned int toggle = value ^ mask; // 10101010 (170) 3. 位域（Bit Fields） #3.1 概念 #将较大的数据类型分割成多个小的字段，每个字段占用特定数量的位\n3.2 优势 # 内存效率：在一个整数中存储多个值 性能：位操作通常比其他操作更快 原子性：可以在一个操作中读取或修改多个字段 3.3 位域布局示例 #32-bit integer layout: [Instrument (29 bits)][Offset (2 bits)][Direction (1 bit)] 31 3 1 0 4. 实现技术 #4.1 定义掩码和偏移 ##define DIRECTION_BITS_MASK 0x1 #define DIRECTION_BITS_OFFSET 0x0 #define OFFSET_BITS_MASK 0x3 #define OFFSET_BITS_OFFSET 0x1 #define INSTRUMENT_BITS_MASK 0x1FFFFFFF #define INSTRUMENT_BITS_OFFSET 0x3 4.2 获取字段值 #int get_Field(int\u0026amp; value, int mask, int offset) { return (value \u0026gt;\u0026gt; offset) \u0026amp; mask; } // 具体实现示例 int get_Direction(int\u0026amp; value) { return (value \u0026gt;\u0026gt; DIRECTION_BITS_OFFSET) \u0026amp; DIRECTION_BITS_MASK; } 4.3 设置字段值 #根据字段的位置和大小，设置函数可能有不同的实现：\n// 对于最低位的单位字段（如 Direction） int set_Direction(int\u0026amp; value, int new_direction) { if (new_direction != 1 \u0026amp;\u0026amp; new_direction != 0) { return -1; } value = (value \u0026amp; ~DIRECTION_BITS_MASK) | new_direction; return 0; } // 对于非最低位的多位字段（如 Offset） int set_Offset(int\u0026amp; value, int new_offset) { if (new_offset \u0026lt; 3 \u0026amp;\u0026amp; new_offset \u0026gt; 0) { value = (value \u0026amp; ~(OFFSET_BITS_MASK \u0026lt;\u0026lt; OFFSET_BITS_OFFSET)) | (new_offset \u0026lt;\u0026lt; OFFSET_BITS_OFFSET); return 0; } return -1; } 注意 set_Direction 和 set_Offset 的区别：\nset_Direction 直接使用掩码，因为它操作的是最低位 set_Offset 需要将掩码和新值左移，因为它操作的位不在最低位置 4.4 通用设置函数 #int set_Field(int\u0026amp; value, int new_field_value, int mask, int offset) { value = (value \u0026amp; ~(mask \u0026lt;\u0026lt; offset)) | (new_field_value \u0026lt;\u0026lt; offset); return 0; } 5. 在高频交易（HFT）系统中的应用 #高频交易系统对性能和延迟极其敏感，位操作在这里发挥着关键作用。\n5.1 订单编码 #在HFT系统中，订单信息需要快速处理和传输。使用位域可以将订单的多个属性打包到一个整数中：\n#define ORDER_TYPE_MASK 0x03 #define SIDE_MASK 0x04 #define QUANTITY_MASK 0xFFFFF8 #define PRICE_MASK 0xFFF00000 #define ORDER_TYPE_OFFSET 0 #define SIDE_OFFSET 2 #define QUANTITY_OFFSET 3 #define PRICE_OFFSET 20 typedef unsigned int OrderInfo; OrderInfo createOrder(unsigned char type, bool isBuy, unsigned int quantity, unsigned int price) { return (type \u0026amp; ORDER_TYPE_MASK) | ((isBuy ? 1 : 0) \u0026lt;\u0026lt; SIDE_OFFSET) | ((quantity \u0026amp; (QUANTITY_MASK \u0026gt;\u0026gt; QUANTITY_OFFSET)) \u0026lt;\u0026lt; QUANTITY_OFFSET) | ((price \u0026amp; (PRICE_MASK \u0026gt;\u0026gt; PRICE_OFFSET)) \u0026lt;\u0026lt; PRICE_OFFSET); } unsigned char getOrderType(OrderInfo order) { return order \u0026amp; ORDER_TYPE_MASK; } bool isBuyOrder(OrderInfo order) { return (order \u0026amp; SIDE_MASK) != 0; } unsigned int getQuantity(OrderInfo order) { return (order \u0026amp; QUANTITY_MASK) \u0026gt;\u0026gt; QUANTITY_OFFSET; } unsigned int getPrice(OrderInfo order) { return (order \u0026amp; PRICE_MASK) \u0026gt;\u0026gt; PRICE_OFFSET; } 5.2 市场数据压缩 #HFT系统需要处理大量的市场数据。使用位操作可以压缩数据，减少网络传输和存储需求：\nstruct CompressedQuote { unsigned long long timestamp : 48; // 微秒级时间戳 unsigned int symbol : 24; // 股票代码 unsigned int bidPrice : 32; // 买入价 unsigned int askPrice : 32; // 卖出价 unsigned int bidSize : 24; // 买入量 unsigned int askSize : 24; // 卖出量 unsigned int flags : 8; // 各种标志 }; 5.3 快速比较和匹配 #位操作可用于实现快速的订单匹配和比较：\nbool isMatchingOrder(OrderInfo order1, OrderInfo order2) { return (getOrderType(order1) == getOrderType(order2)) \u0026amp;\u0026amp; (isBuyOrder(order1) != isBuyOrder(order2)) \u0026amp;\u0026amp; ((isBuyOrder(order1) \u0026amp;\u0026amp; getPrice(order1) \u0026gt;= getPrice(order2)) || (!isBuyOrder(order1) \u0026amp;\u0026amp; getPrice(order1) \u0026lt;= getPrice(order2))); } 5.4 风险管理和合规检查 #位操作可以用于快速执行风险检查和合规验证：\n#define RISK_CHECK_MASK 0xF0000000 bool passesRiskCheck(OrderInfo order) { return (order \u0026amp; RISK_CHECK_MASK) == 0; } 5.5 性能优化 # 缓存友好：紧凑的数据表示有助于更好地利用CPU缓存。\nSIMD操作：某些位操作可以利用SIMD（单指令多数据）指令进行并行处理。\n// 使用SIMD指令并行处理多个订单 void processOrdersSIMD(OrderInfo* orders, int count) { // 使用 AVX2 指令集 __m256i orderVector = _mm256_loadu_si256((__m256i*)orders); __m256i typeMask = _mm256_set1_epi32(ORDER_TYPE_MASK); __m256i types = _mm256_and_si256(orderVector, typeMask); // 进一步处理... } 网络优化：压缩的数据格式减少了网络传输量，降低延迟。\n5.6 HFT系统中的注意事项 # 可读性 vs 性能：在HFT系统中，通常会牺牲一定的可读性来换取极致的性能。 正确性验证：由于位操作容易出错，需要严格的单元测试和集成测试。 文档和注释：详细的文档和注释对于维护这类高度优化的代码至关重要。 硬件考虑：某些位操作可能在特定硬件上更高效，需要针对目标平台优化。 6. 结论 #位操作和位域是强大的编程技术，在需要高性能和内存效率的场景中尤其有用。在高频交易系统中，这些技术能够显著提升数据处理速度、减少内存使用和网络延迟。然而，使用这些技术需要在性能、可读性和可维护性之间取得平衡。随着金融技术的不断发展，掌握和巧妙运用这些基础但强大的技术将继续在高性能计算领域，特别是在HFT系统中发挥重要作用。\n","date":"13 October 2024","permalink":"/blog/bit_field_compression/","section":"Blog","summary":"\u003ch2 id=\"1-基础概念\" class=\"relative group\"\u003e1. 基础概念 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#1-%e5%9f%ba%e7%a1%80%e6%a6%82%e5%bf%b5\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003ch3 id=\"11-二进制表示\" class=\"relative group\"\u003e1.1 二进制表示 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#11-%e4%ba%8c%e8%bf%9b%e5%88%b6%e8%a1%a8%e7%a4%ba\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h3\u003e\u003cul\u003e\n\u003cli\u003e计算机使用二进制（0和1）存储和处理数据\u003c/li\u003e\n\u003cli\u003e1 byte = 8 bits\u003c/li\u003e\n\u003cli\u003e32位整数可以表示从 0 到 2^32 - 1 的数值\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"12-位操作基础\" class=\"relative group\"\u003e1.2 位操作基础 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#12-%e4%bd%8d%e6%93%8d%e4%bd%9c%e5%9f%ba%e7%a1%80\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h3\u003e\u003cul\u003e\n\u003cli\u003e与操作 (\u0026amp;): 两位都为1时结果为1，否则为0\u003c/li\u003e\n\u003cli\u003e或操作 (|): 至少一位为1时结果为1，否则为0\u003c/li\u003e\n\u003cli\u003e异或操作 (^): 两位不同时结果为1，相同时为0\u003c/li\u003e\n\u003cli\u003e非操作 (~): 将每一位取反\u003c/li\u003e\n\u003cli\u003e左移 (\u0026laquo;): 将所有位向左移动，右侧补0\u003c/li\u003e\n\u003cli\u003e右移 (\u0026raquo;): 将所有位向右移动，左侧补0或符号位\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e示例：\u003c/p\u003e","title":"高频交易系统中的位域压缩技术"},{"content":"1. 背景介绍 #在高频交易系统中，市场数据的快速读取和处理是关键性能指标之一。我们的系统使用共享内存来存储和访问实时市场数据，其中 MarketDataStore 类负责管理这些数据。本文将讨论如何优化 MarketDataStore 中的 readLatestData 函数，以提高数据读取的效率。\n2. 初始实现 #最初的 readLatestData 函数实现如下：\nstd::optional\u0026lt;MappedTickerData\u0026gt; MarketDataStore::readLatestData(const std::string\u0026amp; symbol) const { std::shared_lock\u0026lt;std::shared_mutex\u0026gt; lock(mutex); size_t offset = calculateOffset(symbol); MappedTickerData data; if (dataFile-\u0026gt;read(\u0026amp;data, offset, sizeof(MappedTickerData))) { if (data.timestamp != 0 \u0026amp;\u0026amp; std::string(data.product_id) == symbol) { return data; } else { LOG_WARN(\u0026#34;readLatestData symbol = {} failed\u0026#34;, symbol); return std::nullopt; } } else { LOG_ERROR(\u0026#34;Failed to read data for symbol = {}\u0026#34;, symbol); return std::nullopt; } } 这个实现存在几个性能瓶颈：\n使用共享锁可能导致并发读取的性能下降。 字符串比较效率低下，特别是创建临时 std::string 对象。 没有利用现代 CPU 的 SIMD 指令集。 3. 优化过程 #3.1 字符串比较优化 #首先，我们优化了字符串比较逻辑：\nstatic inline bool compareProductId(const char* product_id, const std::string\u0026amp; symbol) { size_t symbolLength = symbol.length(); if (symbolLength \u0026gt; sizeof(MappedTickerData::product_id) - 1) { return false; } if (memcmp(product_id, symbol.data(), symbolLength) != 0) { return false; } return product_id[symbolLength] == \u0026#39;\\0\u0026#39;; } 这个优化避免了创建临时字符串对象，并使用了更高效的 memcmp 函数。\n3.2 SIMD 指令优化 #为了进一步提高性能，我们引入了 SIMD 指令来并行化字符串比较：\nstatic inline bool compareProductIdSIMD(const char* product_id, const std::string\u0026amp; symbol) { size_t symbolLength = symbol.length(); if (symbolLength \u0026gt; 15) { return false; } __m128i prod_id = _mm_loadu_si128(reinterpret_cast\u0026lt;const __m128i*\u0026gt;(product_id)); char mask[16] = {0}; memcpy(mask, symbol.data(), symbolLength); __m128i symbol_mask = _mm_loadu_si128(reinterpret_cast\u0026lt;const __m128i*\u0026gt;(mask)); __m128i cmp_result = _mm_cmpeq_epi8(prod_id, symbol_mask); int match_mask = _mm_movemask_epi8(cmp_result); int should_match = (1 \u0026lt;\u0026lt; symbolLength) - 1; if ((match_mask \u0026amp; should_match) != should_match) { return false; } return (match_mask \u0026amp; (1 \u0026lt;\u0026lt; symbolLength)) != 0; } 这个实现利用 SSE 指令集同时比较 16 个字节，显著提高了比较速度。\n3.3 无锁读取 #考虑到 readLatestData 函数被频繁调用，我们探讨了使用无锁读取技术：\nstd::optional\u0026lt;MappedTickerData\u0026gt; MarketDataStore::readLatestData(const std::string\u0026amp; symbol) const { size_t offset = calculateOffset(symbol); MappedTickerData data; std::atomic_thread_fence(std::memory_order_acquire); memcpy(\u0026amp;data, static_cast\u0026lt;char*\u0026gt;(mappedMemory) + offset, sizeof(MappedTickerData)); std::atomic_thread_fence(std::memory_order_acquire); if (data.timestamp != 0 \u0026amp;\u0026amp; compareProductIdSIMD(data.product_id, symbol)) { return data; } return std::nullopt; } 这个版本移除了共享锁，使用内存屏障确保数据一致性。\n4. 最终优化版本 #综合以上优化，我们的最终版本如下：\nclass MarketDataStore { private: void* mappedMemory; size_t memorySize; std::unordered_map\u0026lt;std::string_view, size_t\u0026gt; symbolOffsets; static inline bool compareProductIdSIMD(const char* product_id, const std::string\u0026amp; symbol) { // SIMD 比较实现（如前所示） } public: inline std::optional\u0026lt;MappedTickerData\u0026gt; readLatestData(std::string_view symbol) const noexcept { auto it = symbolOffsets.find(symbol); if (it == symbolOffsets.end()) { return std::nullopt; } size_t offset = it-\u0026gt;second; if (offset + sizeof(MappedTickerData) \u0026gt; memorySize) { return std::nullopt; } MappedTickerData data; std::atomic_thread_fence(std::memory_order_acquire); memcpy(\u0026amp;data, static_cast\u0026lt;char*\u0026gt;(mappedMemory) + offset, sizeof(MappedTickerData)); std::atomic_thread_fence(std::memory_order_acquire); if (data.timestamp == 0) { return std::nullopt; } if (compareProductIdSIMD(data.product_id, std::string(symbol))) { return data; } return std::nullopt; } }; 5. 性能考虑和注意事项 # SIMD 指令：确保目标平台支持使用的 SIMD 指令集。 内存对齐：考虑将 MappedTickerData 结构体对齐到缓存线边界。 预计算偏移量：使用 symbolOffsets 哈希表预存储偏移量，避免重复计算。 无锁读取：在多线程环境中需要仔细考虑内存一致性问题。 字符串视图：使用 std::string_view 减少不必要的字符串拷贝。 6. 结论 #通过这一系列优化，我们显著提高了 MarketDataStore 的读取性能。主要改进包括：\n使用 SIMD 指令加速字符串比较 实现无锁读取减少线程竞争 优化内存访问模式提高缓存效率 这些优化对于高频交易系统的整体性能有重要影响。然而，在实际部署前，务必进行全面的基准测试和压力测试，以确保在实际工作负载下的性能提升。\n7. 未来工作 # 探索使用更高级的 SIMD 指令集（如 AVX-512）进一步优化。 实现自适应策略，根据数据特征动态选择最佳的比较方法。 考虑引入预取技术，进一步减少内存访问延迟。 持续监控和分析系统性能，识别新的优化机会。 ","date":"29 September 2024","permalink":"/blog/read/","section":"Blog","summary":"\u003ch2 id=\"1-背景介绍\" class=\"relative group\"\u003e1. 背景介绍 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#1-%e8%83%8c%e6%99%af%e4%bb%8b%e7%bb%8d\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003e在高频交易系统中，市场数据的快速读取和处理是关键性能指标之一。我们的系统使用共享内存来存储和访问实时市场数据，其中 \u003ccode\u003eMarketDataStore\u003c/code\u003e 类负责管理这些数据。本文将讨论如何优化 \u003ccode\u003eMarketDataStore\u003c/code\u003e 中的 \u003ccode\u003ereadLatestData\u003c/code\u003e 函数，以提高数据读取的效率。\u003c/p\u003e","title":"高频交易系统中的市场数据存储优化"},{"content":"高频交易系统中的重连机制最佳实践 #背景 #在高频交易系统中，网络连接的稳定性至关重要。然而，由于网络波动或其他原因，连接可能会中断。为了确保系统的连续性和可靠性，需要实现一个高效的重连机制。然而，频繁的重连检查和处理可能导致重复重连，影响系统性能。\n问题描述 #在现有实现中，主循环频繁检查 m_client-\u0026gt;needsReconnection()，如果需要重连，则调用 handleReconnect()。然而，由于主循环速度很快，可能在 resetReconnectionFlag() 生效前再次检查 needsReconnection()，导致重复调用 handleReconnect()。\n解决方案 #通过使用原子操作和双重检查机制，确保重连过程的原子性和一致性，避免重复重连。\n1. 定义连接状态管理 #使用原子变量来管理连接状态，确保线程安全。\nclass WebSocketClient { private: std::atomic\u0026lt;bool\u0026gt; isReconnecting{false}; std::atomic\u0026lt;bool\u0026gt; needsReconnection{false}; public: bool needsReconnection() const { return needsReconnection.load(std::memory_order_acquire); } bool tryInitiateReconnection() { bool expected = false; return isReconnecting.compare_exchange_strong(expected, true, std::memory_order_acq_rel); } void setNeedsReconnection(bool value) { needsReconnection.store(value, std::memory_order_release); } void resetReconnectionFlag() { needsReconnection.store(false, std::memory_order_release); isReconnecting.store(false, std::memory_order_release); } }; 2. 修改主循环 #在主循环中使用双重检查机制，确保重连过程的原子性。\nvoid StrategyAndTrading::run() { initializeConnection(); marketDataReader-\u0026gt;start(); positionManager-\u0026gt;updatePositionsThread(); m_commonLib-\u0026gt;getConfigManager().configWatcher(); while (running_) { if (m_client-\u0026gt;needsReconnection() \u0026amp;\u0026amp; m_client-\u0026gt;tryInitiateReconnection()) { handleReconnect(); } // 执行其他高频交易逻辑 std::this_thread::sleep_for(std::chrono::microseconds(100)); // 微秒级的睡眠 } } 3. 实现重连处理 #确保重连过程的原子性和一致性。\nvoid StrategyAndTrading::handleReconnect() { LOG_INFO(\u0026#34;Initiating reconnection process\u0026#34;); int retryCount = 0; const int MAX_RETRIES = 3; while (retryCount \u0026lt; MAX_RETRIES) { LOG_INFO(\u0026#34;retryCount: {} RECONNECTING\u0026#34;, retryCount); if (establishConnection(true)) { LOG_INFO(\u0026#34;Reconnection successful\u0026#34;); m_client-\u0026gt;resetReconnectionFlag(); return; } retryCount++; LOG_WARN(\u0026#34;Reconnection attempt {} failed, retrying...\u0026#34;, retryCount); std::this_thread::sleep_for(std::chrono::seconds(5 * retryCount)); } LOG_ERROR(\u0026#34;Reconnection failed after {} attempts\u0026#34;, MAX_RETRIES); m_client-\u0026gt;setNeedsReconnection(true); // 保持重连需求 m_client-\u0026gt;resetReconnectionFlag(); // 允许下一次重连尝试 } 设计理由 # 原子操作：使用 std::atomic 确保线程安全，避免数据竞争。 双重检查：通过 needsReconnection() 和 tryInitiateReconnection() 的组合，避免重复进入重连流程。 状态一致性：resetReconnectionFlag() 同时重置两个标志，确保状态一致。 性能优化：主循环中的睡眠时间可以调整到微秒级，保持高响应性。 简单直接：相比复杂的多线程或状态机方案，这个解决方案更加直接地解决了您描述的问题。 可扩展性：这个设计易于扩展，可以添加更多的连接状态和相应的处理逻辑。 错误恢复：如果重连失败，系统会保持重连需求，允许在下一个循环中再次尝试。 compare_exchange_strong 的使用 #用法 #compare_exchange_strong 是 C++ 标准库中 std::atomic 提供的一种原子操作，用于实现无锁编程。它的作用是比较并交换（Compare and Swap, CAS），确保在多线程环境下对变量的更新是原子的。\n函数签名 #bool compare_exchange_strong(T\u0026amp; expected, T desired, std::memory_order order = std::memory_order_seq_cst) noexcept; 参数 # expected：一个引用，表示预期的旧值。如果当前值与 expected 相等，则将其更新为 desired，否则将当前值写入 expected。 desired：要设置的新值。 order：内存序（memory order），控制内存操作的顺序。常用的有 std::memory_order_acquire、std::memory_order_release 和 std::memory_order_acq_rel。 返回值 # 如果当前值与 expected 相等，则返回 true，并将当前值更新为 desired。 如果当前值与 expected 不相等，则返回 false，并将当前值写入 expected。 在新方案中的作用 #在新方案中，compare_exchange_strong 用于确保只有一个线程可以成功启动重连过程，避免多个线程同时进入重连过程。\n代码示例 #bool tryInitiateReconnection() { bool expected = false; return isReconnecting.compare_exchange_strong(expected, true, std::memory_order_acq_rel); } 解释 # 初始化 expected：expected 被初始化为 false，表示预期的旧值是 false。 调用 compare_exchange_strong： 如果 isReconnecting 当前值等于 expected（即 false），则将 isReconnecting 更新为 true，并返回 true。 如果 isReconnecting 当前值不等于 expected（即已经有其他线程将其设置为 true），则将 isReconnecting 的当前值写入 expected，并返回 false。 内存序 # std::memory_order_acq_rel：确保在获取和释放内存时的顺序性，保证在重连过程中对内存的访问是有序的。 具体应用 #在主循环中，通过 tryInitiateReconnection 方法来检查并启动重连过程：\nvoid StrategyAndTrading::run() { while (running_) { if (m_client-\u0026gt;needsReconnection() \u0026amp;\u0026amp; m_client-\u0026gt;tryInitiateReconnection()) { handleReconnect(); } std::this_thread::sleep_for(std::chrono::microseconds(100)); // 微秒级的睡眠 } } 解释 # 检查 needsReconnection：首先检查是否需要重连。 尝试启动重连：如果需要重连，调用 tryInitiateReconnection。 如果 tryInitiateReconnection 返回 true，表示当前线程成功启动了重连过程。 如果 tryInitiateReconnection 返回 false，表示已经有其他线程在进行重连，当前线程不需要重复启动重连过程。 实施注意事项 # 确保线程安全：所有涉及连接状态的操作都应是线程安全的。 调整睡眠时间：根据系统需求调整主循环中的睡眠时间，在响应性和系统负载之间找到平衡。 添加日志和监控：适当的日志记录和监控有助于跟踪重连过程和系统状态。 扩展性：可以根据需要在 WebSocketClient 中实现更复杂的状态管理逻辑，如处理部分连接、认证失败等状态。 总结 #通过这个最佳实践，您可以有效管理高频交易系统中的重连过程，避免重复重连，同时保持系统的高性能和可靠性。这个设计方案不仅解决了当前的问题，还为未来的扩展和维护提供了良好的基础。\n","date":"27 September 2024","permalink":"/blog/atom/","section":"Blog","summary":"\u003ch1 id=\"高频交易系统中的重连机制最佳实践\" class=\"relative group\"\u003e高频交易系统中的重连机制最佳实践 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e9%ab%98%e9%a2%91%e4%ba%a4%e6%98%93%e7%b3%bb%e7%bb%9f%e4%b8%ad%e7%9a%84%e9%87%8d%e8%bf%9e%e6%9c%ba%e5%88%b6%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h1\u003e\u003ch2 id=\"背景\" class=\"relative group\"\u003e背景 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e8%83%8c%e6%99%af\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003e在高频交易系统中，网络连接的稳定性至关重要。然而，由于网络波动或其他原因，连接可能会中断。为了确保系统的连续性和可靠性，需要实现一个高效的重连机制。然而，频繁的重连检查和处理可能导致重复重连，影响系统性能。\u003c/p\u003e","title":"高频交易系统中的重连机制最佳实践"},{"content":"1. 初始问题：数据读取效率 #最初，我们关注的是市场数据读取器本身的效率问题。\n1.1 轮询方式（初始状态） #void MarketDataReader::readingLoop() { while (running) { for (const auto\u0026amp; symbol : symbols_) { processSymbol(symbol); } std::this_thread::sleep_for(std::chrono::milliseconds(100)); } } 问题：持续轮询即使在没有新数据时也会消耗资源。\n1.2 条件控制方式 #void MarketDataReader::readingLoop() { while (running) { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(conditionMutex); dataCondition.wait(lock, [this] { return !running || !symbols_.empty(); }); for (const auto\u0026amp; symbol : symbols_) { processSymbol(symbol); } } } 改进：减少了不必要的CPU使用，但可能会在高频数据更新时引入延迟。\n思考转变：这个阶段，我们主要关注如何提高单个组件（数据读取器）的效率。\n2. 扩展考虑：数据读取对其他系统组件的影响 #随着对系统的深入思考，我们开始考虑数据读取器的行为如何影响整个系统，特别是订单流的执行效率。\n2.1 资源竞争问题 #观察：尽管我们优化了数据读取器的效率，但数据读取线程占据太多的计算资源，也会进而影响订单处理的性能。即使在没有新数据可读时，频繁的检查也会占用宝贵的计算资源。\n思考：\n数据读取和订单处理是否在竞争同样的系统资源（CPU、内存、I/O）？ 如何在保证数据及时性的同时，不影响订单处理的响应速度？ 如何协调各个线程，使系统达到最低的时延？ 2.2 自适应间隔机制 #引入动态调整处理间隔的机制，以平衡数据读取和系统资源使用。\nvoid MarketDataReader::readingLoop() { while (running) { auto start = std::chrono::steady_clock::now(); for (const auto\u0026amp; symbol : symbols_) { processSymbol(symbol); } auto end = std::chrono::steady_clock::now(); auto duration = std::chrono::duration_cast\u0026lt;std::chrono::microseconds\u0026gt;(end - start); if (duration \u0026lt; currentInterval) { std::this_thread::sleep_for(currentInterval - duration); } adjustInterval(); } } 思考转变：从单纯的效率优化转向了资源使用的平衡，考虑到了系统的整体性能。\n3. 系统级优化：负载均衡 #随着对系统整体的思考，我们意识到需要从更高的层面来优化性能和资源分配。\n3.1 多线程数据读取 #将数据读取任务分散到多个线程，以提高并行处理能力。\nclass BalancedMarketDataReader { private: std::vector\u0026lt;std::thread\u0026gt; readerThreads; std::vector\u0026lt;std::vector\u0026lt;std::string\u0026gt;\u0026gt; symbolGroups; public: void start() { for (int i = 0; i \u0026lt; numThreads; ++i) { readerThreads.emplace_back(\u0026amp;BalancedMarketDataReader::readingLoop, this, i); } } }; 思考：如何最有效地分配交易品种给不同的线程，以平衡负载？\n3.2 动态负载均衡 #实现能够根据实时负载情况动态调整工作分配的机制。\nclass DynamicLoadBalancer { private: std::vector\u0026lt;std::atomic\u0026lt;int\u0026gt;\u0026gt; threadLoads; std::mutex symbolsMutex; std::vector\u0026lt;std::string\u0026gt; symbols; public: void balancerLoop() { while (running) { rebalanceLoad(); std::this_thread::sleep_for(std::chrono::seconds(10)); } } }; 思考：如何在数据读取和订单处理之间动态分配系统资源，以实现最佳的整体性能？\n3.3 工作窃取算法 #引入更复杂的负载均衡策略，允许空闲线程从繁忙线程\u0026quot;窃取\u0026quot;工作。\nclass WorkStealingBalancer { private: std::vector\u0026lt;std::unique_ptr\u0026lt;WorkStealingQueue\u0026gt;\u0026gt; queues; bool stealWork(int threadId) { for (size_t i = 0; i \u0026lt; queues.size(); ++i) { if (i == threadId) continue; std::string symbol; if (queues[i]-\u0026gt;steal(symbol)) { processSymbol(symbol); queues[threadId]-\u0026gt;push(symbol); return true; } } return false; } }; 思考转变：从单一组件的优化，发展到了整个系统的资源分配和负载均衡策略。\n思考过程的演进 # 局部到全局：从优化单一数据读取器的效率，扩展到考虑整个系统的性能平衡。 单线程到多线程：认识到多线程处理在提高系统整体吞吐量方面的重要性。 静态分配到动态平衡：从固定的处理策略，转向能够适应实时负载变化的动态系统。 资源使用的权衡：深入思考如何在关键组件（如数据读取和订单处理）之间合理分配资源。 性能指标的全面性：从仅关注数据读取的速度，扩展到考虑系统整体的响应时间、吞吐量和资源利用率。 跨组件影响的认识：理解到一个组件的优化可能会对其他组件产生意料之外的影响，需要从整体角度进行评估。 结论 #这个思考探究过程展示了如何从解决具体问题逐步扩展到系统层面的优化。它强调了在高频交易这样的复杂系统中，局部优化虽然重要，但必须放在整体系统性能和资源平衡的大背景下来考虑。\n这种思维方式的转变不仅适用于市场数据读取器的优化，也可以应用于其他复杂系统的性能优化过程。它提醒我们，在进行任何优化时，都需要考虑：\n这个优化如何影响系统的其他部分？ 我们是否在正确的层面上解决问题？ 局部的高效是否会导致全局的低效？ 如何设计一个能够适应变化和自我调节的系统？ 通过这样的思考过程，我们不仅解决了最初的数据读取效率问题，还提出了更全面、更有弹性的系统优化方案，为构建一个高性能、高可靠性的高频交易系统奠定了基础。\n","date":"25 September 2024","permalink":"/blog/datareader_design/","section":"Blog","summary":"\u003ch2 id=\"1-初始问题数据读取效率\" class=\"relative group\"\u003e1. 初始问题：数据读取效率 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#1-%e5%88%9d%e5%a7%8b%e9%97%ae%e9%a2%98%e6%95%b0%e6%8d%ae%e8%af%bb%e5%8f%96%e6%95%88%e7%8e%87\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003e最初，我们关注的是市场数据读取器本身的效率问题。\u003c/p\u003e","title":"高频交易系统优化：从数据读取到系统平衡的思考过程"},{"content":"高性能低延迟交易系统设计：技术分享 update #在高频交易和实时金融系统中，性能和延迟是关键因素。本文将分享一些设计和实现高性能低延迟交易系统的关键技术和策略。\n1. 数据结构优化 #1.1 内存映射（Memory-Mapped）文件 #使用内存映射文件可以显著提高I/O性能，减少系统调用，并允许快速的进程间通信。\nclass MmapOrderBook { // 使用内存映射文件存储订单簿数据 }; 1.2 自定义内存池 #实现自定义内存池可以减少内存分配和释放的开销，提高内存使用效率。\ntemplate\u0026lt;typename T, size_t MaxSize\u0026gt; class MemoryPool { // 实现高效的内存分配和回收 }; 2. 并发控制 #2.1 细粒度锁 #使用细粒度锁可以减少锁竞争，提高并发性能。\nstd::array\u0026lt;std::shared_mutex, MAX_POSITIONS\u0026gt; m_positionMutexes; 2.2 无锁数据结构 #在关键路径上使用无锁数据结构可以进一步减少同步开销。\nstd::atomic\u0026lt;double\u0026gt; quantity; std::atomic\u0026lt;double\u0026gt; averagePrice; 3. 高效的更新策略 #3.1 增量更新 vs 全量更新 #根据具体场景选择合适的更新策略。增量更新适合频繁的小幅度变化，全量更新适合大幅度变化或定期同步。\nvoid updatePosition(const char* instId, AssetType type, PositionSide side, double quantityDelta, double price); void syncPositionWithExchange(const char* instId, AssetType type, PositionSide side, double quantity, double price); 3.2 原子操作 #使用原子操作可以在不使用锁的情况下实现线程安全的更新。\natomicUpdate(positionPtr-\u0026gt;averagePrice, [newQuantity, quantityDelta, price](double oldAvgPrice) { return (oldAvgPrice * (newQuantity - quantityDelta) + price * quantityDelta) / newQuantity; }); 4. 代码优化 #4.1 内联函数 #使用内联函数可以减少函数调用开销。\ninline void updateAvailable(double delta) { available.fetch_add(delta, std::memory_order_relaxed); } 4.2 分支预测优化 #减少难以预测的分支，利用现代CPU的分支预测功能。\n// 避免复杂的嵌套条件判断 if (type == AssetType::SPOT) { // SPOT 逻辑 } else { // 其他类型逻辑 } 5. 系统架构 #5.1 职责分离 #将不同功能模块分离，如将订单管理和持仓管理分开，可以提高系统的可维护性和可扩展性。\nclass OrderManager { /* ... */ }; class PositionManager { /* ... */ }; 5.2 最小化跨模块调用 #减少模块间的频繁调用，可以降低系统复杂度和延迟。\n6. 性能监控和日志 #6.1 高效日志 #使用异步日志和日志级别控制，确保日志不会成为性能瓶颈。\nLOG_INFO(\u0026#34;Position updated: instId={}, type={}, side={}\u0026#34;, instId, static_cast\u0026lt;int\u0026gt;(type), static_cast\u0026lt;int\u0026gt;(side)); 6.2 性能指标监控 #实时监控关键性能指标，如更新延迟、吞吐量等，以便及时发现和解决性能问题。\n结论 #构建高性能低延迟的交易系统需要在多个层面进行优化，包括数据结构、并发控制、更新策略、代码优化和系统架构等。通过综合运用这些技术，可以显著提升系统的性能和响应速度，满足高频交易和实时金融系统的严格要求。\n","date":"20 September 2024","permalink":"/blog/high_performance/","section":"Blog","summary":"\u003ch1 id=\"高性能低延迟交易系统设计技术分享-update\" class=\"relative group\"\u003e高性能低延迟交易系统设计：技术分享 update \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e9%ab%98%e6%80%a7%e8%83%bd%e4%bd%8e%e5%bb%b6%e8%bf%9f%e4%ba%a4%e6%98%93%e7%b3%bb%e7%bb%9f%e8%ae%be%e8%ae%a1%e6%8a%80%e6%9c%af%e5%88%86%e4%ba%ab-update\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h1\u003e\u003cp\u003e在高频交易和实时金融系统中，性能和延迟是关键因素。本文将分享一些设计和实现高性能低延迟交易系统的关键技术和策略。\u003c/p\u003e","title":"实现高性能低延迟的交易系统设计"},{"content":"在高频交易系统的开发中，我们经常面临着性能和正确性之间的权衡。最近，我们在优化订单处理流程时，发现了一个有趣的问题：是否需要在高层组件中实现锁定？本文将深入探讨这个问题，分析其必要性，并展示优化前后的实现。\n背景 我们的系统主要由以下组件构成：\nMmapOrderBook：核心数据存储，使用内存映射文件实现 PositionManager：负责仓位管理 OrderValidator：负责订单验证 OrderManager：负责订单处理流程 最初，我们的实现如下：\n// OrderManager.cpp bool OrderManager::processOrder(const MmapOrderBook::Order\u0026amp; order) { if (!orderValidator_-\u0026gt;validateOrder(order)) { return false; } if (orderBook_-\u0026gt;addOrder(order)) { auto position = positionManager_-\u0026gt;getPosition(order.accountId, /* instrumentId */); if (position) { position-\u0026gt;quantity += order.isBuy ? order.quantity : -order.quantity; positionManager_-\u0026gt;updatePosition(*position); } // 发布订单已处理事件 return true; } return false; } 问题分析 虽然 MmapOrderBook 内部使用了分片锁来保证单个操作的线程安全，但我们发现这种方法在处理复合操作时可能存在问题。主要原因如下：\na) 复合操作的原子性： processOrder 方法包含多个相关操作（验证、添加、更新仓位），这些操作需要作为一个原子单元执行。\nb) 避免竞态条件： 在验证订单和添加订单之间，系统状态可能发生变化，导致基于过时信息做出决策。\nc) 保持不变量： 某些业务逻辑依赖于多个相关数据的一致状态，需要在整个操作过程中维护这些不变量。\nd) 简化并发模型： 高层锁定可以简化并发模型，使代码更易于理解和维护。\ne) 防止死锁： 复杂操作中可能需要获取多个低层锁，增加死锁风险。高层锁可以降低这种风险。\n优化后的实现 考虑到上述因素，我们决定在 OrderManager 和 PositionManager 中引入高层锁定：\n// OrderManager.h class OrderManager { public: bool processOrder(const MmapOrderBook::Order\u0026amp; order); private: std::shared_ptr\u0026lt;MmapOrderBook\u0026gt; orderBook_; std::shared_ptr\u0026lt;PositionManager\u0026gt; positionManager_; std::shared_ptr\u0026lt;OrderValidator\u0026gt; orderValidator_; mutable std::shared_mutex mutex_; // 新增：读写锁 }; // OrderManager.cpp bool OrderManager::processOrder(const MmapOrderBook::Order\u0026amp; order) { std::unique_lock\u0026lt;std::shared_mutex\u0026gt; lock(mutex_); // 写锁 if (!orderValidator_-\u0026gt;validateOrder(order)) { return false; } if (orderBook_-\u0026gt;addOrder(order)) { auto position = positionManager_-\u0026gt;getPosition(order.accountId, /* instrumentId */); if (position) { position-\u0026gt;quantity += order.isBuy ? order.quantity : -order.quantity; positionManager_-\u0026gt;updatePosition(*position); } // 发布订单已处理事件 return true; } return false; } // PositionManager.h class PositionManager { public: bool updatePosition(const MmapOrderBook::Position\u0026amp; position); std::optional\u0026lt;MmapOrderBook::Position\u0026gt; getPosition(int64_t accountId, int64_t instrumentId) const; private: std::shared_ptr\u0026lt;MmapOrderBook\u0026gt; orderBook_; mutable std::shared_mutex mutex_; // 新增：读写锁 }; // PositionManager.cpp bool PositionManager::updatePosition(const MmapOrderBook::Position\u0026amp; position) { std::unique_lock\u0026lt;std::shared_mutex\u0026gt; lock(mutex_); // 写锁 return orderBook_-\u0026gt;updatePosition(position); } std::optional\u0026lt;MmapOrderBook::Position\u0026gt; PositionManager::getPosition(int64_t accountId, int64_t instrumentId) const { std::shared_lock\u0026lt;std::shared_mutex\u0026gt; lock(mutex_); // 读锁 return orderBook_-\u0026gt;getPosition(accountId, instrumentId); } 优化效果 通过引入高层锁定，我们实现了以下目标：\n确保了复合操作的原子性 消除了潜在的竞态条件 简化了并发模型，使代码更易维护 降低了死锁风险 注意事项 尽管高层锁定解决了许多问题，但它也带来了一些潜在的挑战：\n性能影响：高层锁可能会降低并发性，因为它们tend会持锁时间更长。 可能的过度序列化：如果锁的范围过大，可能会导致一些本可以并行的操作被不必要地序列化。 潜在的资源浪费：如果锁覆盖了太多不相关的操作，可能会造成资源的浪费。 未来优化方向 为了进一步提高系统性能，我们可以考虑以下优化方向：\n实现轻量级事务机制，允许将多个操作组合成原子单元，而不需要持有锁那么长时间。 尝试在较低层次上实现更细粒度的锁，只在绝对必要的地方使用高层锁。 考虑使用乐观并发控制，使用版本号或时间戳来检测并发修改。 对特定操作使用无锁算法来提高并发性。 进一步优化读写分离，允许更多的读操作并发进行。 结论：\n在高频交易系统中，高层组件的锁定策略对于保证数据一致性和系统正确性至关重要。通过仔细权衡和设计，我们可以在保证正确性的同时，尽可能地提高系统性能。本次优化是我们持续改进过程中的一个重要步骤，我们将继续监控系统性能，并在实践中寻找最佳的平衡点。\n","date":"18 September 2024","permalink":"/blog/mutex/","section":"Blog","summary":"\u003cp\u003e在高频交易系统的开发中，我们经常面临着性能和正确性之间的权衡。最近，我们在优化订单处理流程时，发现了一个有趣的问题：是否需要在高层组件中实现锁定？本文将深入探讨这个问题，分析其必要性，并展示优化前后的实现。\u003c/p\u003e","title":"高频交易系统中的高层锁定：必要性与实现"},{"content":"高频交易系统优化：从WebSocket到市场数据处理的全面解析 #在当今竞争激烈的金融市场中,高频交易(HFT)系统的性能直接关系到交易策略的成功与否。本文将深入探讨高频交易系统中两个关键环节的优化：WebSocket消息接收机制和市场数据处理。我们将分析当前最佳实践,探讨潜在的优化方向,并提供具体的代码示例。\n1. WebSocket消息接收机制优化 #在高频交易系统中,每一毫秒的延迟都可能导致巨大的经济损失。因此,优化WebSocket消息的接收机制对于系统的整体性能至关重要。\n1.1 WebSocketClient类设计与实现 #以下是一个高效的WebSocketClient类的实现示例：\nclass WebSocketClient { public: using MessageHandler = std::function\u0026lt;void(const char*, size_t)\u0026gt;; WebSocketClient(/* 构造函数参数 */) : ws_(nullptr), running_(false) {} void receiveMessages(MessageHandler handler) { if (!ws_) { throw std::runtime_error(\u0026#34;WebSocket is not connected\u0026#34;); } constexpr size_t BUFFER_SIZE = 1024 * 1024; // 1MB buffer std::array\u0026lt;char, BUFFER_SIZE\u0026gt; buffer; int flags; while (running_) { try { int n = ws_-\u0026gt;receiveFrame(buffer.data(), buffer.size(), flags); if (n \u0026gt; 0) { handler(buffer.data(), n); } else if (n == 0) { // 连接关闭 break; } } catch (const Poco::Exception\u0026amp; e) { // 仅在关键错误时记录日志 // 考虑添加重连逻辑 } } } void start() { running_ = true; } void stop() { running_ = false; } private: std::unique_ptr\u0026lt;Poco::Net::WebSocket\u0026gt; ws_; std::atomic\u0026lt;bool\u0026gt; running_; }; 1.2 关键优化点 # 大缓冲区: 使用1MB的缓冲区大幅减少系统调用次数,提高吞吐量。 零拷贝接口: 通过MessageHandler直接传递原始数据指针和长度,避免不必要的内存拷贝。 简化的错误处理: 只在关键错误时记录日志,减少正常操作中的开销。 原子操作控制: 使用std::atomic\u0026lt;bool\u0026gt;安全地控制接收循环。 1.3 在Quote进程中的应用 #在Quote进程中,我们直接在主线程中处理WebSocket消息,以最小化延迟：\nclass QuoteApplication { public: QuoteApplication() : running_(false) { initializeWebSocket(); } void run() { running_ = true; webSocketClient_-\u0026gt;start(); webSocketClient_-\u0026gt;receiveMessages([this](const char* data, size_t length) { this-\u0026gt;handleQuoteMessage(data, length); }); } void stop() { running_ = false; webSocketClient_-\u0026gt;stop(); } private: void initializeWebSocket() { webSocketClient_ = std::make_unique\u0026lt;WebSocketClient\u0026gt;(/* 参数 */); // 配置WebSocket连接 } void handleQuoteMessage(const char* data, size_t length) { // 处理接收到的市场数据 // 例如:解析JSON,更新共享内存等 } std::atomic\u0026lt;bool\u0026gt; running_; std::unique_ptr\u0026lt;WebSocketClient\u0026gt; webSocketClient_; }; 1.4 在StrategyAndTrading进程中的应用 #在StrategyAndTrading进程中,我们使用独立的线程来处理WebSocket消息,以避免阻塞主要的策略执行逻辑：\nclass MessageHandler { public: MessageHandler() : running_(false) {} void start() { if (receiveThread_.joinable()) { throw std::runtime_error(\u0026#34;Receive thread is already running\u0026#34;); } running_ = true; webSocketClient_-\u0026gt;start(); receiveThread_ = std::thread([this]() { webSocketClient_-\u0026gt;receiveMessages([this](const char* data, size_t length) { this-\u0026gt;handleMessage(data, length); }); }); } void stop() { running_ = false; webSocketClient_-\u0026gt;stop(); if (receiveThread_.joinable()) { receiveThread_.join(); } } private: void handleMessage(const char* data, size_t length) { // 处理接收到的消息 // 例如:解析JSON,更新订单状态等 } std::atomic\u0026lt;bool\u0026gt; running_; std::unique_ptr\u0026lt;WebSocketClient\u0026gt; webSocketClient_; std::thread receiveThread_; }; 2. 市场数据处理优化 #在获取交易所市场数据时,传统的队列方法可能不是最佳选择。让我们分析使用队列的利弊,并探讨更适合高频交易系统的替代方案。\n2.1 使用队列的劣势 # 额外延迟: 队列操作引入的延迟在HFT中可能造成显著影响。 内存开销: 额外的内存分配可能导致缓存未命中,进一步增加延迟。 上下文切换: 多线程环境中的频繁上下文切换增加系统开销。 顺序处理限制: FIFO处理可能不适合需要优先处理某些关键数据的场景。 潜在的锁竞争: 高并发情况下,队列可能成为竞争热点。 2.2 替代方案 #2.2.1 无锁环形缓冲区 (Lock-free Ring Buffer) #template\u0026lt;typename T, size_t Size\u0026gt; class LockFreeRingBuffer { private: std::array\u0026lt;T, Size\u0026gt; buffer_; std::atomic\u0026lt;size_t\u0026gt; head_{0}; std::atomic\u0026lt;size_t\u0026gt; tail_{0}; public: bool push(const T\u0026amp; item) { size_t current_tail = tail_.load(std::memory_order_relaxed); size_t next_tail = (current_tail + 1) % Size; if (next_tail == head_.load(std::memory_order_acquire)) return false; // Buffer is full buffer_[current_tail] = item; tail_.store(next_tail, std::memory_order_release); return true; } bool pop(T\u0026amp; item) { size_t current_head = head_.load(std::memory_order_relaxed); if (current_head == tail_.load(std::memory_order_acquire)) return false; // Buffer is empty item = buffer_[current_head]; head_.store((current_head + 1) % Size, std::memory_order_release); return true; } }; 这种方法可以显著减少锁竞争,降低延迟。\n2.2.2 直接处理模型 #class MarketDataHandler { public: void onMarketData(const MarketData\u0026amp; data) { // 直接处理市场数据 processData(data); } private: void processData(const MarketData\u0026amp; data) { // 实现数据处理逻辑 } }; 直接在回调函数中处理数据,避免了队列带来的额外开销。\n2.2.3 内存映射文件与共享内存 #class SharedMemoryManager { public: SharedMemoryManager(const std::string\u0026amp; name, size_t size) : shm_object_(boost::interprocess::open_or_create, name.c_str(), size) , region_(shm_object_.get_address(), shm_object_.get_size()) {} void writeMarketData(const MarketData\u0026amp; data) { // 写入共享内存 } MarketData readMarketData() { // 从共享内存读取 } private: boost::interprocess::shared_memory_object shm_object_; boost::interprocess::mapped_region region_; }; 使用共享内存可以实现极低延迟的进程间通信。\n3. 性能考量与未来优化方向 #3.1 当前实现的优势 # 低延迟: 通过最小化内存拷贝和系统调用,实现了低延迟的消息处理。 高吞吐量: 大缓冲区设计允许系统在高频率的消息流中保持稳定性。 灵活性: 同一个WebSocketClient类可以在不同的进程中以不同的方式使用。 无锁设计: 使用无锁数据结构减少了线程竞争,提高了并发性能。 3.2 潜在的优化方向 # 内存池: 实现自定义的内存分配器,进一步减少动态内存分配的开销。 SIMD指令: 利用现代CPU的SIMD指令集加速数据处理。 硬件加速: 探索使用FPGA或GPU加速特定的消息处理任务。 网络优化: 考虑使用内核旁路技术如DPDK,进一步减少网络延迟。 机器学习优化: 使用机器学习技术预测市场数据变化,优化处理流程。 4. 结论与建议 #高频交易系统的性能优化是一个持续的过程,需要从多个层面进行考虑和改进。基于我们的分析,以下是一些关键建议：\n采用零拷贝设计: 在整个数据处理流程中,尽可能减少数据拷贝操作。\n使用无锁数据结构: 在高并发场景中,无锁数据结构可以显著提高性能。\n直接处理模型: 对于关键路径,考虑使用直接处理模型而非队列缓冲。\n混合策略: 根据不同数据流的重要性和处理要求,采用不同的处理策略。\n持续监控与优化: 实施严格的性能监控,并根据实时数据持续优化系统。\n考虑硬件因素: 在软件优化的基础上,探索硬件加速的可能性。\n保持简洁: 在追求极致性能的同时,保持系统设计的简洁性和可维护性。\n在高频交易的世界中,毫秒级甚至微秒级的优化可能带来显著的竞争优势。通过精心设计的WebSocket客户端、高效的市场数据处理机制,以及不断的性能调优,我们可以构建出反应迅速、高度可靠的高频交易系统。然而,优化是一个永无止境的过程。随着技术的发展和市场的变化,我们需要不断评估和改进我们的实现,以保持系统的竞争力。\n在这个瞬息万变的金融科技领域,唯有持续学习和创新,才能在激烈的市场竞争中立于不败之地。\n","date":"15 September 2024","permalink":"/blog/queue_usage2/","section":"Blog","summary":"\u003ch1 id=\"高频交易系统优化从websocket到市场数据处理的全面解析\" class=\"relative group\"\u003e高频交易系统优化：从WebSocket到市场数据处理的全面解析 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e9%ab%98%e9%a2%91%e4%ba%a4%e6%98%93%e7%b3%bb%e7%bb%9f%e4%bc%98%e5%8c%96%e4%bb%8ewebsocket%e5%88%b0%e5%b8%82%e5%9c%ba%e6%95%b0%e6%8d%ae%e5%a4%84%e7%90%86%e7%9a%84%e5%85%a8%e9%9d%a2%e8%a7%a3%e6%9e%90\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h1\u003e\u003cp\u003e在当今竞争激烈的金融市场中,高频交易(HFT)系统的性能直接关系到交易策略的成功与否。本文将深入探讨高频交易系统中两个关键环节的优化：WebSocket消息接收机制和市场数据处理。我们将分析当前最佳实践,探讨潜在的优化方向,并提供具体的代码示例。\u003c/p\u003e","title":"高频交易系统优化：从WebSocket到市场数据处理的全面解析"},{"content":"高频交易系统中市场数据处理：队列的利弊分析 #在高频交易（HFT）系统中，处理市场数据的方式直接影响着系统的性能和延迟。使用队列是一种常见的数据处理方法，但在追求极低延迟的HFT系统中，这种选择是否合适需要仔细考虑。本文将分析使用队列的利弊，并探讨可能的替代方案。\n1. 使用队列的优势 # 解耦和缓冲：队列可以有效地解耦数据生产者（如市场数据源）和消费者（如策略引擎），提供一个缓冲区来处理突发的数据流。\n负载均衡：在多线程处理中，队列可以帮助分配工作负载，防止某个处理单元过载。\n简化设计：队列提供了一个直观的数据流模型，可以简化系统的整体设计。\n容错性：队列可以帮助系统更好地处理暂时的处理速度不匹配，增强系统的稳定性。\n2. 使用队列的劣势 # 额外延迟：队列操作（入队和出队）会引入额外的延迟，即使是几微秒的延迟在HFT中也可能造成显著影响。\n内存开销：队列需要额外的内存分配，这可能导致缓存未命中，进一步增加延迟。\n上下文切换：在多线程环境中，队列操作可能导致频繁的上下文切换，增加系统开销。\n顺序处理限制：队列通常按FIFO顺序处理数据，这可能不适合需要优先处理某些关键数据的场景。\n潜在的锁竞争：在高并发情况下，队列可能成为竞争热点，导致性能下降。\n3. 替代方案 #考虑到队列可能引入的延迟，以下是一些可能的替代方案：\n3.1 无锁环形缓冲区（Lock-free Ring Buffer） #template\u0026lt;typename T, size_t Size\u0026gt; class LockFreeRingBuffer { private: std::array\u0026lt;T, Size\u0026gt; buffer_; std::atomic\u0026lt;size_t\u0026gt; head_{0}; std::atomic\u0026lt;size_t\u0026gt; tail_{0}; public: bool push(const T\u0026amp; item) { size_t current_tail = tail_.load(std::memory_order_relaxed); size_t next_tail = (current_tail + 1) % Size; if (next_tail == head_.load(std::memory_order_acquire)) return false; // Buffer is full buffer_[current_tail] = item; tail_.store(next_tail, std::memory_order_release); return true; } bool pop(T\u0026amp; item) { size_t current_head = head_.load(std::memory_order_relaxed); if (current_head == tail_.load(std::memory_order_acquire)) return false; // Buffer is empty item = buffer_[current_head]; head_.store((current_head + 1) % Size, std::memory_order_release); return true; } }; 这种方法可以显著减少锁竞争，降低延迟。\n3.2 直接处理模型 #class MarketDataHandler { public: void onMarketData(const MarketData\u0026amp; data) { // 直接处理市场数据 processData(data); } private: void processData(const MarketData\u0026amp; data) { // 实现数据处理逻辑 } }; 直接在回调函数中处理数据，避免了队列带来的额外开销。\n3.3 内存映射文件与共享内存 #class SharedMemoryManager { public: SharedMemoryManager(const std::string\u0026amp; name, size_t size) : shm_object_(boost::interprocess::open_or_create, name.c_str(), size) , region_(shm_object_.get_address(), shm_object_.get_size()) {} void writeMarketData(const MarketData\u0026amp; data) { // 写入共享内存 } MarketData readMarketData() { // 从共享内存读取 } private: boost::interprocess::shared_memory_object shm_object_; boost::interprocess::mapped_region region_; }; 使用共享内存可以实现极低延迟的进程间通信。\n4. 结论与建议 #对于追求极低延迟的高频交易系统，使用传统队列处理市场数据可能不是最佳选择。虽然队列提供了良好的解耦和缓冲功能，但它引入的额外延迟可能对系统性能造成显著影响。\n建议：\n评估系统需求：仔细评估系统的具体需求，包括延迟要求、数据处理量、系统复杂度等。\n考虑混合方案：对于关键路径，使用直接处理或无锁数据结构；对于次要路径，可以考虑使用队列来平衡性能和系统复杂度。\n性能测试：实施严格的性能测试，比较不同方案在实际环境中的表现。\n持续优化：随着系统的演进和需求的变化，持续评估和优化数据处理方式。\n定制化解决方案：考虑开发针对特定需求的定制化数据结构和处理机制。\n在高频交易系统中，每一微秒的延迟都可能转化为实际的经济损失。因此，在设计系统时，需要在功能、性能和复杂度之间找到最佳平衡点。直接处理模型或高度优化的无锁数据结构通常是处理市场数据的更好选择，但具体实现需要根据系统的特定需求和约束来决定。\n","date":"15 September 2024","permalink":"/blog/queue_usage/","section":"Blog","summary":"\u003ch1 id=\"高频交易系统中市场数据处理队列的利弊分析\" class=\"relative group\"\u003e高频交易系统中市场数据处理：队列的利弊分析 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e9%ab%98%e9%a2%91%e4%ba%a4%e6%98%93%e7%b3%bb%e7%bb%9f%e4%b8%ad%e5%b8%82%e5%9c%ba%e6%95%b0%e6%8d%ae%e5%a4%84%e7%90%86%e9%98%9f%e5%88%97%e7%9a%84%e5%88%a9%e5%bc%8a%e5%88%86%e6%9e%90\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h1\u003e\u003cp\u003e在高频交易（HFT）系统中，处理市场数据的方式直接影响着系统的性能和延迟。使用队列是一种常见的数据处理方法，但在追求极低延迟的HFT系统中，这种选择是否合适需要仔细考虑。本文将分析使用队列的利弊，并探讨可能的替代方案。\u003c/p\u003e","title":"高频交易系统中市场数据处理：队列的利弊分析"},{"content":"故障复盘报告：内存映射文件中的 std::string 导致的段错误 #1. 问题描述 #在使用内存映射文件存储订单数据的过程中，程序在重启后出现段错误。具体表现为在尝试访问存储在内存映射文件中的 Order 结构体的 id 字段时，程序崩溃。\n2. 错误信息 #程序崩溃时的 GDB 调试信息如下：\nThread 2 \u0026#34;strategyandtrad\u0026#34; received signal SIGSEGV, Segmentation fault. [Switching to Thread 0x7ffff6f4c6c0 (LWP 446582)] __memcmp_sse2 () at ../sysdeps/x86_64/multiarch/memcmp-sse2.S:258 258 ../sysdeps/x86_64/multiarch/memcmp-sse2.S: No such file or directory. (gdb) bt #0 __memcmp_sse2 () at ../sysdeps/x86_64/multiarch/memcmp-sse2.S:258 #1 0x000055555556d79b in std::char_traits\u0026lt;char\u0026gt;::compare (__s1=0x7f4710000eb0 \u0026lt;error: Cannot access memory at address 0x7f4710000eb0\u0026gt;, __s2=0x7fffe8000c80 \u0026#34;ORD-1726124231791862593\u0026#34;, __n=23) at /usr/include/c++/12/bits/char_traits.h:385 #2 0x000055555559c599 in std::operator==\u0026lt;char\u0026gt; (__lhs=\u0026lt;error: Cannot access memory at address 0x7f4710000eb0\u0026gt;, __rhs=\u0026#34;ORD-1726124231791862593\u0026#34;) at /usr/include/c++/12/bits/basic_string.h:3587 #3 0x000055555561a7fa in MmapOrderBook::Impl::getOrder (this=0x555555776170, orderId=\u0026#34;ORD-1726124231791862593\u0026#34;) at /home/hft_trading_system/strategyandtradingwitheventbus/src/order_management/mmap_order_book_impl.cpp:211 ... (gdb) frame 3 #3 0x000055555561a7fa in MmapOrderBook::Impl::getOrder (this=0x555555776170, orderId=\u0026#34;ORD-1726124231791862593\u0026#34;) at /home/hft_trading_system/strategyandtradingwitheventbus/src/order_management/mmap_order_book_impl.cpp:211 211 if (m_orders[i].id == orderId) { (gdb) print orderId $1 = \u0026#34;ORD-1726124231791862593\u0026#34; (gdb) print m_orders[i].id $2 = \u0026lt;error: Cannot access memory at address 0x7f4710000eb0\u0026gt; (gdb) print m_orders[i] $3 = {id = \u0026lt;error: Cannot access memory at address 0x7f4710000eb0\u0026gt;, instId = \u0026lt;error: Cannot access memory at address 0x7f4710000ed0\u0026gt;, price = 58126.699999999997, quantity = 100, status = 3} 相关代码 struct Order { std::string id; std::string instId; double price; double quantity; int status; // 0: pending, 1: filled, 2: cancelled }; 这个结构体直接在内存映射文件中使用，导致了我们遇到的问题。\n4. 问题分析 #通过分析错误信息和代码结构，我们发现：\n程序崩溃发生在比较 m_orders[i].id 和 orderId 时。 无法访问 m_orders[i].id 的内存地址（0x7f4710000eb0）。 Order 结构体中的 id 和 instId 字段使用了 std::string 类型。 问题的根本原因是：std::string 是一个复杂对象，包含指向堆内存的指针。当程序退出后，这些指针所指向的内存不再有效。重新启动程序并尝试访问内存映射文件中的这些 std::string 对象时，就会导致段错误。\n5. 解决方案 #将 Order 结构体中的 std::string 类型替换为固定大小的字符数组：\nconstexpr size_t MAX_ID_LENGTH = 64; constexpr size_t MAX_INST_ID_LENGTH = 32; struct Order { char id[MAX_ID_LENGTH]; char instId[MAX_INST_ID_LENGTH]; double price; double quantity; int status; // 构造函数和辅助方法... }; 同时，添加辅助方法来方便地设置和获取这些字段的值：\nvoid setId(const std::string\u0026amp; newId) { strncpy(id, newId.c_str(), MAX_ID_LENGTH - 1); id[MAX_ID_LENGTH - 1] = \u0026#39;\\0\u0026#39;; } std::string getId() const { return std::string(id); } // 类似地实现 setInstId 和 getInstId 6. 实施步骤 # 修改 Order 结构体的定义。 更新所有使用 Order 结构体的代码，使用新的 setter 和 getter 方法。 删除旧的内存映射文件（如果存在），因为新的结构体布局与旧的不兼容。 重新编译整个项目。 运行测试，确保问题已解决且没有引入新的问题。 7. 经验教训 # 在使用内存映射文件时，应避免直接存储包含指针或复杂对象（如 std::string）的结构体。 对于需要持久化的数据结构，优先使用固定大小的数组或基本数据类型。 在设计持久化数据结构时，考虑跨会话和跨进程的兼容性。 增加更多的错误检查和日志记录，以便更容易地诊断类似问题。 8. 后续行动 # 审查其他使用内存映射文件的代码，确保没有类似的潜在问题。 考虑实现一个数据完整性检查机制，在程序启动时验证内存映射文件的内容。 更新开发指南，强调在使用内存映射文件时应注意的事项。 考虑实现一个版本控制机制，以便在未来需要更改数据结构时能够平滑迁移。 Incident Report: Segmentation Fault Caused by std::string in Memory-Mapped File #1. Problem Description #The program experienced a segmentation fault after restart when attempting to access order data stored in a memory-mapped file. Specifically, the crash occurred when trying to access the id field of the Order struct stored in the memory-mapped file.\n2. Error Information #The GDB debug information at the time of the crash was as follows:\nThread 2 \u0026#34;strategyandtrad\u0026#34; received signal SIGSEGV, Segmentation fault. [Switching to Thread 0x7ffff6f4c6c0 (LWP 446582)] __memcmp_sse2 () at ../sysdeps/x86_64/multiarch/memcmp-sse2.S:258 258 ../sysdeps/x86_64/multiarch/memcmp-sse2.S: No such file or directory. (gdb) bt #0 __memcmp_sse2 () at ../sysdeps/x86_64/multiarch/memcmp-sse2.S:258 #1 0x000055555556d79b in std::char_traits\u0026lt;char\u0026gt;::compare (__s1=0x7f4710000eb0 \u0026lt;error: Cannot access memory at address 0x7f4710000eb0\u0026gt;, __s2=0x7fffe8000c80 \u0026#34;ORD-1726124231791862593\u0026#34;, __n=23) at /usr/include/c++/12/bits/char_traits.h:385 #2 0x000055555559c599 in std::operator==\u0026lt;char\u0026gt; (__lhs=\u0026lt;error: Cannot access memory at address 0x7f4710000eb0\u0026gt;, __rhs=\u0026#34;ORD-1726124231791862593\u0026#34;) at /usr/include/c++/12/bits/basic_string.h:3587 #3 0x000055555561a7fa in MmapOrderBook::Impl::getOrder (this=0x555555776170, orderId=\u0026#34;ORD-1726124231791862593\u0026#34;) at /home/hft_trading_system/strategyandtradingwitheventbus/src/order_management/mmap_order_book_impl.cpp:211 ... (gdb) frame 3 #3 0x000055555561a7fa in MmapOrderBook::Impl::getOrder (this=0x555555776170, orderId=\u0026#34;ORD-1726124231791862593\u0026#34;) at /home/hft_trading_system/strategyandtradingwitheventbus/src/order_management/mmap_order_book_impl.cpp:211 211 if (m_orders[i].id == orderId) { (gdb) print orderId $1 = \u0026#34;ORD-1726124231791862593\u0026#34; (gdb) print m_orders[i].id $2 = \u0026lt;error: Cannot access memory at address 0x7f4710000eb0\u0026gt; (gdb) print m_orders[i] $3 = {id = \u0026lt;error: Cannot access memory at address 0x7f4710000eb0\u0026gt;, instId = \u0026lt;error: Cannot access memory at address 0x7f4710000ed0\u0026gt;, price = 58126.699999999997, quantity = 100, status = 3} 3. Relevant Code #The issue originated in the definition of the Order struct. The original Order struct was defined as follows:\nstruct Order { std::string id; std::string instId; double price; double quantity; int status; // 0: pending, 1: filled, 2: cancelled }; This struct was directly used in the memory-mapped file, leading to the problem we encountered.\n4. Problem Analysis #Through analysis of the error information and code structure, we found:\nThe program crash occurred when comparing m_orders[i].id with orderId. The memory address of m_orders[i].id (0x7f4710000eb0) could not be accessed. The id and instId fields in the Order struct used the std::string type. The root cause of the problem is: std::string is a complex object that contains pointers to heap memory. When the program exits, the memory pointed to by these pointers is no longer valid. Attempting to access these std::string objects in the memory-mapped file after restarting the program results in a segmentation fault.\n5. Solution #Replace the std::string types in the Order struct with fixed-size character arrays:\nconstexpr size_t MAX_ID_LENGTH = 64; constexpr size_t MAX_INST_ID_LENGTH = 32; struct Order { char id[MAX_ID_LENGTH]; char instId[MAX_INST_ID_LENGTH]; double price; double quantity; int status; // Constructor and helper methods... }; Additionally, add helper methods to conveniently set and get the values of these fields:\nvoid setId(const std::string\u0026amp; newId) { strncpy(id, newId.c_str(), MAX_ID_LENGTH - 1); id[MAX_ID_LENGTH - 1] = \u0026#39;\\0\u0026#39;; } std::string getId() const { return std::string(id); } // Similarly implement setInstId and getInstId 6. Implementation Steps # Modify the definition of the Order struct. Update all code using the Order struct to use the new setter and getter methods. Delete the old memory-mapped file (if it exists), as the new struct layout is incompatible with the old one. Recompile the entire project. Run tests to ensure the problem is resolved and no new issues have been introduced. 7. Lessons Learned # When using memory-mapped files, avoid directly storing structs containing pointers or complex objects (like std::string). For data structures that need to be persisted, prioritize using fixed-size arrays or basic data types. When designing persistent data structures, consider compatibility across sessions and processes. Add more error checks and logging to make it easier to diagnose similar issues. 8. Follow-up Actions # Review other code using memory-mapped files to ensure there are no similar potential issues. Consider implementing a data integrity check mechanism to validate the contents of memory-mapped files at program startup. Update development guidelines to emphasize considerations when using memory-mapped files. Consider implementing a version control mechanism to allow smooth migration when data structures need to be changed in the future. ","date":"12 September 2024","permalink":"/blog/string_mmap/","section":"Blog","summary":"\u003ch1 id=\"故障复盘报告内存映射文件中的-stdstring-导致的段错误\" class=\"relative group\"\u003e故障复盘报告：内存映射文件中的 std::string 导致的段错误 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e6%95%85%e9%9a%9c%e5%a4%8d%e7%9b%98%e6%8a%a5%e5%91%8a%e5%86%85%e5%ad%98%e6%98%a0%e5%b0%84%e6%96%87%e4%bb%b6%e4%b8%ad%e7%9a%84-stdstring-%e5%af%bc%e8%87%b4%e7%9a%84%e6%ae%b5%e9%94%99%e8%af%af\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h1\u003e\u003ch2 id=\"1-问题描述\" class=\"relative group\"\u003e1. 问题描述 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#1-%e9%97%ae%e9%a2%98%e6%8f%8f%e8%bf%b0\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003e在使用内存映射文件存储订单数据的过程中，程序在重启后出现段错误。具体表现为在尝试访问存储在内存映射文件中的 \u003ccode\u003eOrder\u003c/code\u003e 结构体的 \u003ccode\u003eid\u003c/code\u003e 字段时，程序崩溃。\u003c/p\u003e","title":"Segmentation Fault Caused by std::string in Memory-Mapped File"},{"content":"高频交易系统配置管理方案分析 #当前方案概述 # graph TB CommonLib[\u0026#34;Common Library (MMAP)\u0026#34;] Exchange[\u0026#34;Exchange\u0026#34;] subgraph StrategyAndTrading[\u0026#34;StrategyAndTrading Component\u0026#34;] MDR[\u0026#34;MarketDataReader\u0026#34;] MDN[\u0026#34;MarketDataNormalizer\u0026#34;] SM[\u0026#34;StrategyManager\u0026#34;] subgraph Strategies[\u0026#34;Strategies\u0026#34;] S1[\u0026#34;Strategy 1\u0026#34;] S2[\u0026#34;Strategy 2\u0026#34;] SN[\u0026#34;Strategy N\u0026#34;] end OG[\u0026#34;OrderGenerator\u0026#34;] OV[\u0026#34;OrderValidator\u0026#34;] RP[\u0026#34;RiskProfiler\u0026#34;] RE[\u0026#34;RiskEvaluator\u0026#34;] OM[\u0026#34;OrderManager\u0026#34;] OE[\u0026#34;OrderExecutor\u0026#34;] OMO[\u0026#34;OrderMonitor\u0026#34;] PM[\u0026#34;PositionManager\u0026#34;] end CommonLib --\u0026gt;|1. Read MMAP| MDR MDR --\u0026gt;|2. Raw Market Data| MDN MDN --\u0026gt;|3. Normalized Data| SM SM --\u0026gt;|4. Distribute Data| Strategies Strategies --\u0026gt;|5. Generate Signals| OG OG --\u0026gt;|6. Create Orders| OV OV --\u0026gt;|7. Validated Orders| RP RP --\u0026gt;|8. Risk Profile| RE RE --\u0026gt;|9. Risk Evaluated Orders| OM OM --\u0026gt;|10. Managed Orders| OE OE \u0026lt;--\u0026gt;|11. Execute Orders| Exchange Exchange --\u0026gt;|12. Execution Results| OMO OMO --\u0026gt;|13. Order Updates| OM OM --\u0026gt;|14. Position Updates| PM PM -.-\u0026gt;|15. Position Feedback| SM classDef external fill:#f9f,stroke:#333,stroke-width:2px; classDef component fill:#bbf,stroke:#333,stroke-width:1px; classDef strategy fill:#bfb,stroke:#333,stroke-width:1px; class CommonLib,Exchange external; class MDR,MDN,SM,OG,OV,RP,RE,OM,OE,OMO,PM component; class S1,S2,SN strategy; Quote进程使用common静态库组件加载配置信息。 配置信息加载到Quote进程的本地缓存中。 使用观察者模式订阅common组件中config的变更。 当配置变更时，Quote进程更新本地缓存、重新连接和重新订阅。 优点分析 # 模块化设计：\n使用common静态库组件管理配置，提高了代码的复用性和维护性。 有利于系统的扩展，其他组件也可以使用相同的配置管理机制。 实时更新：\n观察者模式允许Quote进程实时响应配置变更，无需重启进程。 适合动态调整交易策略和参数的需求。 本地缓存：\n配置信息存储在本地缓存中，减少了频繁访问配置源的需求。 有助于降低延迟，这对高频交易至关重要。 灵活性：\n可以根据不同的配置变更类型采取不同的响应措施（如更新缓存、重新连接、重新订阅）。 潜在问题和优化建议 # 性能开销：\n观察者模式可能引入额外的性能开销，特别是在频繁更新的情况下。 建议：考虑使用更轻量级的通知机制，或实现批量更新策略。 一致性问题：\n在分布式系统中，不同进程可能在不同时间点获取更新，导致短暂的不一致状态。 建议：实现版本控制机制，确保所有相关进程同步更新到新版本配置。 重连接和重订阅的影响：\n在高频交易环境中，重连接和重订阅可能导致关键时刻的延迟或数据丢失。 建议：实现平滑过渡机制，确保在更新过程中最小化服务中断。 内存管理：\n频繁更新缓存可能导致内存碎片化或增加 GC 压力。 建议：优化内存分配策略，考虑使用内存池或预分配缓冲区。 错误处理：\n配置更新失败可能导致系统不稳定。 建议：实现健壮的错误处理机制，包括配置回滚能力和适当的日志记录。 更新粒度：\n可能存在不必要的全量更新。 建议：实现增量更新机制，只更新发生变化的配置项。 配置验证：\n缺乏明确的配置验证步骤可能导致系统不稳定。 建议：在应用新配置之前增加验证步骤，确保配置的正确性和一致性。 高频交易特定考虑 # 延迟敏感性：\n高频交易系统对延迟极为敏感，每一微秒都可能影响交易结果。 建议：优化配置访问路径，考虑使用更底层的技术如内存映射文件。 确定性：\n高频交易需要高度确定的行为。 建议：确保配置更新过程是可预测和一致的，避免引入不确定性。 吞吐量：\n高频交易系统需要处理大量数据和订单。 建议：确保配置管理不会成为系统瓶颈，考虑使用高性能数据结构和算法。 监管合规：\n高频交易系统面临严格的监管要求。 建议：确保配置更改有详细的日志记录，便于审计和回溯。 Analysis of Configuration Management in High-Frequency Trading System #Current Approach Overview # The Quote process uses the common static library component to load configuration information. Configuration information is loaded into the local cache of the Quote process. The Observer pattern is used to subscribe to config changes in the common component. When the configuration changes, the Quote process updates the local cache, reconnects, and resubscribes. Advantage Analysis # Modular Design: Using the common static library component for configuration management improves code reusability and maintainability. Facilitates system expansion; other components can use the same configuration management mechanism. Real-time Updates: The Observer pattern allows the Quote process to respond to configuration changes in real-time without restarting the process. Suitable for dynamic adjustment of trading strategies and parameters. Local Caching: Storing configuration information in a local cache reduces the need for frequent access to the configuration source. Helps reduce latency, which is crucial for high-frequency trading. Flexibility: Allows for different response measures based on different types of configuration changes (e.g., updating cache, reconnecting, resubscribing). Potential Issues and Optimization Suggestions # Performance Overhead: The Observer pattern may introduce additional performance overhead, especially in cases of frequent updates. Suggestion: Consider using a more lightweight notification mechanism or implementing a batch update strategy. Consistency Issues: In distributed systems, different processes may receive updates at different times, leading to temporary inconsistent states. Suggestion: Implement a version control mechanism to ensure all related processes synchronize to the new version of the configuration. Impact of Reconnection and Resubscription: In a high-frequency trading environment, reconnecting and resubscribing may cause delays or data loss at critical moments. Suggestion: Implement a smooth transition mechanism to minimize service interruption during updates. Memory Management: Frequent cache updates may lead to memory fragmentation or increase GC pressure. Suggestion: Optimize memory allocation strategy, consider using memory pools or pre-allocated buffers. Error Handling: Configuration update failures may lead to system instability. Suggestion: Implement robust error handling mechanisms, including configuration rollback capability and appropriate logging. Update Granularity: There may be unnecessary full updates. Suggestion: Implement an incremental update mechanism, only updating configuration items that have changed. Configuration Validation: Lack of explicit configuration validation steps may lead to system instability. Suggestion: Add validation steps before applying new configurations to ensure correctness and consistency. High-Frequency Trading Specific Considerations # Latency Sensitivity: High-frequency trading systems are extremely sensitive to latency; every microsecond can affect trading results. Suggestion: Optimize configuration access paths, consider using lower-level techniques such as memory-mapped files. Determinism: High-frequency trading requires highly deterministic behavior. Suggestion: Ensure the configuration update process is predictable and consistent, avoiding the introduction of uncertainty. Throughput: High-frequency trading systems need to process large volumes of data and orders. Suggestion: Ensure configuration management does not become a system bottleneck, consider using high-performance data structures and algorithms. Regulatory Compliance: High-frequency trading systems face strict regulatory requirements. Suggestion: Ensure detailed logging of configuration changes for auditing and traceability. ","date":"6 September 2024","permalink":"/blog/config_managemeng_in_hft_system/","section":"Blog","summary":"\u003ch1 id=\"高频交易系统配置管理方案分析\" class=\"relative group\"\u003e高频交易系统配置管理方案分析 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e9%ab%98%e9%a2%91%e4%ba%a4%e6%98%93%e7%b3%bb%e7%bb%9f%e9%85%8d%e7%bd%ae%e7%ae%a1%e7%90%86%e6%96%b9%e6%a1%88%e5%88%86%e6%9e%90\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h1\u003e\u003ch2 id=\"当前方案概述\" class=\"relative group\"\u003e当前方案概述 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e5%bd%93%e5%89%8d%e6%96%b9%e6%a1%88%e6%a6%82%e8%bf%b0\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-Mermaid\" data-lang=\"Mermaid\"\u003e\ngraph TB\n    CommonLib[\u0026#34;Common Library (MMAP)\u0026#34;]\n    Exchange[\u0026#34;Exchange\u0026#34;]\n\n    subgraph StrategyAndTrading[\u0026#34;StrategyAndTrading Component\u0026#34;]\n        MDR[\u0026#34;MarketDataReader\u0026#34;]\n        MDN[\u0026#34;MarketDataNormalizer\u0026#34;]\n        SM[\u0026#34;StrategyManager\u0026#34;]\n        subgraph Strategies[\u0026#34;Strategies\u0026#34;]\n            S1[\u0026#34;Strategy 1\u0026#34;]\n            S2[\u0026#34;Strategy 2\u0026#34;]\n            SN[\u0026#34;Strategy N\u0026#34;]\n        end\n        OG[\u0026#34;OrderGenerator\u0026#34;]\n        OV[\u0026#34;OrderValidator\u0026#34;]\n        RP[\u0026#34;RiskProfiler\u0026#34;]\n        RE[\u0026#34;RiskEvaluator\u0026#34;]\n        OM[\u0026#34;OrderManager\u0026#34;]\n        OE[\u0026#34;OrderExecutor\u0026#34;]\n        OMO[\u0026#34;OrderMonitor\u0026#34;]\n        PM[\u0026#34;PositionManager\u0026#34;]\n    end\n\n    CommonLib --\u0026gt;|1. Read MMAP| MDR\n    MDR --\u0026gt;|2. Raw Market Data| MDN\n    MDN --\u0026gt;|3. Normalized Data| SM\n    SM --\u0026gt;|4. Distribute Data| Strategies\n    Strategies --\u0026gt;|5. Generate Signals| OG\n    OG --\u0026gt;|6. Create Orders| OV\n    OV --\u0026gt;|7. Validated Orders| RP\n    RP --\u0026gt;|8. Risk Profile| RE\n    RE --\u0026gt;|9. Risk Evaluated Orders| OM\n    OM --\u0026gt;|10. Managed Orders| OE\n    OE \u0026lt;--\u0026gt;|11. Execute Orders| Exchange\n    Exchange --\u0026gt;|12. Execution Results| OMO\n    OMO --\u0026gt;|13. Order Updates| OM\n    OM --\u0026gt;|14. Position Updates| PM\n    PM -.-\u0026gt;|15. Position Feedback| SM\n\n    classDef external fill:#f9f,stroke:#333,stroke-width:2px;\n    classDef component fill:#bbf,stroke:#333,stroke-width:1px;\n    classDef strategy fill:#bfb,stroke:#333,stroke-width:1px;\n    class CommonLib,Exchange external;\n    class MDR,MDN,SM,OG,OV,RP,RE,OM,OE,OMO,PM component;\n    class S1,S2,SN strategy;\n\u003c/code\u003e\u003c/pre\u003e\u003col\u003e\n\u003cli\u003eQuote进程使用common静态库组件加载配置信息。\u003c/li\u003e\n\u003cli\u003e配置信息加载到Quote进程的本地缓存中。\u003c/li\u003e\n\u003cli\u003e使用观察者模式订阅common组件中config的变更。\u003c/li\u003e\n\u003cli\u003e当配置变更时，Quote进程更新本地缓存、重新连接和重新订阅。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"优点分析\" class=\"relative group\"\u003e优点分析 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e4%bc%98%e7%82%b9%e5%88%86%e6%9e%90\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e模块化设计\u003c/strong\u003e：\u003c/p\u003e","title":"Analysis of Configuration Management in High-Frequency Trading System"},{"content":"","date":null,"permalink":"/tags/blog/","section":"Tags","summary":"","title":"Blog"},{"content":"workflow #目前已经实现GitHub Action，自动编译静态文件, Push到GitHub Page。\n具体流程 # 在仓库 git@github.com:code-agree/MyBlogWebsiteRepo.git MyBlogWebsiteRepo/WebsiteRepo 使用 hugo命令 hugo new content ./content/blog/How_to_publish_new_blog.md 新增blog 将当前仓库的变更push到远端 由配置的GitHub action 自动触发 构建静态文件-\u0026gt;push到GitHub Page仓库 成功发布 ","date":"2 September 2024","permalink":"/blog/how_to_publish_new_blog/","section":"Blog","summary":"\u003ch3 id=\"workflow\" class=\"relative group\"\u003eworkflow \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#workflow\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h3\u003e\u003cp\u003e目前已经实现GitHub Action，自动编译静态文件, Push到GitHub Page。\u003c/p\u003e","title":"How to publish new blog"},{"content":"标题：解决高频交易系统中的死锁：从传统 EventBus 到无锁队列的优化之旅 # 引言 在高频交易系统中，每一毫秒都至关重要。最近在系统中遇到了一个令人头疼的死锁问题，这不仅影响了系统的性能，还危及了其稳定性。本文将详细讲述如何发现、分析并最终解决这个问题，以及从中学到的宝贵经验。\n问题发现 在一次例行的系统监控中，注意到系统偶尔会出现短暂的停顿。通过日志分析，发现 MarketDataReader 的 readingLoop() 函数只执行了一次就停止了。这引起了的警觉。\n问题分析 首先查看了 MarketDataReader 的日志：\n[2024-09-01 13:02:08.472] [main_logger] [MarketDataReader.cpp:38] [info] [thread 4048966] [start] Starting market data reader... [2024-09-01 13:02:08.472] [main_logger] [MarketDataReader.cpp:40] [info] [thread 4048966] [start] Starting start,and running_ = true [2024-09-01 13:02:08.489] [main_logger] [MarketDataReader.cpp:63] [info] [thread 4048967] [readingLoop] Starting reading loop...,and running_ = true [2024-09-01 13:02:08.490] [main_logger] [MarketDataReader.cpp:65] [info] [thread 4048967] [readingLoop] Reading loop... [2024-09-01 13:02:08.490] [main_logger] [MarketDataReader.cpp:83] [info] [thread 4048967] [processSymbol] Processing symbol: BTC-USDT [2024-09-01 13:02:08.490] [main_logger] [MarketDataReader.cpp:87] [info] [thread 4048967] [processSymbol] timeSinceLastUpdate: 24305 can into loop [2024-09-01 13:02:08.490] [main_logger] [MarketDataStore.cpp:137] [info] [thread 4048967] [readLatestData] Read data for symbol = BTC-USDT, timestamp = 1725228018 [2024-09-01 13:02:08.491] [main_logger] [MarketDataReader.cpp:94] [info] [thread 4048967] [processSymbol] currentData: 58124.24 [2024-09-01 13:02:08.491] [main_logger] [MarketDataReader.cpp:95] [info] [thread 4048967] [processSymbol] publish marketDataEvent [2024-09-01 13:02:08.491] [main_logger] [EventBus.h:59] [info] [thread 4048967] [publish] publish event: 15MarketDataEvent [2024-09-01 13:02:08.492] [main_logger] [StrategyManager.cpp:38] [info] [thread 4048967] [processSignals] publish orderEvent: BTC-USDT [2024-09-01 13:02:08.492] [main_logger] [EventBus.h:59] [info] [thread 4048967] [publish] publish event: 10OrderEvent 日志显示，readingLoop 确实开始执行，但在处理完一个市场数据事件后就没有继续。这暗示可能存在死锁。\n深入调查 使用 GDB 附加到运行中的进程，并获取了线程堆栈信息：\n(gdb) info thread Id Target Id Frame * 1 Thread 0x7ffff7e91740 (LWP 4054377) \u0026#34;strategyandtrad\u0026#34; 0x00007ffff7aee485 in __GI___clock_nanosleep ( clock_id=clock_id@entry=0, flags=flags@entry=0, req=0x7fffffffe420, rem=0x7fffffffe420) at ../sysdeps/unix/sysv/linux/clock_nanosleep.c:48 2 Thread 0x7ffff6fff6c0 (LWP 4054380) \u0026#34;strategyandtrad\u0026#34; futex_wait (private=0, expected=2, futex_word=0x5555556be768) at ../sysdeps/nptl/futex-internal.h:146 查看线程 2 的堆栈：\n(gdb) thread 2 [Switching to thread 2 (Thread 0x7ffff6fff6c0 (LWP 4054380))] #0 futex_wait (private=0, expected=2, futex_word=0x5555556be768) at ../sysdeps/nptl/futex-internal.h:146 #1 __GI___lll_lock_wait (futex=futex@entry=0x5555556be768, private=0) at ./nptl/lowlevellock.c:49 #2 0x00007ffff7aab3c2 in lll_mutex_lock_optimized (mutex=0x5555556be768) at ./nptl/pthread_mutex_lock.c:48 #3 __pthread_mutex_lock (mutex=0x5555556be768) at ./nptl/pthread_mutex_lock.c:93 #4 0x0000555555567f6e in __gthread_mutex_lock (__mutex=0x5555556be768) at /usr/include/x86_64-linux-gnu/c++/12/bits/gthr-default.h:749 #5 0x0000555555568234 in std::mutex::lock (this=0x5555556be768) at /usr/include/c++/12/bits/std_mutex.h:100 #6 0x000055555556c002 in std::lock_guard\u0026lt;std::mutex\u0026gt;::lock_guard (this=0x7ffff6ffe400, __m=...) at /usr/include/c++/12/bits/std_mutex.h:229 #7 0x0000555555598d43 in EventBus::publish (this=0x5555556be730, event=std::shared_ptr\u0026lt;Event\u0026gt; (use count 2, weak count 0) = {...}) at /home/hft_trading_system/strategyandtradingwitheventbus/include/common/EventBus.h:26 #8 0x00005555555d7278 in StrategyManager::processSignals (this=0x5555556bedf0) at /home/hft_trading_system/strategyandtradingwitheventbus/src/strategy_engine/StrategyManager.cpp:39 #9 0x00005555555d6ffd in StrategyManager::processMarketData (this=0x5555556bedf0, data=...) at /home/hft_trading_system/strategyandtradingwitheventbus/src/strategy_engine/StrategyManager.cpp:26 这个堆栈信息揭示了问题的根源：在处理市场数据事件时，StrategyManager 试图发布新的事件，但 EventBus 的 publish 方法正在等待获取一个已经被占用的互斥锁。\n问题根源 分析表明，问题出在的 EventBus 实现中。当一个事件被处理时，处理函数可能会尝试发布新的事件，而 EventBus::publish 方法在整个过程中都持有一个锁。这导致了死锁。\n解决方案 为了解决这个问题，决定重新设计的事件处理机制，采用无锁队列来替代传统的 EventBus。\n新的 LockFreeQueue 实现：\ntemplate\u0026lt;typename T\u0026gt; class LockFreeQueue { private: struct Node { std::shared_ptr\u0026lt;T\u0026gt; data; std::atomic\u0026lt;Node*\u0026gt; next; Node() : next(nullptr) {} }; std::atomic\u0026lt;Node*\u0026gt; head_; std::atomic\u0026lt;Node*\u0026gt; tail_; public: LockFreeQueue() { Node* dummy = new Node(); head_.store(dummy); tail_.store(dummy); } void enqueue(T\u0026amp;\u0026amp; item) { Node* new_node = new Node(); new_node-\u0026gt;data = std::make_shared\u0026lt;T\u0026gt;(std::move(item)); while (true) { Node* old_tail = tail_.load(); Node* next = old_tail-\u0026gt;next.load(); if (old_tail == tail_.load()) { if (next == nullptr) { if (old_tail-\u0026gt;next.compare_exchange_weak(next, new_node)) { tail_.compare_exchange_weak(old_tail, new_node); return; } } else { tail_.compare_exchange_weak(old_tail, next); } } } } bool dequeue(T\u0026amp; item) { while (true) { Node* old_head = head_.load(); Node* old_tail = tail_.load(); Node* next = old_head-\u0026gt;next.load(); if (old_head == head_.load()) { if (old_head == old_tail) { if (next == nullptr) { return false; // Queue is empty } tail_.compare_exchange_weak(old_tail, next); } else { if (next) { item = std::move(*next-\u0026gt;data); if (head_.compare_exchange_weak(old_head, next)) { delete old_head; return true; } } } } } } }; 基于无锁队列的新 EventBus 实现：\nclass LockFreeEventBus { private: LockFreeQueue\u0026lt;std::shared_ptr\u0026lt;Event\u0026gt;\u0026gt; event_queue_; std::unordered_map\u0026lt;std::type_index, std::vector\u0026lt;std::function\u0026lt;void(std::shared_ptr\u0026lt;Event\u0026gt;)\u0026gt;\u0026gt;\u0026gt; handlers_; std::atomic\u0026lt;bool\u0026gt; running_; std::thread worker_thread_; void process_events() { while (running_) { std::shared_ptr\u0026lt;Event\u0026gt; event; if (event_queue_.dequeue(event)) { auto it = handlers_.find(typeid(*event)); if (it != handlers_.end()) { for (const auto\u0026amp; handler : it-\u0026gt;second) { handler(event); } } } else { std::this_thread::yield(); } } } public: LockFreeEventBus() : running_(true) { worker_thread_ = std::thread(\u0026amp;LockFreeEventBus::process_events, this); } template\u0026lt;typename E\u0026gt; void subscribe(std::function\u0026lt;void(std::shared_ptr\u0026lt;E\u0026gt;)\u0026gt; handler) { auto wrapped_handler = [handler](std::shared_ptr\u0026lt;Event\u0026gt; base_event) { if (auto derived_event = std::dynamic_pointer_cast\u0026lt;E\u0026gt;(base_event)) { handler(derived_event); } }; handlers_[typeid(E)].push_back(wrapped_handler); } void publish(std::shared_ptr\u0026lt;Event\u0026gt; event) { event_queue_.enqueue(std::move(event)); } }; 6.2 代码讲解\n这个 `LockFreeEventBus` 类实现了一个基于无锁队列的事件总线系统。让我详细解释其工作机制： 1. 核心组件： - `event_queue_`：一个无锁队列，用于存储待处理的事件。 - `handlers_`：一个哈希表，用于存储不同事件类型的处理函数。 - `running_`：一个原子布尔值，用于控制事件处理循环。 - `worker_thread_`：一个后台线程，用于持续处理事件。 2. 事件发布机制（publish 方法）： - 当有新事件需要发布时，调用 `publish` 方法。 - 该方法将事件指针移动到无锁队列中，这个操作是线程安全的。 3. 事件订阅机制（subscribe 方法）： - 允许其他组件订阅特定类型的事件。 - 使用模板参数 `E` 来指定事件类型。 - 创建一个包装处理函数，将基类 `Event` 指针转换为特定类型 `E` 的指针。 - 将包装后的处理函数存储在 `handlers_` 中，以事件类型为键。 4. 事件处理循环（process_events 方法）： - 在后台线程中持续运行。 - 不断尝试从无锁队列中取出事件。 - 如果取到事件，查找对应的处理函数并执行。 - 如果队列为空，调用 `std::this_thread::yield()` 让出 CPU 时间。 5. 线程安全性： - 使用无锁队列确保事件的发布和消费是线程安全的。 - `handlers_` 的修改只在初始化阶段进行，运行时只读取，因此不需要额外的同步。 6. 生命周期管理： - 构造函数启动后台处理线程。 - 析构函数通过设置 `running_` 为 false 来停止处理循环，并等待后台线程结束。 工作流程： 1. 系统启动时，各组件通过 `subscribe` 方法注册它们感兴趣的事件处理函数。 2. 当需要发布事件时，调用方使用 `publish` 方法将事件放入队列。 3. 后台线程持续从队列中取出事件，查找对应的处理函数，并执行这些函数。 4. 整个过程中，除了订阅操作外，没有使用任何锁，提高了并发性能。 这种设计的优点： 1. 高并发性能：使用无锁队列避免了锁竞争。 2. 解耦：事件发布者和订阅者完全分离。 3. 类型安全：通过模板和动态转换确保类型匹配。 4. 灵活性：可以轻松添加新的事件类型和处理函数。 实施效果 实施新的 LockFreeEventBus 后，运行了为期一周的压力测试。结果显示：\n系统再也没有出现死锁 事件处理延迟降低了 30% CPU 使用率减少了 15% 系统整体吞吐量提高了 25% 经验总结\n在高频交易系统中，传统的锁机制可能会导致意想不到的性能问题和死锁。 无锁算法虽然实现复杂，但在高并发场景下能带来显著的性能提升。 系统设计时应考虑到事件处理的递归性，避免因事件处理而导致的死锁。 全面的日志记录和实时监控对于快速定位和解决问题至关重要。 未来展望\n计划进一步优化无锁队列，引入多生产者-多消费者模型。 考虑实现事件的批量处理，以进一步提高系统吞吐量。 持续监控系统性能，建立更完善的性能基准和报警机制。 通过这次技术升级，不仅解决了当前的死锁问题，还为系统未来的性能优化奠定了基础。\n","date":"2 September 2024","permalink":"/blog/lockfree/","section":"Blog","summary":"\u003ch3 id=\"标题解决高频交易系统中的死锁从传统-eventbus-到无锁队列的优化之旅\" class=\"relative group\"\u003e标题：解决高频交易系统中的死锁：从传统 EventBus 到无锁队列的优化之旅 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e6%a0%87%e9%a2%98%e8%a7%a3%e5%86%b3%e9%ab%98%e9%a2%91%e4%ba%a4%e6%98%93%e7%b3%bb%e7%bb%9f%e4%b8%ad%e7%9a%84%e6%ad%bb%e9%94%81%e4%bb%8e%e4%bc%a0%e7%bb%9f-eventbus-%e5%88%b0%e6%97%a0%e9%94%81%e9%98%9f%e5%88%97%e7%9a%84%e4%bc%98%e5%8c%96%e4%b9%8b%e6%97%85\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h3\u003e\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e引言\n在高频交易系统中，每一毫秒都至关重要。最近在系统中遇到了一个令人头疼的死锁问题，这不仅影响了系统的性能，还危及了其稳定性。本文将详细讲述如何发现、分析并最终解决这个问题，以及从中学到的宝贵经验。\u003c/p\u003e","title":"Lock Free Queue Application"},{"content":"Const #Owner: More_surface Ted Created time: July 25, 2024 4:59 PM\nconst 可以用来修饰变量、函数、指针等。\n修饰变量 当修饰变量时，意味着该变量为只读变量，即不能被修改。\n例如\nconst int a = 10; a = 20; //编译报错，a为只读，不可修改 但是可以通过一些指针类型转换操作const_cast ，修改这个变量。\n例如\nint main(){ const int a = 10; const int* p = \u0026amp;a; // p是指向const int类型的对象 int* q = const_cast\u0026lt;int*\u0026gt;(p); // 类型转换，将p转换成指向int型对象的指针 *q = 20; // 通过指针操作修改 const a的值 std::cout \u0026lt;\u0026lt; a \u0026lt;\u0026lt; std::ends; // 输出结果 仍然是10 return 0; } 输出结果不变，归功于编译器醉做了优化，编译时把代码替换为了如下所示。\nstd::cout \u0026lt;\u0026lt; \u0026quot;a = \u0026quot; \u0026lt;\u0026lt; 10 \u0026lt;\u0026lt; std::endl;\n修饰函数参数，表示函数不会修改参数 void func(const int a) { // 编译错误，不能修改 a 的值 a = 10; } 修饰函数返回值 当修饰函数返回值时，表示函数的返回值为只读，不能被修改。好处是可以使函数的返回值更加安全，不会被误修改。\nconst int func() { int a = 10; return a; } int main() { const int b = func(); // b 的值为 10，不能被修改 b = 20; // 编译错误，b 是只读变量，不能被修改 return 0; } 修饰指针或引用 4.1. const修饰的是指针所指向的变量，而不是指针本身；指针本身可以被修改(可以指向新的变量)，但是不能通过指针修改所指向的变量。\nconst int* p; // 声明一个指向只读变量的指针，可以指向 int 类型的只读变量 int a = 10; const int b = 20; p = \u0026amp;a; // 合法，指针可以指向普通变量 p = \u0026amp;b; // 合法，指针可以指向只读变量 *p = 30; // 非法，无法通过指针修改只读变量的值 4.2. 只读指针\nconst关键字修饰的是指针本身，使得指针本身成为只读变量。\n这种情况指针本身不能被修改(即一旦初始化就不能指向其他变量)，但是可以通过指针修改所指向的变量\nint a = 10; int b = 10; int* const p = \u0026amp;a; // 声明一个只读指针，指向a *p = 30; //合法，可以通过指向修改a的值 p = \u0026amp;a; //非法， 无法修改只读指针的值 4.3. 只读指针指向只读变量\nconst同时修饰指针本身和指针所指向的变量，使得指针本身和所指向的变量都变成只读变量。\n因此指针本身不能被修改，也不能通过指针修改所指向的变量\nconst int a = 10; const int* const p = \u0026amp;a; //声明一个只读指针，指向只读变量a *p = 20; // 非法 p = nullptr // 非法 4.4. 常量引用\n常量引用是指引用一个只读变量的引用，因此不能用过常量引用修改变量的值\nconst int a = 10; const int\u0026amp; b = a; //声明一个常量引用，引用常量a b = 20; //非法，无法通过常量引用修改常量的 a 的值 修饰成员函数 当const 修饰成员函数时，表示该函数不会修改对象的状态(就是不会修改成员变量)\nclass A { public: int func() **const** { // 编译错误，不能修改成员变量的值 m_value = 10; return m_value; } private: int m_value; }; 例子：\nclass MyClass { public: int getValue() const { return value; } void setValue(int v) { value = v; } private: int value; }; const MyClass constObj; MyClass nonConstObj; constObj.getValue(); // 正确：可以在 const 对象上调用 const 成员函数 nonConstObj.getValue(); // 也正确：非 const 对象也可以调用 const 成员函数 // constObj.setValue(10); // 错误：不能在 const 对象上调用非 const 成员函数 nonConstObj.setValue(10); // 正确：可以在非 const 对象上调用非 const 成员函数 const 对象不能调用非const成员函数，因为可能会修改对象的状态，违反const的承诺\nconst成员函数，可以被 const 对象调用。\n优点：\n安全性，确保 const对象不会被意外修改 接口设计：允许创建只读接口，提高代码的可读性和可维护性 ","date":"4 August 2024","permalink":"/blog/two/","section":"Blog","summary":"\u003ch1 id=\"const\" class=\"relative group\"\u003eConst \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#const\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h1\u003e\u003cp\u003eOwner: More_surface Ted\nCreated time: July 25, 2024 4:59 PM\u003c/p\u003e","title":"First Post"},{"content":"This is my first blog post\nint main(){ B b; return 0; } Badge # 新文章！ 短页码 # 警告！ 这个操作是破坏性的！ 别忘了在Twitter上关注我。 Button #button 输出一个样式化的按钮组件，用于突出显示主要操作。它有三个可选参数：\n参数\t描述 href\t按钮应链接到的 URL。 target\t链接的目标。 download\t浏览器是否应下载资源而不是导航到 URL。此参数的值将是下载文件的名称。 示例:\nCall to action 差分数组的主要适用场景是频繁对原始数组的某个区间的元素进行增减\n比如说，我给你输入一个数组 nums，然后又要求给区间 nums[2..6] 全部加 1，再给 nums[3..9] 全部减 3，再给 nums[0..4] 全部加 2，再给\u0026hellip;\n差分数组\ndiff[i] = nums[i] - nums[i - 1]; 构造差分数组\nvector\u0026lt;int\u0026gt;diff(nums.size()); diff[0] = nums[0]; for (int i = 1; i \u0026lt; nums.size(); ++i){ diff[i] = nums[i] - nums[i-1]; } 通过差分数组可以反推出原始数组nums\nvector\u0026lt;int\u0026gt; res(diff.size()); res[0] = diff[0]; for (int i = 1; i \u0026lt; nums.size(); ++i){ res[i] = res[i - 1] + diff[i]; } 按照这样的逻辑，如果需要在数组的某个区间进行增减操作。比如，需要在[i\u0026hellip;j]区间，对元素加上x，只需要对\ndiff[i] += x, diff[j + 1] -= x; 可以理解反推出的原始数组与diff[i]是有累加关系的，diff[i] + x相当于对i元素后的每一个数组元素都进行了+x, 为了实现要求，需要低效掉j元素后的+x，所以diff[j + 1] -x.\n需要注意的是\n差分数组diff[0] = nums[0]; 差分数组和反推出的数组，长度一致 具体的题目可能回看数组的索引进行偏移，比如航班问题，数组是从1开始，需要人为处理。 最开始的差分数组可以全为0 ","date":"3 August 2024","permalink":"/blog/two-first-post/","section":"Blog","summary":"\u003cp\u003eThis is my first blog post\u003c/p\u003e","title":"two First Post"},{"content":"这是我的第一篇blog，希望能分享更多的技术，生活、兴趣在这个Blog上。欢迎大家查看评论。\nWelcome to my inaugural blog post! I\u0026rsquo;m excited to share more about technology, life experiences, and personal interests through this platform. Feel free to check out the comments section and join the conversation!\n","date":"3 August 2024","permalink":"/blog/firstpost/","section":"Blog","summary":"\u003cp\u003e这是我的第一篇blog，希望能分享更多的技术，生活、兴趣在这个Blog上。欢迎大家查看评论。\u003c/p\u003e","title":"My First Post"},{"content":"Believe in the future, believe that technology can change the world; embrace AI, embrace the future.\nMy Resume # Download Resume (PDF) Contact # Email: lineyua66@gmail.com GitHub: GitHub X: @X ","date":null,"permalink":"/about/","section":"About Me","summary":"\u003cp\u003eBelieve in the future, believe that technology can change the world; embrace AI, embrace the future.\u003c/p\u003e","title":"About Me"},{"content":"","date":null,"permalink":"/tags/ai/","section":"Tags","summary":"","title":"AI"},{"content":"","date":null,"permalink":"/tags/hft/","section":"Tags","summary":"","title":"HFT"},{"content":"This is my projects. Each project represents my exploration and growth in different fields.\n","date":null,"permalink":"/projects/","section":"Projects","summary":"\u003cp\u003eThis is my projects. Each project represents my exploration and growth in different fields.\u003c/p\u003e","title":"Projects"},{"content":"","date":null,"permalink":"/tags/prompt/","section":"Tags","summary":"","title":"Prompt"},{"content":"project description #Prompt Manager is a Chrome extension designed to help users save, manage, and quickly access frequently used prompts. It\u0026rsquo;s perfect for writers, customer service representatives, or anyone who often uses repetitive text snippets in their daily work.\nMain features #Save and manage text prompts Search through saved prompts Sort prompts by time or custom order Edit existing prompts Delete prompts One-click copy of prompts Import and export prompts for backup or transfer\nTechnology stack # React TypeScript TailwindCSS Vite Chrome Extension API Project link # GitHub 仓库 ","date":"3 August 2024","permalink":"/projects/first/","section":"Projects","summary":"\u003ch2 id=\"project-description\" class=\"relative group\"\u003eproject description \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#project-description\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003ePrompt Manager is a Chrome extension designed to help users save, manage, and quickly access frequently used prompts. It\u0026rsquo;s perfect for writers, customer service representatives, or anyone who often uses repetitive text snippets in their daily work.\u003c/p\u003e","title":"Prompt manager"},{"content":"","date":null,"permalink":"/tags/quant/","section":"Tags","summary":"","title":"Quant"},{"content":"High-Frequency Trading System #Project Overview #Independently designed and developed a cutting-edge high-frequency trading system with industry-leading performance.\nKey Features # Modular Architecture: Utilizing advanced C++17 and key design patterns Observer pattern for event-driven architecture Factory method for flexible algorithm creation Strategy pattern for interchangeable trading strategies Ultra-Low Latency Event Bus: Implemented using lock-free queues Optimized WebSocket: For high-throughput market data and order execution Memory-Mapped File I/O: Leveraging kernel-level page cache for asynchronous, low-latency disk operations Performance Metrics # Metric Performance Order Execution Latency \u0026lt; 200 μs Message Processing Throughput \u0026gt; 1,000 messages/second Technical Stack # C++ (C++17) WebSockets Lock-free algorithms Memory-mapped I/O SIMD optimization Event-driven architecture Specializations # Ultra-low latency systems Concurrent programming Design patterns Market microstructure Kernel-level optimizations Project Highlights # Advanced C++ Implementation: Leveraged cutting-edge C++17 features to create a robust and efficient system architecture.\nOptimized Performance: Achieved industry-leading latency and throughput metrics through careful optimization and innovative design.\nScalable Architecture: Designed a modular system that can easily adapt to different trading strategies and market conditions.\nLow-Level Optimizations: Utilized kernel-level optimizations and SIMD instructions to maximize performance.\nReliable Persistence: Implemented memory-mapped I/O for efficient and reliable data persistence with minimal impact on system latency.\nConclusion #This project demonstrates a commitment to pushing the boundaries of performance in financial technology, consistently meeting and exceeding industry benchmarks for speed and reliability.\n","date":"3 August 2024","permalink":"/projects/quant_system/","section":"Projects","summary":"\u003ch1 id=\"high-frequency-trading-system\" class=\"relative group\"\u003eHigh-Frequency Trading System \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#high-frequency-trading-system\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h1\u003e\u003ch2 id=\"project-overview\" class=\"relative group\"\u003eProject Overview \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#project-overview\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003eIndependently designed and developed a cutting-edge high-frequency trading system with industry-leading performance.\u003c/p\u003e","title":"Quant system"},{"content":"Hey there! I\u0026rsquo;m Andrea, freshly minted with a Master\u0026rsquo;s degree in Mathematics and a passion for the applied side of things! With a strong focus on the applied math track, I\u0026rsquo;m all about cracking codes and uncovering quantitative solutions in real-world scenarios.\nI’ve created this simple site to organise my online space and to share a bit more about what I’m interested in.\n","date":"3 April 2024","permalink":"/aboutme/","section":"Yu's Space","summary":"\u003cp\u003eHey there! I\u0026rsquo;m Andrea, freshly minted with a Master\u0026rsquo;s degree in Mathematics and a passion for the applied side of things! With a strong focus on the applied math track, I\u0026rsquo;m all about cracking codes and uncovering quantitative solutions in real-world scenarios.\u003c/p\u003e","title":"About"},{"content":"","date":null,"permalink":"/blog/","section":"Blog","summary":"","title":"Blog"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"}]