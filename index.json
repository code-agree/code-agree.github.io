[{"content":"","date":null,"permalink":"/tags/hft-system-design/","section":"Tags","summary":"","title":"HFT System Design"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":null,"permalink":"/","section":"Yu's Space","summary":"","title":"Yu's Space"},{"content":"","date":null,"permalink":"/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","section":"Tags","summary":"","title":"性能优化"},{"content":"高频交易系统优化：从数据读取到系统平衡的思考过程 #1. 初始问题：数据读取效率 #最初，我们关注的是市场数据读取器本身的效率问题。\n1.1 轮询方式（初始状态） #void MarketDataReader::readingLoop() { while (running) { for (const auto\u0026amp; symbol : symbols_) { processSymbol(symbol); } std::this_thread::sleep_for(std::chrono::milliseconds(100)); } } 问题：持续轮询即使在没有新数据时也会消耗资源。\n1.2 条件控制方式 #void MarketDataReader::readingLoop() { while (running) { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(conditionMutex); dataCondition.wait(lock, [this] { return !running || !symbols_.empty(); }); for (const auto\u0026amp; symbol : symbols_) { processSymbol(symbol); } } } 改进：减少了不必要的CPU使用，但可能会在高频数据更新时引入延迟。\n思考转变：这个阶段，我们主要关注如何提高单个组件（数据读取器）的效率。\n2. 扩展考虑：数据读取对其他系统组件的影响 #随着对系统的深入思考，我们开始考虑数据读取器的行为如何影响整个系统，特别是订单流的执行效率。\n2.1 资源竞争问题 #观察：尽管我们优化了数据读取器的效率，但数据读取线程占据太多的计算资源，也会进而影响订单处理的性能。即使在没有新数据可读时，频繁的检查也会占用宝贵的计算资源。\n思考：\n数据读取和订单处理是否在竞争同样的系统资源（CPU、内存、I/O）？ 如何在保证数据及时性的同时，不影响订单处理的响应速度？ 如何协调各个线程，使系统达到最低的时延？ 2.2 自适应间隔机制 #引入动态调整处理间隔的机制，以平衡数据读取和系统资源使用。\nvoid MarketDataReader::readingLoop() { while (running) { auto start = std::chrono::steady_clock::now(); for (const auto\u0026amp; symbol : symbols_) { processSymbol(symbol); } auto end = std::chrono::steady_clock::now(); auto duration = std::chrono::duration_cast\u0026lt;std::chrono::microseconds\u0026gt;(end - start); if (duration \u0026lt; currentInterval) { std::this_thread::sleep_for(currentInterval - duration); } adjustInterval(); } } 思考转变：从单纯的效率优化转向了资源使用的平衡，考虑到了系统的整体性能。\n3. 系统级优化：负载均衡 #随着对系统整体的思考，我们意识到需要从更高的层面来优化性能和资源分配。\n3.1 多线程数据读取 #将数据读取任务分散到多个线程，以提高并行处理能力。\nclass BalancedMarketDataReader { private: std::vector\u0026lt;std::thread\u0026gt; readerThreads; std::vector\u0026lt;std::vector\u0026lt;std::string\u0026gt;\u0026gt; symbolGroups; public: void start() { for (int i = 0; i \u0026lt; numThreads; ++i) { readerThreads.emplace_back(\u0026amp;BalancedMarketDataReader::readingLoop, this, i); } } }; 思考：如何最有效地分配交易品种给不同的线程，以平衡负载？\n3.2 动态负载均衡 #实现能够根据实时负载情况动态调整工作分配的机制。\nclass DynamicLoadBalancer { private: std::vector\u0026lt;std::atomic\u0026lt;int\u0026gt;\u0026gt; threadLoads; std::mutex symbolsMutex; std::vector\u0026lt;std::string\u0026gt; symbols; public: void balancerLoop() { while (running) { rebalanceLoad(); std::this_thread::sleep_for(std::chrono::seconds(10)); } } }; 思考：如何在数据读取和订单处理之间动态分配系统资源，以实现最佳的整体性能？\n3.3 工作窃取算法 #引入更复杂的负载均衡策略，允许空闲线程从繁忙线程\u0026quot;窃取\u0026quot;工作。\nclass WorkStealingBalancer { private: std::vector\u0026lt;std::unique_ptr\u0026lt;WorkStealingQueue\u0026gt;\u0026gt; queues; bool stealWork(int threadId) { for (size_t i = 0; i \u0026lt; queues.size(); ++i) { if (i == threadId) continue; std::string symbol; if (queues[i]-\u0026gt;steal(symbol)) { processSymbol(symbol); queues[threadId]-\u0026gt;push(symbol); return true; } } return false; } }; 思考转变：从单一组件的优化，发展到了整个系统的资源分配和负载均衡策略。\n思考过程的演进 # 局部到全局：从优化单一数据读取器的效率，扩展到考虑整个系统的性能平衡。 单线程到多线程：认识到多线程处理在提高系统整体吞吐量方面的重要性。 静态分配到动态平衡：从固定的处理策略，转向能够适应实时负载变化的动态系统。 资源使用的权衡：深入思考如何在关键组件（如数据读取和订单处理）之间合理分配资源。 性能指标的全面性：从仅关注数据读取的速度，扩展到考虑系统整体的响应时间、吞吐量和资源利用率。 跨组件影响的认识：理解到一个组件的优化可能会对其他组件产生意料之外的影响，需要从整体角度进行评估。 结论 #这个思考探究过程展示了如何从解决具体问题逐步扩展到系统层面的优化。它强调了在高频交易这样的复杂系统中，局部优化虽然重要，但必须放在整体系统性能和资源平衡的大背景下来考虑。\n这种思维方式的转变不仅适用于市场数据读取器的优化，也可以应用于其他复杂系统的性能优化过程。它提醒我们，在进行任何优化时，都需要考虑：\n这个优化如何影响系统的其他部分？ 我们是否在正确的层面上解决问题？ 局部的高效是否会导致全局的低效？ 如何设计一个能够适应变化和自我调节的系统？ 通过这样的思考过程，我们不仅解决了最初的数据读取效率问题，还提出了更全面、更有弹性的系统优化方案，为构建一个高性能、高可靠性的高频交易系统奠定了基础。\n","date":"25 September 2024","permalink":"/blog/datareader_design/","section":"Blog","summary":"\u003ch1 id=\"高频交易系统优化从数据读取到系统平衡的思考过程\" class=\"relative group\"\u003e高频交易系统优化：从数据读取到系统平衡的思考过程 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e9%ab%98%e9%a2%91%e4%ba%a4%e6%98%93%e7%b3%bb%e7%bb%9f%e4%bc%98%e5%8c%96%e4%bb%8e%e6%95%b0%e6%8d%ae%e8%af%bb%e5%8f%96%e5%88%b0%e7%b3%bb%e7%bb%9f%e5%b9%b3%e8%a1%a1%e7%9a%84%e6%80%9d%e8%80%83%e8%bf%87%e7%a8%8b\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h1\u003e\u003ch2 id=\"1-初始问题数据读取效率\" class=\"relative group\"\u003e1. 初始问题：数据读取效率 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#1-%e5%88%9d%e5%a7%8b%e9%97%ae%e9%a2%98%e6%95%b0%e6%8d%ae%e8%af%bb%e5%8f%96%e6%95%88%e7%8e%87\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003e最初，我们关注的是市场数据读取器本身的效率问题。\u003c/p\u003e","title":"高频交易系统优化：从数据读取到系统平衡的思考过程"},{"content":"高性能低延迟交易系统设计：技术分享 update #在高频交易和实时金融系统中，性能和延迟是关键因素。本文将分享一些设计和实现高性能低延迟交易系统的关键技术和策略。\n1. 数据结构优化 #1.1 内存映射（Memory-Mapped）文件 #使用内存映射文件可以显著提高I/O性能，减少系统调用，并允许快速的进程间通信。\nclass MmapOrderBook { // 使用内存映射文件存储订单簿数据 }; 1.2 自定义内存池 #实现自定义内存池可以减少内存分配和释放的开销，提高内存使用效率。\ntemplate\u0026lt;typename T, size_t MaxSize\u0026gt; class MemoryPool { // 实现高效的内存分配和回收 }; 2. 并发控制 #2.1 细粒度锁 #使用细粒度锁可以减少锁竞争，提高并发性能。\nstd::array\u0026lt;std::shared_mutex, MAX_POSITIONS\u0026gt; m_positionMutexes; 2.2 无锁数据结构 #在关键路径上使用无锁数据结构可以进一步减少同步开销。\nstd::atomic\u0026lt;double\u0026gt; quantity; std::atomic\u0026lt;double\u0026gt; averagePrice; 3. 高效的更新策略 #3.1 增量更新 vs 全量更新 #根据具体场景选择合适的更新策略。增量更新适合频繁的小幅度变化，全量更新适合大幅度变化或定期同步。\nvoid updatePosition(const char* instId, AssetType type, PositionSide side, double quantityDelta, double price); void syncPositionWithExchange(const char* instId, AssetType type, PositionSide side, double quantity, double price); 3.2 原子操作 #使用原子操作可以在不使用锁的情况下实现线程安全的更新。\natomicUpdate(positionPtr-\u0026gt;averagePrice, [newQuantity, quantityDelta, price](double oldAvgPrice) { return (oldAvgPrice * (newQuantity - quantityDelta) + price * quantityDelta) / newQuantity; }); 4. 代码优化 #4.1 内联函数 #使用内联函数可以减少函数调用开销。\ninline void updateAvailable(double delta) { available.fetch_add(delta, std::memory_order_relaxed); } 4.2 分支预测优化 #减少难以预测的分支，利用现代CPU的分支预测功能。\n// 避免复杂的嵌套条件判断 if (type == AssetType::SPOT) { // SPOT 逻辑 } else { // 其他类型逻辑 } 5. 系统架构 #5.1 职责分离 #将不同功能模块分离，如将订单管理和持仓管理分开，可以提高系统的可维护性和可扩展性。\nclass OrderManager { /* ... */ }; class PositionManager { /* ... */ }; 5.2 最小化跨模块调用 #减少模块间的频繁调用，可以降低系统复杂度和延迟。\n6. 性能监控和日志 #6.1 高效日志 #使用异步日志和日志级别控制，确保日志不会成为性能瓶颈。\nLOG_INFO(\u0026#34;Position updated: instId={}, type={}, side={}\u0026#34;, instId, static_cast\u0026lt;int\u0026gt;(type), static_cast\u0026lt;int\u0026gt;(side)); 6.2 性能指标监控 #实时监控关键性能指标，如更新延迟、吞吐量等，以便及时发现和解决性能问题。\n结论 #构建高性能低延迟的交易系统需要在多个层面进行优化，包括数据结构、并发控制、更新策略、代码优化和系统架构等。通过综合运用这些技术，可以显著提升系统的性能和响应速度，满足高频交易和实时金融系统的严格要求。\n","date":"20 September 2024","permalink":"/blog/high_performance/","section":"Blog","summary":"\u003ch1 id=\"高性能低延迟交易系统设计技术分享-update\" class=\"relative group\"\u003e高性能低延迟交易系统设计：技术分享 update \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e9%ab%98%e6%80%a7%e8%83%bd%e4%bd%8e%e5%bb%b6%e8%bf%9f%e4%ba%a4%e6%98%93%e7%b3%bb%e7%bb%9f%e8%ae%be%e8%ae%a1%e6%8a%80%e6%9c%af%e5%88%86%e4%ba%ab-update\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h1\u003e\u003cp\u003e在高频交易和实时金融系统中，性能和延迟是关键因素。本文将分享一些设计和实现高性能低延迟交易系统的关键技术和策略。\u003c/p\u003e","title":"实现高性能低延迟的交易系统设计"},{"content":"在高频交易系统的开发中，我们经常面临着性能和正确性之间的权衡。最近，我们在优化订单处理流程时，发现了一个有趣的问题：是否需要在高层组件中实现锁定？本文将深入探讨这个问题，分析其必要性，并展示优化前后的实现。\n背景 我们的系统主要由以下组件构成：\nMmapOrderBook：核心数据存储，使用内存映射文件实现 PositionManager：负责仓位管理 OrderValidator：负责订单验证 OrderManager：负责订单处理流程 最初，我们的实现如下：\n// OrderManager.cpp bool OrderManager::processOrder(const MmapOrderBook::Order\u0026amp; order) { if (!orderValidator_-\u0026gt;validateOrder(order)) { return false; } if (orderBook_-\u0026gt;addOrder(order)) { auto position = positionManager_-\u0026gt;getPosition(order.accountId, /* instrumentId */); if (position) { position-\u0026gt;quantity += order.isBuy ? order.quantity : -order.quantity; positionManager_-\u0026gt;updatePosition(*position); } // 发布订单已处理事件 return true; } return false; } 问题分析 虽然 MmapOrderBook 内部使用了分片锁来保证单个操作的线程安全，但我们发现这种方法在处理复合操作时可能存在问题。主要原因如下：\na) 复合操作的原子性： processOrder 方法包含多个相关操作（验证、添加、更新仓位），这些操作需要作为一个原子单元执行。\nb) 避免竞态条件： 在验证订单和添加订单之间，系统状态可能发生变化，导致基于过时信息做出决策。\nc) 保持不变量： 某些业务逻辑依赖于多个相关数据的一致状态，需要在整个操作过程中维护这些不变量。\nd) 简化并发模型： 高层锁定可以简化并发模型，使代码更易于理解和维护。\ne) 防止死锁： 复杂操作中可能需要获取多个低层锁，增加死锁风险。高层锁可以降低这种风险。\n优化后的实现 考虑到上述因素，我们决定在 OrderManager 和 PositionManager 中引入高层锁定：\n// OrderManager.h class OrderManager { public: bool processOrder(const MmapOrderBook::Order\u0026amp; order); private: std::shared_ptr\u0026lt;MmapOrderBook\u0026gt; orderBook_; std::shared_ptr\u0026lt;PositionManager\u0026gt; positionManager_; std::shared_ptr\u0026lt;OrderValidator\u0026gt; orderValidator_; mutable std::shared_mutex mutex_; // 新增：读写锁 }; // OrderManager.cpp bool OrderManager::processOrder(const MmapOrderBook::Order\u0026amp; order) { std::unique_lock\u0026lt;std::shared_mutex\u0026gt; lock(mutex_); // 写锁 if (!orderValidator_-\u0026gt;validateOrder(order)) { return false; } if (orderBook_-\u0026gt;addOrder(order)) { auto position = positionManager_-\u0026gt;getPosition(order.accountId, /* instrumentId */); if (position) { position-\u0026gt;quantity += order.isBuy ? order.quantity : -order.quantity; positionManager_-\u0026gt;updatePosition(*position); } // 发布订单已处理事件 return true; } return false; } // PositionManager.h class PositionManager { public: bool updatePosition(const MmapOrderBook::Position\u0026amp; position); std::optional\u0026lt;MmapOrderBook::Position\u0026gt; getPosition(int64_t accountId, int64_t instrumentId) const; private: std::shared_ptr\u0026lt;MmapOrderBook\u0026gt; orderBook_; mutable std::shared_mutex mutex_; // 新增：读写锁 }; // PositionManager.cpp bool PositionManager::updatePosition(const MmapOrderBook::Position\u0026amp; position) { std::unique_lock\u0026lt;std::shared_mutex\u0026gt; lock(mutex_); // 写锁 return orderBook_-\u0026gt;updatePosition(position); } std::optional\u0026lt;MmapOrderBook::Position\u0026gt; PositionManager::getPosition(int64_t accountId, int64_t instrumentId) const { std::shared_lock\u0026lt;std::shared_mutex\u0026gt; lock(mutex_); // 读锁 return orderBook_-\u0026gt;getPosition(accountId, instrumentId); } 优化效果 通过引入高层锁定，我们实现了以下目标：\n确保了复合操作的原子性 消除了潜在的竞态条件 简化了并发模型，使代码更易维护 降低了死锁风险 注意事项 尽管高层锁定解决了许多问题，但它也带来了一些潜在的挑战：\n性能影响：高层锁可能会降低并发性，因为它们tend会持锁时间更长。 可能的过度序列化：如果锁的范围过大，可能会导致一些本可以并行的操作被不必要地序列化。 潜在的资源浪费：如果锁覆盖了太多不相关的操作，可能会造成资源的浪费。 未来优化方向 为了进一步提高系统性能，我们可以考虑以下优化方向：\n实现轻量级事务机制，允许将多个操作组合成原子单元，而不需要持有锁那么长时间。 尝试在较低层次上实现更细粒度的锁，只在绝对必要的地方使用高层锁。 考虑使用乐观并发控制，使用版本号或时间戳来检测并发修改。 对特定操作使用无锁算法来提高并发性。 进一步优化读写分离，允许更多的读操作并发进行。 结论：\n在高频交易系统中，高层组件的锁定策略对于保证数据一致性和系统正确性至关重要。通过仔细权衡和设计，我们可以在保证正确性的同时，尽可能地提高系统性能。本次优化是我们持续改进过程中的一个重要步骤，我们将继续监控系统性能，并在实践中寻找最佳的平衡点。\n","date":"18 September 2024","permalink":"/blog/mutex/","section":"Blog","summary":"\u003cp\u003e在高频交易系统的开发中，我们经常面临着性能和正确性之间的权衡。最近，我们在优化订单处理流程时，发现了一个有趣的问题：是否需要在高层组件中实现锁定？本文将深入探讨这个问题，分析其必要性，并展示优化前后的实现。\u003c/p\u003e","title":"高频交易系统中的高层锁定：必要性与实现"},{"content":"高频交易系统优化：从WebSocket到市场数据处理的全面解析 #在当今竞争激烈的金融市场中,高频交易(HFT)系统的性能直接关系到交易策略的成功与否。本文将深入探讨高频交易系统中两个关键环节的优化：WebSocket消息接收机制和市场数据处理。我们将分析当前最佳实践,探讨潜在的优化方向,并提供具体的代码示例。\n1. WebSocket消息接收机制优化 #在高频交易系统中,每一毫秒的延迟都可能导致巨大的经济损失。因此,优化WebSocket消息的接收机制对于系统的整体性能至关重要。\n1.1 WebSocketClient类设计与实现 #以下是一个高效的WebSocketClient类的实现示例：\nclass WebSocketClient { public: using MessageHandler = std::function\u0026lt;void(const char*, size_t)\u0026gt;; WebSocketClient(/* 构造函数参数 */) : ws_(nullptr), running_(false) {} void receiveMessages(MessageHandler handler) { if (!ws_) { throw std::runtime_error(\u0026#34;WebSocket is not connected\u0026#34;); } constexpr size_t BUFFER_SIZE = 1024 * 1024; // 1MB buffer std::array\u0026lt;char, BUFFER_SIZE\u0026gt; buffer; int flags; while (running_) { try { int n = ws_-\u0026gt;receiveFrame(buffer.data(), buffer.size(), flags); if (n \u0026gt; 0) { handler(buffer.data(), n); } else if (n == 0) { // 连接关闭 break; } } catch (const Poco::Exception\u0026amp; e) { // 仅在关键错误时记录日志 // 考虑添加重连逻辑 } } } void start() { running_ = true; } void stop() { running_ = false; } private: std::unique_ptr\u0026lt;Poco::Net::WebSocket\u0026gt; ws_; std::atomic\u0026lt;bool\u0026gt; running_; }; 1.2 关键优化点 # 大缓冲区: 使用1MB的缓冲区大幅减少系统调用次数,提高吞吐量。 零拷贝接口: 通过MessageHandler直接传递原始数据指针和长度,避免不必要的内存拷贝。 简化的错误处理: 只在关键错误时记录日志,减少正常操作中的开销。 原子操作控制: 使用std::atomic\u0026lt;bool\u0026gt;安全地控制接收循环。 1.3 在Quote进程中的应用 #在Quote进程中,我们直接在主线程中处理WebSocket消息,以最小化延迟：\nclass QuoteApplication { public: QuoteApplication() : running_(false) { initializeWebSocket(); } void run() { running_ = true; webSocketClient_-\u0026gt;start(); webSocketClient_-\u0026gt;receiveMessages([this](const char* data, size_t length) { this-\u0026gt;handleQuoteMessage(data, length); }); } void stop() { running_ = false; webSocketClient_-\u0026gt;stop(); } private: void initializeWebSocket() { webSocketClient_ = std::make_unique\u0026lt;WebSocketClient\u0026gt;(/* 参数 */); // 配置WebSocket连接 } void handleQuoteMessage(const char* data, size_t length) { // 处理接收到的市场数据 // 例如:解析JSON,更新共享内存等 } std::atomic\u0026lt;bool\u0026gt; running_; std::unique_ptr\u0026lt;WebSocketClient\u0026gt; webSocketClient_; }; 1.4 在StrategyAndTrading进程中的应用 #在StrategyAndTrading进程中,我们使用独立的线程来处理WebSocket消息,以避免阻塞主要的策略执行逻辑：\nclass MessageHandler { public: MessageHandler() : running_(false) {} void start() { if (receiveThread_.joinable()) { throw std::runtime_error(\u0026#34;Receive thread is already running\u0026#34;); } running_ = true; webSocketClient_-\u0026gt;start(); receiveThread_ = std::thread([this]() { webSocketClient_-\u0026gt;receiveMessages([this](const char* data, size_t length) { this-\u0026gt;handleMessage(data, length); }); }); } void stop() { running_ = false; webSocketClient_-\u0026gt;stop(); if (receiveThread_.joinable()) { receiveThread_.join(); } } private: void handleMessage(const char* data, size_t length) { // 处理接收到的消息 // 例如:解析JSON,更新订单状态等 } std::atomic\u0026lt;bool\u0026gt; running_; std::unique_ptr\u0026lt;WebSocketClient\u0026gt; webSocketClient_; std::thread receiveThread_; }; 2. 市场数据处理优化 #在获取交易所市场数据时,传统的队列方法可能不是最佳选择。让我们分析使用队列的利弊,并探讨更适合高频交易系统的替代方案。\n2.1 使用队列的劣势 # 额外延迟: 队列操作引入的延迟在HFT中可能造成显著影响。 内存开销: 额外的内存分配可能导致缓存未命中,进一步增加延迟。 上下文切换: 多线程环境中的频繁上下文切换增加系统开销。 顺序处理限制: FIFO处理可能不适合需要优先处理某些关键数据的场景。 潜在的锁竞争: 高并发情况下,队列可能成为竞争热点。 2.2 替代方案 #2.2.1 无锁环形缓冲区 (Lock-free Ring Buffer) #template\u0026lt;typename T, size_t Size\u0026gt; class LockFreeRingBuffer { private: std::array\u0026lt;T, Size\u0026gt; buffer_; std::atomic\u0026lt;size_t\u0026gt; head_{0}; std::atomic\u0026lt;size_t\u0026gt; tail_{0}; public: bool push(const T\u0026amp; item) { size_t current_tail = tail_.load(std::memory_order_relaxed); size_t next_tail = (current_tail + 1) % Size; if (next_tail == head_.load(std::memory_order_acquire)) return false; // Buffer is full buffer_[current_tail] = item; tail_.store(next_tail, std::memory_order_release); return true; } bool pop(T\u0026amp; item) { size_t current_head = head_.load(std::memory_order_relaxed); if (current_head == tail_.load(std::memory_order_acquire)) return false; // Buffer is empty item = buffer_[current_head]; head_.store((current_head + 1) % Size, std::memory_order_release); return true; } }; 这种方法可以显著减少锁竞争,降低延迟。\n2.2.2 直接处理模型 #class MarketDataHandler { public: void onMarketData(const MarketData\u0026amp; data) { // 直接处理市场数据 processData(data); } private: void processData(const MarketData\u0026amp; data) { // 实现数据处理逻辑 } }; 直接在回调函数中处理数据,避免了队列带来的额外开销。\n2.2.3 内存映射文件与共享内存 #class SharedMemoryManager { public: SharedMemoryManager(const std::string\u0026amp; name, size_t size) : shm_object_(boost::interprocess::open_or_create, name.c_str(), size) , region_(shm_object_.get_address(), shm_object_.get_size()) {} void writeMarketData(const MarketData\u0026amp; data) { // 写入共享内存 } MarketData readMarketData() { // 从共享内存读取 } private: boost::interprocess::shared_memory_object shm_object_; boost::interprocess::mapped_region region_; }; 使用共享内存可以实现极低延迟的进程间通信。\n3. 性能考量与未来优化方向 #3.1 当前实现的优势 # 低延迟: 通过最小化内存拷贝和系统调用,实现了低延迟的消息处理。 高吞吐量: 大缓冲区设计允许系统在高频率的消息流中保持稳定性。 灵活性: 同一个WebSocketClient类可以在不同的进程中以不同的方式使用。 无锁设计: 使用无锁数据结构减少了线程竞争,提高了并发性能。 3.2 潜在的优化方向 # 内存池: 实现自定义的内存分配器,进一步减少动态内存分配的开销。 SIMD指令: 利用现代CPU的SIMD指令集加速数据处理。 硬件加速: 探索使用FPGA或GPU加速特定的消息处理任务。 网络优化: 考虑使用内核旁路技术如DPDK,进一步减少网络延迟。 机器学习优化: 使用机器学习技术预测市场数据变化,优化处理流程。 4. 结论与建议 #高频交易系统的性能优化是一个持续的过程,需要从多个层面进行考虑和改进。基于我们的分析,以下是一些关键建议：\n采用零拷贝设计: 在整个数据处理流程中,尽可能减少数据拷贝操作。\n使用无锁数据结构: 在高并发场景中,无锁数据结构可以显著提高性能。\n直接处理模型: 对于关键路径,考虑使用直接处理模型而非队列缓冲。\n混合策略: 根据不同数据流的重要性和处理要求,采用不同的处理策略。\n持续监控与优化: 实施严格的性能监控,并根据实时数据持续优化系统。\n考虑硬件因素: 在软件优化的基础上,探索硬件加速的可能性。\n保持简洁: 在追求极致性能的同时,保持系统设计的简洁性和可维护性。\n在高频交易的世界中,毫秒级甚至微秒级的优化可能带来显著的竞争优势。通过精心设计的WebSocket客户端、高效的市场数据处理机制,以及不断的性能调优,我们可以构建出反应迅速、高度可靠的高频交易系统。然而,优化是一个永无止境的过程。随着技术的发展和市场的变化,我们需要不断评估和改进我们的实现,以保持系统的竞争力。\n在这个瞬息万变的金融科技领域,唯有持续学习和创新,才能在激烈的市场竞争中立于不败之地。\n","date":"15 September 2024","permalink":"/blog/queue_usage2/","section":"Blog","summary":"\u003ch1 id=\"高频交易系统优化从websocket到市场数据处理的全面解析\" class=\"relative group\"\u003e高频交易系统优化：从WebSocket到市场数据处理的全面解析 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e9%ab%98%e9%a2%91%e4%ba%a4%e6%98%93%e7%b3%bb%e7%bb%9f%e4%bc%98%e5%8c%96%e4%bb%8ewebsocket%e5%88%b0%e5%b8%82%e5%9c%ba%e6%95%b0%e6%8d%ae%e5%a4%84%e7%90%86%e7%9a%84%e5%85%a8%e9%9d%a2%e8%a7%a3%e6%9e%90\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h1\u003e\u003cp\u003e在当今竞争激烈的金融市场中,高频交易(HFT)系统的性能直接关系到交易策略的成功与否。本文将深入探讨高频交易系统中两个关键环节的优化：WebSocket消息接收机制和市场数据处理。我们将分析当前最佳实践,探讨潜在的优化方向,并提供具体的代码示例。\u003c/p\u003e","title":"高频交易系统优化：从WebSocket到市场数据处理的全面解析"},{"content":"高频交易系统中市场数据处理：队列的利弊分析 #在高频交易（HFT）系统中，处理市场数据的方式直接影响着系统的性能和延迟。使用队列是一种常见的数据处理方法，但在追求极低延迟的HFT系统中，这种选择是否合适需要仔细考虑。本文将分析使用队列的利弊，并探讨可能的替代方案。\n1. 使用队列的优势 # 解耦和缓冲：队列可以有效地解耦数据生产者（如市场数据源）和消费者（如策略引擎），提供一个缓冲区来处理突发的数据流。\n负载均衡：在多线程处理中，队列可以帮助分配工作负载，防止某个处理单元过载。\n简化设计：队列提供了一个直观的数据流模型，可以简化系统的整体设计。\n容错性：队列可以帮助系统更好地处理暂时的处理速度不匹配，增强系统的稳定性。\n2. 使用队列的劣势 # 额外延迟：队列操作（入队和出队）会引入额外的延迟，即使是几微秒的延迟在HFT中也可能造成显著影响。\n内存开销：队列需要额外的内存分配，这可能导致缓存未命中，进一步增加延迟。\n上下文切换：在多线程环境中，队列操作可能导致频繁的上下文切换，增加系统开销。\n顺序处理限制：队列通常按FIFO顺序处理数据，这可能不适合需要优先处理某些关键数据的场景。\n潜在的锁竞争：在高并发情况下，队列可能成为竞争热点，导致性能下降。\n3. 替代方案 #考虑到队列可能引入的延迟，以下是一些可能的替代方案：\n3.1 无锁环形缓冲区（Lock-free Ring Buffer） #template\u0026lt;typename T, size_t Size\u0026gt; class LockFreeRingBuffer { private: std::array\u0026lt;T, Size\u0026gt; buffer_; std::atomic\u0026lt;size_t\u0026gt; head_{0}; std::atomic\u0026lt;size_t\u0026gt; tail_{0}; public: bool push(const T\u0026amp; item) { size_t current_tail = tail_.load(std::memory_order_relaxed); size_t next_tail = (current_tail + 1) % Size; if (next_tail == head_.load(std::memory_order_acquire)) return false; // Buffer is full buffer_[current_tail] = item; tail_.store(next_tail, std::memory_order_release); return true; } bool pop(T\u0026amp; item) { size_t current_head = head_.load(std::memory_order_relaxed); if (current_head == tail_.load(std::memory_order_acquire)) return false; // Buffer is empty item = buffer_[current_head]; head_.store((current_head + 1) % Size, std::memory_order_release); return true; } }; 这种方法可以显著减少锁竞争，降低延迟。\n3.2 直接处理模型 #class MarketDataHandler { public: void onMarketData(const MarketData\u0026amp; data) { // 直接处理市场数据 processData(data); } private: void processData(const MarketData\u0026amp; data) { // 实现数据处理逻辑 } }; 直接在回调函数中处理数据，避免了队列带来的额外开销。\n3.3 内存映射文件与共享内存 #class SharedMemoryManager { public: SharedMemoryManager(const std::string\u0026amp; name, size_t size) : shm_object_(boost::interprocess::open_or_create, name.c_str(), size) , region_(shm_object_.get_address(), shm_object_.get_size()) {} void writeMarketData(const MarketData\u0026amp; data) { // 写入共享内存 } MarketData readMarketData() { // 从共享内存读取 } private: boost::interprocess::shared_memory_object shm_object_; boost::interprocess::mapped_region region_; }; 使用共享内存可以实现极低延迟的进程间通信。\n4. 结论与建议 #对于追求极低延迟的高频交易系统，使用传统队列处理市场数据可能不是最佳选择。虽然队列提供了良好的解耦和缓冲功能，但它引入的额外延迟可能对系统性能造成显著影响。\n建议：\n评估系统需求：仔细评估系统的具体需求，包括延迟要求、数据处理量、系统复杂度等。\n考虑混合方案：对于关键路径，使用直接处理或无锁数据结构；对于次要路径，可以考虑使用队列来平衡性能和系统复杂度。\n性能测试：实施严格的性能测试，比较不同方案在实际环境中的表现。\n持续优化：随着系统的演进和需求的变化，持续评估和优化数据处理方式。\n定制化解决方案：考虑开发针对特定需求的定制化数据结构和处理机制。\n在高频交易系统中，每一微秒的延迟都可能转化为实际的经济损失。因此，在设计系统时，需要在功能、性能和复杂度之间找到最佳平衡点。直接处理模型或高度优化的无锁数据结构通常是处理市场数据的更好选择，但具体实现需要根据系统的特定需求和约束来决定。\n","date":"15 September 2024","permalink":"/blog/queue_usage/","section":"Blog","summary":"\u003ch1 id=\"高频交易系统中市场数据处理队列的利弊分析\" class=\"relative group\"\u003e高频交易系统中市场数据处理：队列的利弊分析 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e9%ab%98%e9%a2%91%e4%ba%a4%e6%98%93%e7%b3%bb%e7%bb%9f%e4%b8%ad%e5%b8%82%e5%9c%ba%e6%95%b0%e6%8d%ae%e5%a4%84%e7%90%86%e9%98%9f%e5%88%97%e7%9a%84%e5%88%a9%e5%bc%8a%e5%88%86%e6%9e%90\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h1\u003e\u003cp\u003e在高频交易（HFT）系统中，处理市场数据的方式直接影响着系统的性能和延迟。使用队列是一种常见的数据处理方法，但在追求极低延迟的HFT系统中，这种选择是否合适需要仔细考虑。本文将分析使用队列的利弊，并探讨可能的替代方案。\u003c/p\u003e","title":"高频交易系统中市场数据处理：队列的利弊分析"},{"content":"故障复盘报告：内存映射文件中的 std::string 导致的段错误 #1. 问题描述 #在使用内存映射文件存储订单数据的过程中，程序在重启后出现段错误。具体表现为在尝试访问存储在内存映射文件中的 Order 结构体的 id 字段时，程序崩溃。\n2. 错误信息 #程序崩溃时的 GDB 调试信息如下：\nThread 2 \u0026#34;strategyandtrad\u0026#34; received signal SIGSEGV, Segmentation fault. [Switching to Thread 0x7ffff6f4c6c0 (LWP 446582)] __memcmp_sse2 () at ../sysdeps/x86_64/multiarch/memcmp-sse2.S:258 258 ../sysdeps/x86_64/multiarch/memcmp-sse2.S: No such file or directory. (gdb) bt #0 __memcmp_sse2 () at ../sysdeps/x86_64/multiarch/memcmp-sse2.S:258 #1 0x000055555556d79b in std::char_traits\u0026lt;char\u0026gt;::compare (__s1=0x7f4710000eb0 \u0026lt;error: Cannot access memory at address 0x7f4710000eb0\u0026gt;, __s2=0x7fffe8000c80 \u0026#34;ORD-1726124231791862593\u0026#34;, __n=23) at /usr/include/c++/12/bits/char_traits.h:385 #2 0x000055555559c599 in std::operator==\u0026lt;char\u0026gt; (__lhs=\u0026lt;error: Cannot access memory at address 0x7f4710000eb0\u0026gt;, __rhs=\u0026#34;ORD-1726124231791862593\u0026#34;) at /usr/include/c++/12/bits/basic_string.h:3587 #3 0x000055555561a7fa in MmapOrderBook::Impl::getOrder (this=0x555555776170, orderId=\u0026#34;ORD-1726124231791862593\u0026#34;) at /home/hft_trading_system/strategyandtradingwitheventbus/src/order_management/mmap_order_book_impl.cpp:211 ... (gdb) frame 3 #3 0x000055555561a7fa in MmapOrderBook::Impl::getOrder (this=0x555555776170, orderId=\u0026#34;ORD-1726124231791862593\u0026#34;) at /home/hft_trading_system/strategyandtradingwitheventbus/src/order_management/mmap_order_book_impl.cpp:211 211 if (m_orders[i].id == orderId) { (gdb) print orderId $1 = \u0026#34;ORD-1726124231791862593\u0026#34; (gdb) print m_orders[i].id $2 = \u0026lt;error: Cannot access memory at address 0x7f4710000eb0\u0026gt; (gdb) print m_orders[i] $3 = {id = \u0026lt;error: Cannot access memory at address 0x7f4710000eb0\u0026gt;, instId = \u0026lt;error: Cannot access memory at address 0x7f4710000ed0\u0026gt;, price = 58126.699999999997, quantity = 100, status = 3} 相关代码 struct Order { std::string id; std::string instId; double price; double quantity; int status; // 0: pending, 1: filled, 2: cancelled }; 这个结构体直接在内存映射文件中使用，导致了我们遇到的问题。\n4. 问题分析 #通过分析错误信息和代码结构，我们发现：\n程序崩溃发生在比较 m_orders[i].id 和 orderId 时。 无法访问 m_orders[i].id 的内存地址（0x7f4710000eb0）。 Order 结构体中的 id 和 instId 字段使用了 std::string 类型。 问题的根本原因是：std::string 是一个复杂对象，包含指向堆内存的指针。当程序退出后，这些指针所指向的内存不再有效。重新启动程序并尝试访问内存映射文件中的这些 std::string 对象时，就会导致段错误。\n5. 解决方案 #将 Order 结构体中的 std::string 类型替换为固定大小的字符数组：\nconstexpr size_t MAX_ID_LENGTH = 64; constexpr size_t MAX_INST_ID_LENGTH = 32; struct Order { char id[MAX_ID_LENGTH]; char instId[MAX_INST_ID_LENGTH]; double price; double quantity; int status; // 构造函数和辅助方法... }; 同时，添加辅助方法来方便地设置和获取这些字段的值：\nvoid setId(const std::string\u0026amp; newId) { strncpy(id, newId.c_str(), MAX_ID_LENGTH - 1); id[MAX_ID_LENGTH - 1] = \u0026#39;\\0\u0026#39;; } std::string getId() const { return std::string(id); } // 类似地实现 setInstId 和 getInstId 6. 实施步骤 # 修改 Order 结构体的定义。 更新所有使用 Order 结构体的代码，使用新的 setter 和 getter 方法。 删除旧的内存映射文件（如果存在），因为新的结构体布局与旧的不兼容。 重新编译整个项目。 运行测试，确保问题已解决且没有引入新的问题。 7. 经验教训 # 在使用内存映射文件时，应避免直接存储包含指针或复杂对象（如 std::string）的结构体。 对于需要持久化的数据结构，优先使用固定大小的数组或基本数据类型。 在设计持久化数据结构时，考虑跨会话和跨进程的兼容性。 增加更多的错误检查和日志记录，以便更容易地诊断类似问题。 8. 后续行动 # 审查其他使用内存映射文件的代码，确保没有类似的潜在问题。 考虑实现一个数据完整性检查机制，在程序启动时验证内存映射文件的内容。 更新开发指南，强调在使用内存映射文件时应注意的事项。 考虑实现一个版本控制机制，以便在未来需要更改数据结构时能够平滑迁移。 Incident Report: Segmentation Fault Caused by std::string in Memory-Mapped File #1. Problem Description #The program experienced a segmentation fault after restart when attempting to access order data stored in a memory-mapped file. Specifically, the crash occurred when trying to access the id field of the Order struct stored in the memory-mapped file.\n2. Error Information #The GDB debug information at the time of the crash was as follows:\nThread 2 \u0026#34;strategyandtrad\u0026#34; received signal SIGSEGV, Segmentation fault. [Switching to Thread 0x7ffff6f4c6c0 (LWP 446582)] __memcmp_sse2 () at ../sysdeps/x86_64/multiarch/memcmp-sse2.S:258 258 ../sysdeps/x86_64/multiarch/memcmp-sse2.S: No such file or directory. (gdb) bt #0 __memcmp_sse2 () at ../sysdeps/x86_64/multiarch/memcmp-sse2.S:258 #1 0x000055555556d79b in std::char_traits\u0026lt;char\u0026gt;::compare (__s1=0x7f4710000eb0 \u0026lt;error: Cannot access memory at address 0x7f4710000eb0\u0026gt;, __s2=0x7fffe8000c80 \u0026#34;ORD-1726124231791862593\u0026#34;, __n=23) at /usr/include/c++/12/bits/char_traits.h:385 #2 0x000055555559c599 in std::operator==\u0026lt;char\u0026gt; (__lhs=\u0026lt;error: Cannot access memory at address 0x7f4710000eb0\u0026gt;, __rhs=\u0026#34;ORD-1726124231791862593\u0026#34;) at /usr/include/c++/12/bits/basic_string.h:3587 #3 0x000055555561a7fa in MmapOrderBook::Impl::getOrder (this=0x555555776170, orderId=\u0026#34;ORD-1726124231791862593\u0026#34;) at /home/hft_trading_system/strategyandtradingwitheventbus/src/order_management/mmap_order_book_impl.cpp:211 ... (gdb) frame 3 #3 0x000055555561a7fa in MmapOrderBook::Impl::getOrder (this=0x555555776170, orderId=\u0026#34;ORD-1726124231791862593\u0026#34;) at /home/hft_trading_system/strategyandtradingwitheventbus/src/order_management/mmap_order_book_impl.cpp:211 211 if (m_orders[i].id == orderId) { (gdb) print orderId $1 = \u0026#34;ORD-1726124231791862593\u0026#34; (gdb) print m_orders[i].id $2 = \u0026lt;error: Cannot access memory at address 0x7f4710000eb0\u0026gt; (gdb) print m_orders[i] $3 = {id = \u0026lt;error: Cannot access memory at address 0x7f4710000eb0\u0026gt;, instId = \u0026lt;error: Cannot access memory at address 0x7f4710000ed0\u0026gt;, price = 58126.699999999997, quantity = 100, status = 3} 3. Relevant Code #The issue originated in the definition of the Order struct. The original Order struct was defined as follows:\nstruct Order { std::string id; std::string instId; double price; double quantity; int status; // 0: pending, 1: filled, 2: cancelled }; This struct was directly used in the memory-mapped file, leading to the problem we encountered.\n4. Problem Analysis #Through analysis of the error information and code structure, we found:\nThe program crash occurred when comparing m_orders[i].id with orderId. The memory address of m_orders[i].id (0x7f4710000eb0) could not be accessed. The id and instId fields in the Order struct used the std::string type. The root cause of the problem is: std::string is a complex object that contains pointers to heap memory. When the program exits, the memory pointed to by these pointers is no longer valid. Attempting to access these std::string objects in the memory-mapped file after restarting the program results in a segmentation fault.\n5. Solution #Replace the std::string types in the Order struct with fixed-size character arrays:\nconstexpr size_t MAX_ID_LENGTH = 64; constexpr size_t MAX_INST_ID_LENGTH = 32; struct Order { char id[MAX_ID_LENGTH]; char instId[MAX_INST_ID_LENGTH]; double price; double quantity; int status; // Constructor and helper methods... }; Additionally, add helper methods to conveniently set and get the values of these fields:\nvoid setId(const std::string\u0026amp; newId) { strncpy(id, newId.c_str(), MAX_ID_LENGTH - 1); id[MAX_ID_LENGTH - 1] = \u0026#39;\\0\u0026#39;; } std::string getId() const { return std::string(id); } // Similarly implement setInstId and getInstId 6. Implementation Steps # Modify the definition of the Order struct. Update all code using the Order struct to use the new setter and getter methods. Delete the old memory-mapped file (if it exists), as the new struct layout is incompatible with the old one. Recompile the entire project. Run tests to ensure the problem is resolved and no new issues have been introduced. 7. Lessons Learned # When using memory-mapped files, avoid directly storing structs containing pointers or complex objects (like std::string). For data structures that need to be persisted, prioritize using fixed-size arrays or basic data types. When designing persistent data structures, consider compatibility across sessions and processes. Add more error checks and logging to make it easier to diagnose similar issues. 8. Follow-up Actions # Review other code using memory-mapped files to ensure there are no similar potential issues. Consider implementing a data integrity check mechanism to validate the contents of memory-mapped files at program startup. Update development guidelines to emphasize considerations when using memory-mapped files. Consider implementing a version control mechanism to allow smooth migration when data structures need to be changed in the future. ","date":"12 September 2024","permalink":"/blog/string_mmap/","section":"Blog","summary":"\u003ch1 id=\"故障复盘报告内存映射文件中的-stdstring-导致的段错误\" class=\"relative group\"\u003e故障复盘报告：内存映射文件中的 std::string 导致的段错误 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e6%95%85%e9%9a%9c%e5%a4%8d%e7%9b%98%e6%8a%a5%e5%91%8a%e5%86%85%e5%ad%98%e6%98%a0%e5%b0%84%e6%96%87%e4%bb%b6%e4%b8%ad%e7%9a%84-stdstring-%e5%af%bc%e8%87%b4%e7%9a%84%e6%ae%b5%e9%94%99%e8%af%af\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h1\u003e\u003ch2 id=\"1-问题描述\" class=\"relative group\"\u003e1. 问题描述 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#1-%e9%97%ae%e9%a2%98%e6%8f%8f%e8%bf%b0\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003e在使用内存映射文件存储订单数据的过程中，程序在重启后出现段错误。具体表现为在尝试访问存储在内存映射文件中的 \u003ccode\u003eOrder\u003c/code\u003e 结构体的 \u003ccode\u003eid\u003c/code\u003e 字段时，程序崩溃。\u003c/p\u003e","title":"Segmentation Fault Caused by std::string in Memory-Mapped File"},{"content":"高频交易系统配置管理方案分析 #当前方案概述 # graph TB CommonLib[\u0026#34;Common Library (MMAP)\u0026#34;] Exchange[\u0026#34;Exchange\u0026#34;] subgraph StrategyAndTrading[\u0026#34;StrategyAndTrading Component\u0026#34;] MDR[\u0026#34;MarketDataReader\u0026#34;] MDN[\u0026#34;MarketDataNormalizer\u0026#34;] SM[\u0026#34;StrategyManager\u0026#34;] subgraph Strategies[\u0026#34;Strategies\u0026#34;] S1[\u0026#34;Strategy 1\u0026#34;] S2[\u0026#34;Strategy 2\u0026#34;] SN[\u0026#34;Strategy N\u0026#34;] end OG[\u0026#34;OrderGenerator\u0026#34;] OV[\u0026#34;OrderValidator\u0026#34;] RP[\u0026#34;RiskProfiler\u0026#34;] RE[\u0026#34;RiskEvaluator\u0026#34;] OM[\u0026#34;OrderManager\u0026#34;] OE[\u0026#34;OrderExecutor\u0026#34;] OMO[\u0026#34;OrderMonitor\u0026#34;] PM[\u0026#34;PositionManager\u0026#34;] end CommonLib --\u0026gt;|1. Read MMAP| MDR MDR --\u0026gt;|2. Raw Market Data| MDN MDN --\u0026gt;|3. Normalized Data| SM SM --\u0026gt;|4. Distribute Data| Strategies Strategies --\u0026gt;|5. Generate Signals| OG OG --\u0026gt;|6. Create Orders| OV OV --\u0026gt;|7. Validated Orders| RP RP --\u0026gt;|8. Risk Profile| RE RE --\u0026gt;|9. Risk Evaluated Orders| OM OM --\u0026gt;|10. Managed Orders| OE OE \u0026lt;--\u0026gt;|11. Execute Orders| Exchange Exchange --\u0026gt;|12. Execution Results| OMO OMO --\u0026gt;|13. Order Updates| OM OM --\u0026gt;|14. Position Updates| PM PM -.-\u0026gt;|15. Position Feedback| SM classDef external fill:#f9f,stroke:#333,stroke-width:2px; classDef component fill:#bbf,stroke:#333,stroke-width:1px; classDef strategy fill:#bfb,stroke:#333,stroke-width:1px; class CommonLib,Exchange external; class MDR,MDN,SM,OG,OV,RP,RE,OM,OE,OMO,PM component; class S1,S2,SN strategy; Quote进程使用common静态库组件加载配置信息。 配置信息加载到Quote进程的本地缓存中。 使用观察者模式订阅common组件中config的变更。 当配置变更时，Quote进程更新本地缓存、重新连接和重新订阅。 优点分析 # 模块化设计：\n使用common静态库组件管理配置，提高了代码的复用性和维护性。 有利于系统的扩展，其他组件也可以使用相同的配置管理机制。 实时更新：\n观察者模式允许Quote进程实时响应配置变更，无需重启进程。 适合动态调整交易策略和参数的需求。 本地缓存：\n配置信息存储在本地缓存中，减少了频繁访问配置源的需求。 有助于降低延迟，这对高频交易至关重要。 灵活性：\n可以根据不同的配置变更类型采取不同的响应措施（如更新缓存、重新连接、重新订阅）。 潜在问题和优化建议 # 性能开销：\n观察者模式可能引入额外的性能开销，特别是在频繁更新的情况下。 建议：考虑使用更轻量级的通知机制，或实现批量更新策略。 一致性问题：\n在分布式系统中，不同进程可能在不同时间点获取更新，导致短暂的不一致状态。 建议：实现版本控制机制，确保所有相关进程同步更新到新版本配置。 重连接和重订阅的影响：\n在高频交易环境中，重连接和重订阅可能导致关键时刻的延迟或数据丢失。 建议：实现平滑过渡机制，确保在更新过程中最小化服务中断。 内存管理：\n频繁更新缓存可能导致内存碎片化或增加 GC 压力。 建议：优化内存分配策略，考虑使用内存池或预分配缓冲区。 错误处理：\n配置更新失败可能导致系统不稳定。 建议：实现健壮的错误处理机制，包括配置回滚能力和适当的日志记录。 更新粒度：\n可能存在不必要的全量更新。 建议：实现增量更新机制，只更新发生变化的配置项。 配置验证：\n缺乏明确的配置验证步骤可能导致系统不稳定。 建议：在应用新配置之前增加验证步骤，确保配置的正确性和一致性。 高频交易特定考虑 # 延迟敏感性：\n高频交易系统对延迟极为敏感，每一微秒都可能影响交易结果。 建议：优化配置访问路径，考虑使用更底层的技术如内存映射文件。 确定性：\n高频交易需要高度确定的行为。 建议：确保配置更新过程是可预测和一致的，避免引入不确定性。 吞吐量：\n高频交易系统需要处理大量数据和订单。 建议：确保配置管理不会成为系统瓶颈，考虑使用高性能数据结构和算法。 监管合规：\n高频交易系统面临严格的监管要求。 建议：确保配置更改有详细的日志记录，便于审计和回溯。 Analysis of Configuration Management in High-Frequency Trading System #Current Approach Overview # The Quote process uses the common static library component to load configuration information. Configuration information is loaded into the local cache of the Quote process. The Observer pattern is used to subscribe to config changes in the common component. When the configuration changes, the Quote process updates the local cache, reconnects, and resubscribes. Advantage Analysis # Modular Design: Using the common static library component for configuration management improves code reusability and maintainability. Facilitates system expansion; other components can use the same configuration management mechanism. Real-time Updates: The Observer pattern allows the Quote process to respond to configuration changes in real-time without restarting the process. Suitable for dynamic adjustment of trading strategies and parameters. Local Caching: Storing configuration information in a local cache reduces the need for frequent access to the configuration source. Helps reduce latency, which is crucial for high-frequency trading. Flexibility: Allows for different response measures based on different types of configuration changes (e.g., updating cache, reconnecting, resubscribing). Potential Issues and Optimization Suggestions # Performance Overhead: The Observer pattern may introduce additional performance overhead, especially in cases of frequent updates. Suggestion: Consider using a more lightweight notification mechanism or implementing a batch update strategy. Consistency Issues: In distributed systems, different processes may receive updates at different times, leading to temporary inconsistent states. Suggestion: Implement a version control mechanism to ensure all related processes synchronize to the new version of the configuration. Impact of Reconnection and Resubscription: In a high-frequency trading environment, reconnecting and resubscribing may cause delays or data loss at critical moments. Suggestion: Implement a smooth transition mechanism to minimize service interruption during updates. Memory Management: Frequent cache updates may lead to memory fragmentation or increase GC pressure. Suggestion: Optimize memory allocation strategy, consider using memory pools or pre-allocated buffers. Error Handling: Configuration update failures may lead to system instability. Suggestion: Implement robust error handling mechanisms, including configuration rollback capability and appropriate logging. Update Granularity: There may be unnecessary full updates. Suggestion: Implement an incremental update mechanism, only updating configuration items that have changed. Configuration Validation: Lack of explicit configuration validation steps may lead to system instability. Suggestion: Add validation steps before applying new configurations to ensure correctness and consistency. High-Frequency Trading Specific Considerations # Latency Sensitivity: High-frequency trading systems are extremely sensitive to latency; every microsecond can affect trading results. Suggestion: Optimize configuration access paths, consider using lower-level techniques such as memory-mapped files. Determinism: High-frequency trading requires highly deterministic behavior. Suggestion: Ensure the configuration update process is predictable and consistent, avoiding the introduction of uncertainty. Throughput: High-frequency trading systems need to process large volumes of data and orders. Suggestion: Ensure configuration management does not become a system bottleneck, consider using high-performance data structures and algorithms. Regulatory Compliance: High-frequency trading systems face strict regulatory requirements. Suggestion: Ensure detailed logging of configuration changes for auditing and traceability. ","date":"6 September 2024","permalink":"/blog/config_managemeng_in_hft_system/","section":"Blog","summary":"\u003ch1 id=\"高频交易系统配置管理方案分析\" class=\"relative group\"\u003e高频交易系统配置管理方案分析 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e9%ab%98%e9%a2%91%e4%ba%a4%e6%98%93%e7%b3%bb%e7%bb%9f%e9%85%8d%e7%bd%ae%e7%ae%a1%e7%90%86%e6%96%b9%e6%a1%88%e5%88%86%e6%9e%90\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h1\u003e\u003ch2 id=\"当前方案概述\" class=\"relative group\"\u003e当前方案概述 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e5%bd%93%e5%89%8d%e6%96%b9%e6%a1%88%e6%a6%82%e8%bf%b0\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-Mermaid\" data-lang=\"Mermaid\"\u003e\ngraph TB\n    CommonLib[\u0026#34;Common Library (MMAP)\u0026#34;]\n    Exchange[\u0026#34;Exchange\u0026#34;]\n\n    subgraph StrategyAndTrading[\u0026#34;StrategyAndTrading Component\u0026#34;]\n        MDR[\u0026#34;MarketDataReader\u0026#34;]\n        MDN[\u0026#34;MarketDataNormalizer\u0026#34;]\n        SM[\u0026#34;StrategyManager\u0026#34;]\n        subgraph Strategies[\u0026#34;Strategies\u0026#34;]\n            S1[\u0026#34;Strategy 1\u0026#34;]\n            S2[\u0026#34;Strategy 2\u0026#34;]\n            SN[\u0026#34;Strategy N\u0026#34;]\n        end\n        OG[\u0026#34;OrderGenerator\u0026#34;]\n        OV[\u0026#34;OrderValidator\u0026#34;]\n        RP[\u0026#34;RiskProfiler\u0026#34;]\n        RE[\u0026#34;RiskEvaluator\u0026#34;]\n        OM[\u0026#34;OrderManager\u0026#34;]\n        OE[\u0026#34;OrderExecutor\u0026#34;]\n        OMO[\u0026#34;OrderMonitor\u0026#34;]\n        PM[\u0026#34;PositionManager\u0026#34;]\n    end\n\n    CommonLib --\u0026gt;|1. Read MMAP| MDR\n    MDR --\u0026gt;|2. Raw Market Data| MDN\n    MDN --\u0026gt;|3. Normalized Data| SM\n    SM --\u0026gt;|4. Distribute Data| Strategies\n    Strategies --\u0026gt;|5. Generate Signals| OG\n    OG --\u0026gt;|6. Create Orders| OV\n    OV --\u0026gt;|7. Validated Orders| RP\n    RP --\u0026gt;|8. Risk Profile| RE\n    RE --\u0026gt;|9. Risk Evaluated Orders| OM\n    OM --\u0026gt;|10. Managed Orders| OE\n    OE \u0026lt;--\u0026gt;|11. Execute Orders| Exchange\n    Exchange --\u0026gt;|12. Execution Results| OMO\n    OMO --\u0026gt;|13. Order Updates| OM\n    OM --\u0026gt;|14. Position Updates| PM\n    PM -.-\u0026gt;|15. Position Feedback| SM\n\n    classDef external fill:#f9f,stroke:#333,stroke-width:2px;\n    classDef component fill:#bbf,stroke:#333,stroke-width:1px;\n    classDef strategy fill:#bfb,stroke:#333,stroke-width:1px;\n    class CommonLib,Exchange external;\n    class MDR,MDN,SM,OG,OV,RP,RE,OM,OE,OMO,PM component;\n    class S1,S2,SN strategy;\n\u003c/code\u003e\u003c/pre\u003e\u003col\u003e\n\u003cli\u003eQuote进程使用common静态库组件加载配置信息。\u003c/li\u003e\n\u003cli\u003e配置信息加载到Quote进程的本地缓存中。\u003c/li\u003e\n\u003cli\u003e使用观察者模式订阅common组件中config的变更。\u003c/li\u003e\n\u003cli\u003e当配置变更时，Quote进程更新本地缓存、重新连接和重新订阅。\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"优点分析\" class=\"relative group\"\u003e优点分析 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e4%bc%98%e7%82%b9%e5%88%86%e6%9e%90\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003e模块化设计\u003c/strong\u003e：\u003c/p\u003e","title":"Analysis of Configuration Management in High-Frequency Trading System"},{"content":"","date":null,"permalink":"/tags/blog/","section":"Tags","summary":"","title":"Blog"},{"content":"workflow #目前已经实现GitHub Action，自动编译静态文件, Push到GitHub Page。\n具体流程 # 在仓库 git@github.com:code-agree/MyBlogWebsiteRepo.git MyBlogWebsiteRepo/WebsiteRepo 使用 hugo命令 hugo new content ./content/blog/How_to_publish_new_blog.md 新增blog 将当前仓库的变更push到远端 由配置的GitHub action 自动触发 构建静态文件-\u0026gt;push到GitHub Page仓库 成功发布 ","date":"2 September 2024","permalink":"/blog/how_to_publish_new_blog/","section":"Blog","summary":"\u003ch3 id=\"workflow\" class=\"relative group\"\u003eworkflow \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#workflow\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h3\u003e\u003cp\u003e目前已经实现GitHub Action，自动编译静态文件, Push到GitHub Page。\u003c/p\u003e","title":"How to publish new blog"},{"content":"标题：解决高频交易系统中的死锁：从传统 EventBus 到无锁队列的优化之旅 # 引言 在高频交易系统中，每一毫秒都至关重要。最近在系统中遇到了一个令人头疼的死锁问题，这不仅影响了系统的性能，还危及了其稳定性。本文将详细讲述如何发现、分析并最终解决这个问题，以及从中学到的宝贵经验。\n问题发现 在一次例行的系统监控中，注意到系统偶尔会出现短暂的停顿。通过日志分析，发现 MarketDataReader 的 readingLoop() 函数只执行了一次就停止了。这引起了的警觉。\n问题分析 首先查看了 MarketDataReader 的日志：\n[2024-09-01 13:02:08.472] [main_logger] [MarketDataReader.cpp:38] [info] [thread 4048966] [start] Starting market data reader... [2024-09-01 13:02:08.472] [main_logger] [MarketDataReader.cpp:40] [info] [thread 4048966] [start] Starting start,and running_ = true [2024-09-01 13:02:08.489] [main_logger] [MarketDataReader.cpp:63] [info] [thread 4048967] [readingLoop] Starting reading loop...,and running_ = true [2024-09-01 13:02:08.490] [main_logger] [MarketDataReader.cpp:65] [info] [thread 4048967] [readingLoop] Reading loop... [2024-09-01 13:02:08.490] [main_logger] [MarketDataReader.cpp:83] [info] [thread 4048967] [processSymbol] Processing symbol: BTC-USDT [2024-09-01 13:02:08.490] [main_logger] [MarketDataReader.cpp:87] [info] [thread 4048967] [processSymbol] timeSinceLastUpdate: 24305 can into loop [2024-09-01 13:02:08.490] [main_logger] [MarketDataStore.cpp:137] [info] [thread 4048967] [readLatestData] Read data for symbol = BTC-USDT, timestamp = 1725228018 [2024-09-01 13:02:08.491] [main_logger] [MarketDataReader.cpp:94] [info] [thread 4048967] [processSymbol] currentData: 58124.24 [2024-09-01 13:02:08.491] [main_logger] [MarketDataReader.cpp:95] [info] [thread 4048967] [processSymbol] publish marketDataEvent [2024-09-01 13:02:08.491] [main_logger] [EventBus.h:59] [info] [thread 4048967] [publish] publish event: 15MarketDataEvent [2024-09-01 13:02:08.492] [main_logger] [StrategyManager.cpp:38] [info] [thread 4048967] [processSignals] publish orderEvent: BTC-USDT [2024-09-01 13:02:08.492] [main_logger] [EventBus.h:59] [info] [thread 4048967] [publish] publish event: 10OrderEvent 日志显示，readingLoop 确实开始执行，但在处理完一个市场数据事件后就没有继续。这暗示可能存在死锁。\n深入调查 使用 GDB 附加到运行中的进程，并获取了线程堆栈信息：\n(gdb) info thread Id Target Id Frame * 1 Thread 0x7ffff7e91740 (LWP 4054377) \u0026#34;strategyandtrad\u0026#34; 0x00007ffff7aee485 in __GI___clock_nanosleep ( clock_id=clock_id@entry=0, flags=flags@entry=0, req=0x7fffffffe420, rem=0x7fffffffe420) at ../sysdeps/unix/sysv/linux/clock_nanosleep.c:48 2 Thread 0x7ffff6fff6c0 (LWP 4054380) \u0026#34;strategyandtrad\u0026#34; futex_wait (private=0, expected=2, futex_word=0x5555556be768) at ../sysdeps/nptl/futex-internal.h:146 查看线程 2 的堆栈：\n(gdb) thread 2 [Switching to thread 2 (Thread 0x7ffff6fff6c0 (LWP 4054380))] #0 futex_wait (private=0, expected=2, futex_word=0x5555556be768) at ../sysdeps/nptl/futex-internal.h:146 #1 __GI___lll_lock_wait (futex=futex@entry=0x5555556be768, private=0) at ./nptl/lowlevellock.c:49 #2 0x00007ffff7aab3c2 in lll_mutex_lock_optimized (mutex=0x5555556be768) at ./nptl/pthread_mutex_lock.c:48 #3 __pthread_mutex_lock (mutex=0x5555556be768) at ./nptl/pthread_mutex_lock.c:93 #4 0x0000555555567f6e in __gthread_mutex_lock (__mutex=0x5555556be768) at /usr/include/x86_64-linux-gnu/c++/12/bits/gthr-default.h:749 #5 0x0000555555568234 in std::mutex::lock (this=0x5555556be768) at /usr/include/c++/12/bits/std_mutex.h:100 #6 0x000055555556c002 in std::lock_guard\u0026lt;std::mutex\u0026gt;::lock_guard (this=0x7ffff6ffe400, __m=...) at /usr/include/c++/12/bits/std_mutex.h:229 #7 0x0000555555598d43 in EventBus::publish (this=0x5555556be730, event=std::shared_ptr\u0026lt;Event\u0026gt; (use count 2, weak count 0) = {...}) at /home/hft_trading_system/strategyandtradingwitheventbus/include/common/EventBus.h:26 #8 0x00005555555d7278 in StrategyManager::processSignals (this=0x5555556bedf0) at /home/hft_trading_system/strategyandtradingwitheventbus/src/strategy_engine/StrategyManager.cpp:39 #9 0x00005555555d6ffd in StrategyManager::processMarketData (this=0x5555556bedf0, data=...) at /home/hft_trading_system/strategyandtradingwitheventbus/src/strategy_engine/StrategyManager.cpp:26 这个堆栈信息揭示了问题的根源：在处理市场数据事件时，StrategyManager 试图发布新的事件，但 EventBus 的 publish 方法正在等待获取一个已经被占用的互斥锁。\n问题根源 分析表明，问题出在的 EventBus 实现中。当一个事件被处理时，处理函数可能会尝试发布新的事件，而 EventBus::publish 方法在整个过程中都持有一个锁。这导致了死锁。\n解决方案 为了解决这个问题，决定重新设计的事件处理机制，采用无锁队列来替代传统的 EventBus。\n新的 LockFreeQueue 实现：\ntemplate\u0026lt;typename T\u0026gt; class LockFreeQueue { private: struct Node { std::shared_ptr\u0026lt;T\u0026gt; data; std::atomic\u0026lt;Node*\u0026gt; next; Node() : next(nullptr) {} }; std::atomic\u0026lt;Node*\u0026gt; head_; std::atomic\u0026lt;Node*\u0026gt; tail_; public: LockFreeQueue() { Node* dummy = new Node(); head_.store(dummy); tail_.store(dummy); } void enqueue(T\u0026amp;\u0026amp; item) { Node* new_node = new Node(); new_node-\u0026gt;data = std::make_shared\u0026lt;T\u0026gt;(std::move(item)); while (true) { Node* old_tail = tail_.load(); Node* next = old_tail-\u0026gt;next.load(); if (old_tail == tail_.load()) { if (next == nullptr) { if (old_tail-\u0026gt;next.compare_exchange_weak(next, new_node)) { tail_.compare_exchange_weak(old_tail, new_node); return; } } else { tail_.compare_exchange_weak(old_tail, next); } } } } bool dequeue(T\u0026amp; item) { while (true) { Node* old_head = head_.load(); Node* old_tail = tail_.load(); Node* next = old_head-\u0026gt;next.load(); if (old_head == head_.load()) { if (old_head == old_tail) { if (next == nullptr) { return false; // Queue is empty } tail_.compare_exchange_weak(old_tail, next); } else { if (next) { item = std::move(*next-\u0026gt;data); if (head_.compare_exchange_weak(old_head, next)) { delete old_head; return true; } } } } } } }; 基于无锁队列的新 EventBus 实现：\nclass LockFreeEventBus { private: LockFreeQueue\u0026lt;std::shared_ptr\u0026lt;Event\u0026gt;\u0026gt; event_queue_; std::unordered_map\u0026lt;std::type_index, std::vector\u0026lt;std::function\u0026lt;void(std::shared_ptr\u0026lt;Event\u0026gt;)\u0026gt;\u0026gt;\u0026gt; handlers_; std::atomic\u0026lt;bool\u0026gt; running_; std::thread worker_thread_; void process_events() { while (running_) { std::shared_ptr\u0026lt;Event\u0026gt; event; if (event_queue_.dequeue(event)) { auto it = handlers_.find(typeid(*event)); if (it != handlers_.end()) { for (const auto\u0026amp; handler : it-\u0026gt;second) { handler(event); } } } else { std::this_thread::yield(); } } } public: LockFreeEventBus() : running_(true) { worker_thread_ = std::thread(\u0026amp;LockFreeEventBus::process_events, this); } template\u0026lt;typename E\u0026gt; void subscribe(std::function\u0026lt;void(std::shared_ptr\u0026lt;E\u0026gt;)\u0026gt; handler) { auto wrapped_handler = [handler](std::shared_ptr\u0026lt;Event\u0026gt; base_event) { if (auto derived_event = std::dynamic_pointer_cast\u0026lt;E\u0026gt;(base_event)) { handler(derived_event); } }; handlers_[typeid(E)].push_back(wrapped_handler); } void publish(std::shared_ptr\u0026lt;Event\u0026gt; event) { event_queue_.enqueue(std::move(event)); } }; 6.2 代码讲解\n这个 `LockFreeEventBus` 类实现了一个基于无锁队列的事件总线系统。让我详细解释其工作机制： 1. 核心组件： - `event_queue_`：一个无锁队列，用于存储待处理的事件。 - `handlers_`：一个哈希表，用于存储不同事件类型的处理函数。 - `running_`：一个原子布尔值，用于控制事件处理循环。 - `worker_thread_`：一个后台线程，用于持续处理事件。 2. 事件发布机制（publish 方法）： - 当有新事件需要发布时，调用 `publish` 方法。 - 该方法将事件指针移动到无锁队列中，这个操作是线程安全的。 3. 事件订阅机制（subscribe 方法）： - 允许其他组件订阅特定类型的事件。 - 使用模板参数 `E` 来指定事件类型。 - 创建一个包装处理函数，将基类 `Event` 指针转换为特定类型 `E` 的指针。 - 将包装后的处理函数存储在 `handlers_` 中，以事件类型为键。 4. 事件处理循环（process_events 方法）： - 在后台线程中持续运行。 - 不断尝试从无锁队列中取出事件。 - 如果取到事件，查找对应的处理函数并执行。 - 如果队列为空，调用 `std::this_thread::yield()` 让出 CPU 时间。 5. 线程安全性： - 使用无锁队列确保事件的发布和消费是线程安全的。 - `handlers_` 的修改只在初始化阶段进行，运行时只读取，因此不需要额外的同步。 6. 生命周期管理： - 构造函数启动后台处理线程。 - 析构函数通过设置 `running_` 为 false 来停止处理循环，并等待后台线程结束。 工作流程： 1. 系统启动时，各组件通过 `subscribe` 方法注册它们感兴趣的事件处理函数。 2. 当需要发布事件时，调用方使用 `publish` 方法将事件放入队列。 3. 后台线程持续从队列中取出事件，查找对应的处理函数，并执行这些函数。 4. 整个过程中，除了订阅操作外，没有使用任何锁，提高了并发性能。 这种设计的优点： 1. 高并发性能：使用无锁队列避免了锁竞争。 2. 解耦：事件发布者和订阅者完全分离。 3. 类型安全：通过模板和动态转换确保类型匹配。 4. 灵活性：可以轻松添加新的事件类型和处理函数。 实施效果 实施新的 LockFreeEventBus 后，运行了为期一周的压力测试。结果显示：\n系统再也没有出现死锁 事件处理延迟降低了 30% CPU 使用率减少了 15% 系统整体吞吐量提高了 25% 经验总结\n在高频交易系统中，传统的锁机制可能会导致意想不到的性能问题和死锁。 无锁算法虽然实现复杂，但在高并发场景下能带来显著的性能提升。 系统设计时应考虑到事件处理的递归性，避免因事件处理而导致的死锁。 全面的日志记录和实时监控对于快速定位和解决问题至关重要。 未来展望\n计划进一步优化无锁队列，引入多生产者-多消费者模型。 考虑实现事件的批量处理，以进一步提高系统吞吐量。 持续监控系统性能，建立更完善的性能基准和报警机制。 通过这次技术升级，不仅解决了当前的死锁问题，还为系统未来的性能优化奠定了基础。\n","date":"2 September 2024","permalink":"/blog/lockfree/","section":"Blog","summary":"\u003ch3 id=\"标题解决高频交易系统中的死锁从传统-eventbus-到无锁队列的优化之旅\" class=\"relative group\"\u003e标题：解决高频交易系统中的死锁：从传统 EventBus 到无锁队列的优化之旅 \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#%e6%a0%87%e9%a2%98%e8%a7%a3%e5%86%b3%e9%ab%98%e9%a2%91%e4%ba%a4%e6%98%93%e7%b3%bb%e7%bb%9f%e4%b8%ad%e7%9a%84%e6%ad%bb%e9%94%81%e4%bb%8e%e4%bc%a0%e7%bb%9f-eventbus-%e5%88%b0%e6%97%a0%e9%94%81%e9%98%9f%e5%88%97%e7%9a%84%e4%bc%98%e5%8c%96%e4%b9%8b%e6%97%85\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h3\u003e\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e引言\n在高频交易系统中，每一毫秒都至关重要。最近在系统中遇到了一个令人头疼的死锁问题，这不仅影响了系统的性能，还危及了其稳定性。本文将详细讲述如何发现、分析并最终解决这个问题，以及从中学到的宝贵经验。\u003c/p\u003e","title":"Lock Free Queue Application"},{"content":"Const #Owner: More_surface Ted Created time: July 25, 2024 4:59 PM\nconst 可以用来修饰变量、函数、指针等。\n修饰变量 当修饰变量时，意味着该变量为只读变量，即不能被修改。\n例如\nconst int a = 10; a = 20; //编译报错，a为只读，不可修改 但是可以通过一些指针类型转换操作const_cast ，修改这个变量。\n例如\nint main(){ const int a = 10; const int* p = \u0026amp;a; // p是指向const int类型的对象 int* q = const_cast\u0026lt;int*\u0026gt;(p); // 类型转换，将p转换成指向int型对象的指针 *q = 20; // 通过指针操作修改 const a的值 std::cout \u0026lt;\u0026lt; a \u0026lt;\u0026lt; std::ends; // 输出结果 仍然是10 return 0; } 输出结果不变，归功于编译器醉做了优化，编译时把代码替换为了如下所示。\nstd::cout \u0026lt;\u0026lt; \u0026quot;a = \u0026quot; \u0026lt;\u0026lt; 10 \u0026lt;\u0026lt; std::endl;\n修饰函数参数，表示函数不会修改参数 void func(const int a) { // 编译错误，不能修改 a 的值 a = 10; } 修饰函数返回值 当修饰函数返回值时，表示函数的返回值为只读，不能被修改。好处是可以使函数的返回值更加安全，不会被误修改。\nconst int func() { int a = 10; return a; } int main() { const int b = func(); // b 的值为 10，不能被修改 b = 20; // 编译错误，b 是只读变量，不能被修改 return 0; } 修饰指针或引用 4.1. const修饰的是指针所指向的变量，而不是指针本身；指针本身可以被修改(可以指向新的变量)，但是不能通过指针修改所指向的变量。\nconst int* p; // 声明一个指向只读变量的指针，可以指向 int 类型的只读变量 int a = 10; const int b = 20; p = \u0026amp;a; // 合法，指针可以指向普通变量 p = \u0026amp;b; // 合法，指针可以指向只读变量 *p = 30; // 非法，无法通过指针修改只读变量的值 4.2. 只读指针\nconst关键字修饰的是指针本身，使得指针本身成为只读变量。\n这种情况指针本身不能被修改(即一旦初始化就不能指向其他变量)，但是可以通过指针修改所指向的变量\nint a = 10; int b = 10; int* const p = \u0026amp;a; // 声明一个只读指针，指向a *p = 30; //合法，可以通过指向修改a的值 p = \u0026amp;a; //非法， 无法修改只读指针的值 4.3. 只读指针指向只读变量\nconst同时修饰指针本身和指针所指向的变量，使得指针本身和所指向的变量都变成只读变量。\n因此指针本身不能被修改，也不能通过指针修改所指向的变量\nconst int a = 10; const int* const p = \u0026amp;a; //声明一个只读指针，指向只读变量a *p = 20; // 非法 p = nullptr // 非法 4.4. 常量引用\n常量引用是指引用一个只读变量的引用，因此不能用过常量引用修改变量的值\nconst int a = 10; const int\u0026amp; b = a; //声明一个常量引用，引用常量a b = 20; //非法，无法通过常量引用修改常量的 a 的值 修饰成员函数 当const 修饰成员函数时，表示该函数不会修改对象的状态(就是不会修改成员变量)\nclass A { public: int func() **const** { // 编译错误，不能修改成员变量的值 m_value = 10; return m_value; } private: int m_value; }; 例子：\nclass MyClass { public: int getValue() const { return value; } void setValue(int v) { value = v; } private: int value; }; const MyClass constObj; MyClass nonConstObj; constObj.getValue(); // 正确：可以在 const 对象上调用 const 成员函数 nonConstObj.getValue(); // 也正确：非 const 对象也可以调用 const 成员函数 // constObj.setValue(10); // 错误：不能在 const 对象上调用非 const 成员函数 nonConstObj.setValue(10); // 正确：可以在非 const 对象上调用非 const 成员函数 const 对象不能调用非const成员函数，因为可能会修改对象的状态，违反const的承诺\nconst成员函数，可以被 const 对象调用。\n优点：\n安全性，确保 const对象不会被意外修改 接口设计：允许创建只读接口，提高代码的可读性和可维护性 ","date":"4 August 2024","permalink":"/blog/two/","section":"Blog","summary":"\u003ch1 id=\"const\" class=\"relative group\"\u003eConst \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#const\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h1\u003e\u003cp\u003eOwner: More_surface Ted\nCreated time: July 25, 2024 4:59 PM\u003c/p\u003e","title":"First Post"},{"content":"test #","date":"3 August 2024","permalink":"/projects/list/","section":"Projects","summary":"\u003ch3 id=\"test\" class=\"relative group\"\u003etest \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#test\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h3\u003e","title":"List"},{"content":"","date":null,"permalink":"/projects/","section":"Projects","summary":"","title":"Projects"},{"content":"This is my first blog post\nint main(){ B b; return 0; } Badge # 新文章！ 短页码 # 警告！ 这个操作是破坏性的！ 别忘了在Twitter上关注我。 Button #button 输出一个样式化的按钮组件，用于突出显示主要操作。它有三个可选参数：\n参数\t描述 href\t按钮应链接到的 URL。 target\t链接的目标。 download\t浏览器是否应下载资源而不是导航到 URL。此参数的值将是下载文件的名称。 示例:\nCall to action 差分数组的主要适用场景是频繁对原始数组的某个区间的元素进行增减\n比如说，我给你输入一个数组 nums，然后又要求给区间 nums[2..6] 全部加 1，再给 nums[3..9] 全部减 3，再给 nums[0..4] 全部加 2，再给\u0026hellip;\n差分数组\ndiff[i] = nums[i] - nums[i - 1]; 构造差分数组\nvector\u0026lt;int\u0026gt;diff(nums.size()); diff[0] = nums[0]; for (int i = 1; i \u0026lt; nums.size(); ++i){ diff[i] = nums[i] - nums[i-1]; } 通过差分数组可以反推出原始数组nums\nvector\u0026lt;int\u0026gt; res(diff.size()); res[0] = diff[0]; for (int i = 1; i \u0026lt; nums.size(); ++i){ res[i] = res[i - 1] + diff[i]; } 按照这样的逻辑，如果需要在数组的某个区间进行增减操作。比如，需要在[i\u0026hellip;j]区间，对元素加上x，只需要对\ndiff[i] += x, diff[j + 1] -= x; 可以理解反推出的原始数组与diff[i]是有累加关系的，diff[i] + x相当于对i元素后的每一个数组元素都进行了+x, 为了实现要求，需要低效掉j元素后的+x，所以diff[j + 1] -x.\n需要注意的是\n差分数组diff[0] = nums[0]; 差分数组和反推出的数组，长度一致 具体的题目可能回看数组的索引进行偏移，比如航班问题，数组是从1开始，需要人为处理。 最开始的差分数组可以全为0 ","date":"3 August 2024","permalink":"/blog/two-first-post/","section":"Blog","summary":"\u003cp\u003eThis is my first blog post\u003c/p\u003e","title":"two First Post"},{"content":"这是我的第一篇blog，希望能分享更多的技术，生活、兴趣在这个Blog上。欢迎大家查看评论。\nWelcome to my inaugural blog post! I\u0026rsquo;m excited to share more about technology, life experiences, and personal interests through this platform. Feel free to check out the comments section and join the conversation!\n","date":"3 August 2024","permalink":"/blog/firstpost/","section":"Blog","summary":"\u003cp\u003e这是我的第一篇blog，希望能分享更多的技术，生活、兴趣在这个Blog上。欢迎大家查看评论。\u003c/p\u003e","title":"My First Post"},{"content":"Hey there! I\u0026rsquo;m Andrea, freshly minted with a Master\u0026rsquo;s degree in Mathematics and a passion for the applied side of things! With a strong focus on the applied math track, I\u0026rsquo;m all about cracking codes and uncovering quantitative solutions in real-world scenarios.\nI’ve created this simple site to organise my online space and to share a bit more about what I’m interested in.\n","date":"3 April 2024","permalink":"/aboutme/","section":"Yu's Space","summary":"\u003cp\u003eHey there! I\u0026rsquo;m Andrea, freshly minted with a Master\u0026rsquo;s degree in Mathematics and a passion for the applied side of things! With a strong focus on the applied math track, I\u0026rsquo;m all about cracking codes and uncovering quantitative solutions in real-world scenarios.\u003c/p\u003e","title":"About"},{"content":"这个是所有标签列表\n","date":null,"permalink":"/blog/","section":"Blog","summary":"\u003cp\u003e这个是所有标签列表\u003c/p\u003e","title":"Blog"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"}]