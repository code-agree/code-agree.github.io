<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Yu's Space</title><link>https://code-agree.github.io/</link><description>Recent content on Yu's Space</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Mon, 23 Jun 2025 15:39:27 +0800</lastBuildDate><atom:link href="https://code-agree.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>深入理解无锁队列：从原理到实践的完整指南</title><link>https://code-agree.github.io/blog/lock_free_queue/</link><pubDate>Wed, 11 Jun 2025 20:59:00 +0800</pubDate><guid>https://code-agree.github.io/blog/lock_free_queue/</guid><description>目录 # 为什么需要无锁队列？ 硬件基础：理解现代CPU的行为 内存序：无锁编程的核心武器 SPSC队列：最简单的无锁实现 进阶：多生产者多消费者的挑战 性能分析与最佳实践 实际应用场景与选择指南 1. 为什么需要无锁队列？ #传统锁机制的痛点 #想象一个高频交易系统，每秒需要处理数百万笔订单。传统的基于锁的队列会带来什么问题？
// 传统锁机制的队列 class ThreadSafeQueue { std::mutex mtx; std::queue&amp;lt;Order&amp;gt; orders; public: void push(Order order) { std::lock_guard&amp;lt;std::mutex&amp;gt; lock(mtx); // 可能阻塞！ orders.push(order); } Order pop() { std::lock_guard&amp;lt;std::mutex&amp;gt; lock(mtx); // 可能阻塞！ // ... 取数据 } }; 核心问题：
上下文切换开销：线程阻塞时需要保存/恢复CPU状态 锁竞争：多个线程同时访问时，只有一个能获得锁 优先级反转：高优先级线程可能被低优先级线程阻塞 不可预测的延迟：延迟取决于锁的竞争情况 无锁编程的承诺 #无锁编程通过原子操作和精心设计的算法，让多个线程能够无阻塞地协作：
// 无锁队列的理想状态 class LockFreeQueue { public: bool push(T item) { // 原子操作，永不阻塞 // 要么成功，要么失败，但不会等待 } std::optional&amp;lt;T&amp;gt; pop() { // 同样是原子操作 // 要么返回数据，要么返回空，但不会阻塞 } }; 关键优势：</description></item><item><title>深入理解 False Sharing：实测原子操作与缓存行对齐对性能的影响</title><link>https://code-agree.github.io/blog/2025-06-23-15-cache_false_sharing/</link><pubDate>Mon, 23 Jun 2025 15:39:27 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-23-15-cache_false_sharing/</guid><description>目录 #1. 引言 # False Sharing概念介绍 文章研究目标 2. 测试设计概览 # 测试用例矩阵 测试方法说明 3. 样例运行结果 # 普通变量 + False Sharing 普通变量 + 无False Sharing 原子变量 + False Sharing 原子变量 + 无False Sharing 4. 现象分析与原理解释 # False Sharing如何降低性能 alignas(64)避免False Sharing的原理 cache miss升高的原因分析 原子变量性能开销分析 5. 深入理解缓存一致性与原子操作 # MESI缓存一致性协议详解 普通变量与原子变量的对比 原子变量 + False sharing的性能影响 CPU指令层面的差异 缓存一致性协议的影响 微架构层面的详细分析 6. 实战优化建议 # 不同场景的优化策略 7. 总结 # False Sharing的关键要点 核心结论 8. 参考资料与相关阅读 #9. 附录：完整测试代码 # 引言 #在现代多核处理器架构中，缓存系统在性能中扮演着至关重要的角色。然而，当多个线程同时操作位于同一缓存行（Cache Line）内的不同变量时，即使它们并未共享变量本身，也可能导致频繁的缓存一致性协议交互，这就是著名的性能杀手——False Sharing。</description></item><item><title>C++原子操作内存序性能分析：seq_cst vs relaxed</title><link>https://code-agree.github.io/blog/2025-06-21-00-memory_order_performance_analyse/</link><pubDate>Sat, 21 Jun 2025 00:47:52 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-21-00-memory_order_performance_analyse/</guid><description>摘要 #本文分析了C++原子操作中不同内存序(memory ordering)对性能的影响，特别是比较了默认的顺序一致性(seq_cst)与宽松(relaxed)内存序在x86-64架构上的性能差异。通过实验测试、性能分析和汇编代码检查，我们发现即使在内存模型较强的x86架构上，不同内存序的选择仍然会产生可测量的性能差异。
1. 实验设计 #1.1 测试程序 #我们设计了两个版本的测试程序，它们在固定时间内执行原子变量的读取和计数操作，唯一区别是原子变量读取时使用的内存序不同：
seq_cst版本 (默认内存序):
void worker_seq_cst() { while (running_) { // 默认使用 seq_cst counter_.fetch_add(1, std::memory_order_relaxed); busy_loop(); } } relaxed版本 (显式指定宽松内存序):
void worker_relaxed_load() { while (running_.load(std::memory_order_relaxed)) { counter_.fetch_add(1, std::memory_order_relaxed); busy_loop(); } } 1.2 编译与执行环境 #测试程序使用以下命令编译：
g++ -std=c++11 -O0 -pthread atomic_test_seq_cst.cpp -o test_gcc_seq_cst g++ -std=c++11 -O0 -pthread atomic_test_relaxed.cpp -o test_gcc_relaxed 每个程序运行5秒钟，记录在此期间完成的操作次数。同时使用perf工具收集性能数据：
perf record -e cpu-clock:pppH ./test_gcc_seq_cst perf record -e cpu-clock:pppH ./test_gcc_relaxed 2. 实验结果 #2.1 执行计数结果 # 版本 操作计数 seq_cst 26,494,108 relaxed 26,660,082 性能差异：</description></item><item><title>LockFreeEventBus技术剖析：工作机制与性能瓶颈分析</title><link>https://code-agree.github.io/blog/2025-06-20-14-lockfreeeventbus_perf_case/</link><pubDate>Fri, 20 Jun 2025 14:38:58 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-20-14-lockfreeeventbus_perf_case/</guid><description>概述 #本文针对现有的LockFreeEventBus实现进行深入的性能分析和优化建议。当前实现采用了以下核心设计：
事件与处理函数映射：使用std::unordered_map建立事件类型到处理函数的映射关系 处理函数存储：使用std::vector存储每种事件类型对应的处理函数列表 事件分发机制：在高频调用场景下使用RTTI（运行时类型识别）机制进行事件分发 内存管理：大量使用智能指针进行事件对象的生命周期管理 虽然这种设计在功能上完整可靠，但在高频交易等对延迟极度敏感的场景下存在显著的性能瓶颈。本文将详细分析这些瓶颈的根本原因，并提出针对性的优化建议。
注意：本文是深入理解无锁队列：从原理到实践的完整指南的配套性能分析文章，建议先阅读该文章了解无锁队列的基本原理。
1. 核心工作机制 #1.1 基本架构 #LockFreeEventBus采用无锁队列和工作线程的组合，实现事件的异步处理：
class LockFreeEventBus { private: LockFreeQueueEvent&amp;lt;std::shared_ptr&amp;lt;Event&amp;gt;&amp;gt; event_queue_; std::unordered_map&amp;lt;std::type_index, std::vector&amp;lt;std::function&amp;lt;void(std::shared_ptr&amp;lt;Event&amp;gt;)&amp;gt;&amp;gt;&amp;gt; handlers_; std::atomic&amp;lt;bool&amp;gt; running_; std::thread worker_thread_; // ... }; 关键组件：
event_queue_：无锁队列，存储待处理事件 handlers_：以事件类型为键的处理函数映射表 worker_thread_：单独工作线程，循环处理事件队列 1.2 事件发布流程 #void publish(std::shared_ptr&amp;lt;Event&amp;gt; event) { // 设置发布时间 event-&amp;gt;setPublishTime(std::chrono::high_resolution_clock::now()); // 更新队列统计 auto current_size = queue_size_.fetch_add(1) + 1; // ... // 入队 event_queue_.enqueue(std::move(event)); } 重要说明：发布事件只涉及队列操作，不会修改handlers_映射表。每次publish调用只是将事件对象加入队列，不涉及对处理函数映射表的任何读写操作。事件类型作为key在subscribe阶段已经确定，运行时的publish操作与handlers_映射表完全解耦。
1.3 事件处理流程 #void process_events() { while (running_) { std::shared_ptr&amp;lt;Event&amp;gt; event; if (event_queue_.dequeue(event)) { // 计算处理延迟 // .</description></item><item><title>高频交易中的订单数据结构设计与性能优化实战</title><link>https://code-agree.github.io/blog/2025-06-19-how_to_design_order_inlocalmemory/</link><pubDate>Thu, 19 Jun 2025 19:58:31 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-19-how_to_design_order_inlocalmemory/</guid><description>主题：基于并发读写性能优化的订单数据结构重构与底层机制剖析
目录 # 一、业务背景：订单状态的高并发维护 二、常见设计陷阱：char[] 字符串 ID 与哈希表的性能瓶颈 三、优化目标：极致的并发 + O(1) 访问性能 四、核心优化：整数 ID + array 映射结构 五、底层原理解析：为什么 array + int ID 更快? 1. 内存寻址机制(指针偏移) 2. CPU Cache Line 利用与伪共享问题 3. 避免堆分配与内存碎片 4. 内存序(Memory Ordering)选择与原子操作 5. 整数ID分配和回收机制 六、性能测试数据 七、关键组件优化示例 1. OrderBook实现优化 2. RingBuffer优化 八、NUMA架构下的内存访问优化 九、最终方案优势对比总结 九、结语：高频系统的设计哲学 一、业务背景：订单状态的高并发维护 #在高频交易(HFT)系统中，我们需要对数百万级别的订单状态进行并发读写，以支撑如下操作：
✅ 新增订单(add_order(order_id)) ✅ 修改订单状态(如 fill_qty, status 等) ✅ 高频查询订单状态(如成交均价、当前剩余量等) 这些操作高并发、延迟敏感，需要 O(1) 级别的响应，并且不能产生性能抖动或不可控的锁竞争。
二、常见设计陷阱：char[] 字符串 ID 与哈希表的性能瓶颈 #在早期系统中，常见的设计是以字符串 ID 作为订单主键，例如：
struct Order { char id[32]; char instId[16]; .</description></item><item><title>编译器优化级别技术解析</title><link>https://code-agree.github.io/blog/2025-06-19-compile_perf/</link><pubDate>Thu, 19 Jun 2025 04:00:00 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-19-compile_perf/</guid><description>1. 优化级别的本质与编译过程 #编译器优化是将源代码转换为更高效机器码的系统性过程，每个优化级别代表了不同的转换策略集合。要理解这些级别，首先需要了解编译器的工作流程：
词法分析 → 2. 语法分析 → 3. 语义分析 → 4. 中间表示生成 → 5. 优化 → 6. 代码生成 优化级别主要影响第5步，决定应用哪些转换算法及其激进程度。
2. -O0：零优化的底层机制 #核心原理 #-O0的本质是直接映射：保持源代码与生成的机器码之间的一一对应关系，几乎不进行任何转换。
底层实现机制 # 变量分配策略：
每个变量都分配独立的栈空间 即使是临时变量也会写回内存 不进行寄存器重用优化 指令生成逻辑：
严格按照源代码顺序生成指令 保留所有中间计算步骤 不合并冗余操作 函数调用处理：
严格遵循标准调用约定 保存和恢复所有可能被修改的寄存器 不进行任何内联或尾调用优化 技术深度剖析 #int calculate(int a, int b) { int temp = a * 2; return temp + b; } 在-O0级别，编译器生成的伪汇编代码：
calculate: push rbp ; 保存基址指针 mov rbp, rsp ; 建立新的栈帧 mov DWORD PTR [rbp-20], edi ; 存储参数a mov DWORD PTR [rbp-24], esi ; 存储参数b mov eax, DWORD PTR [rbp-20] ; 加载a add eax, eax ; a*2 mov DWORD PTR [rbp-4], eax ; 存储temp mov edx, DWORD PTR [rbp-4] ; 加载temp到edx mov eax, DWORD PTR [rbp-24] ; 加载b到eax add eax, edx ; b+temp pop rbp ; 恢复基址指针 ret ; 返回 这种实现方式的内存访问模式是：</description></item><item><title>Perf Report 分析完全指南 - 高频交易系统性能优化</title><link>https://code-agree.github.io/blog/2025-06-18-how_to_use_perf/</link><pubDate>Wed, 18 Jun 2025 03:03:07 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-18-how_to_use_perf/</guid><description>目录 # 高频交易系统性能优化思路 Perf 基础知识 perf record 命令参数详解 采样事件类型 Perf 能分析的关键指标 Perf Report 输出解析 列含义详解 分析方法论 高级分析技巧 实际优化流程 关键指标解读 使用Perf分析内存性能指标 高频交易系统案例分析 高频交易系统性能优化思路 #在高频交易系统中，微秒级的延迟差异可能直接影响交易策略的有效性和盈利能力。使用perf进行性能分析是优化高频交易系统的关键步骤。以下是一个系统化的优化思路：
1. 性能基准建立 #关键指标:
端到端延迟: 从行情接收到下单的完整路径时间 吞吐量: 每秒处理的订单/行情数量 尾延迟: 95/99/99.9百分位延迟 CPU利用率: 核心交易路径的CPU使用情况 # 建立基准性能数据 perf stat -e cycles,instructions,cache-references,cache-misses,branches,branch-misses -o perf_base.data -a -g ./strategyTrade 命令参数解释:
cycles: CPU周期数，用于测量程序执行所需的处理器周期总量 instructions: 执行的指令数，结合cycles可计算IPC(每周期指令数)，评估CPU利用效率 cache-references: 缓存访问次数，表示程序对CPU缓存的总访问量 cache-misses: 缓存未命中次数，高缓存未命中率会导致处理器等待内存，增加延迟 branches: 分支指令执行次数，反映程序中条件判断和跳转的频率 branch-misses: 分支预测失败次数，高失败率会导致流水线刷新，降低CPU效率 -o: 指定输出文件名 -a: 收集所有CPU核心的数据，全系统视图 -g: 收集调用图信息，便于分析函数调用关系 输出示例及解读:
Performance counter stats for &amp;#39;./strategyTrade&amp;#39;: 12,345,678,901 cycles # 总CPU周期数 24,680,046,512 instructions # 总指令数，指令/周期比约为2.</description></item><item><title>内存序</title><link>https://code-agree.github.io/blog/memory_order/</link><pubDate>Wed, 11 Jun 2025 02:15:43 +0800</pubDate><guid>https://code-agree.github.io/blog/memory_order/</guid><description>C++内存序与无锁编程 #引言 #在现代多核处理器上，高性能并发编程已经成为一项关键技能。C++11引入的原子操作和内存序模型为开发者提供了构建高效无锁数据结构的工具，但同时也带来了显著的复杂性。本文将深入探讨内存序的概念、不同内存序的语义差异，以及如何在实际应用中正确使用它们来构建高性能的无锁数据结构。
内存模型基础 #什么是内存模型 #内存模型定义了多线程程序中内存操作的可见性和顺序性规则。C++内存模型主要关注三个方面：
原子性(Atomicity): 操作是否可以被视为不可分割的整体 可见性(Visibility): 一个线程的写入何时对其他线程可见 顺序性(Ordering): 多个操作之间的执行顺序约束 重排序来源 #在现代计算机系统中，内存操作重排序可能来自三个层面：
编译器重排序: 编译器为了优化可能改变指令顺序 CPU重排序: 处理器可能乱序执行指令或延迟写入主存 缓存一致性: 多核系统中每个核心的缓存可能暂时不一致 happens-before关系 #C++内存模型的核心是建立操作间的happens-before关系：
如果操作A happens-before操作B，则A的结果对B可见 同一线程内的操作之间自动建立happens-before关系 跨线程的happens-before关系需要通过同步操作建立 内存栅栏(Memory Fence) #内存栅栏是一种同步原语，用于限制内存操作的重排序：
// 完整内存栅栏 std::atomic_thread_fence(std::memory_order_seq_cst); // 获取栅栏 std::atomic_thread_fence(std::memory_order_acquire); // 释放栅栏 std::atomic_thread_fence(std::memory_order_release); 栅栏与原子操作的区别在于，栅栏影响所有内存操作，而不仅限于特定的原子变量。
#pragma once #include &amp;lt;atomic&amp;gt; #include &amp;lt;array&amp;gt; #include &amp;lt;optional&amp;gt; #include &amp;lt;memory&amp;gt; #include &amp;lt;vector&amp;gt; namespace LockFreeQueues { // ============================================================================ // 1. 内存序详细演示 // ============================================================================ class MemoryOrderingDemo { private: std::atomic&amp;lt;int&amp;gt; data{0}; std::atomic&amp;lt;bool&amp;gt; flag{false}; public: // 演示不同内存序的行为差异 void demonstrateRelaxed() { // relaxed: 只保证原子性，允许重排序 data.</description></item><item><title>c++ 模版</title><link>https://code-agree.github.io/blog/template_class/</link><pubDate>Tue, 10 Jun 2025 22:48:21 +0800</pubDate><guid>https://code-agree.github.io/blog/template_class/</guid><description>1. 分类 #有三种不同的模版类型，
Function templates class templates Variable templates 1.1. function templates #template&amp;lt;typename T&amp;gt; T max(T a, T b) { return (a &amp;gt; b) ? a : b; } // 使用：编译器自动推导类型 int x = max(3, 7); // T = int double y = max(3.14, 2.71); // T = double 多参数模版 template&amp;lt;typename T, typename U&amp;gt; auto add(T a, U b) { return a + b; } 函数模板的显式实例化 // 声明模板函数 template&amp;lt;typename T&amp;gt; void process(T value) { // 实现.</description></item><item><title>MmAvellaneda Stoikov</title><link>https://code-agree.github.io/blog/mmavellaneda-stoikov/</link><pubDate>Mon, 19 May 2025 13:38:50 +0800</pubDate><guid>https://code-agree.github.io/blog/mmavellaneda-stoikov/</guid><description>这篇论文 《Optimal High-Frequency Market Making》 实现并分析了 Avellaneda-Stoikov (2008) 的高频做市定价模型，并引入了一个动态库存控制模块，用于优化限价单的挂单量，以在保证盈利的同时控制库存风险。下面是详细解读：
📌 一、研究背景与动机 #高频做市商（HFT market makers）通过在订单簿中持续挂出买卖限价单来提供流动性，赚取 买卖价差（spread） 和 交易所提供的挂单返利（rebate）。但这同时会产生库存风险（inventory risk），即买入或卖出过多后，价格波动带来的风险。
Avellaneda-Stoikov 模型是其中一个经典的高频做市定价框架，它在假设股票价格服从布朗运动的基础上，通过求解最优控制问题得出最优报价策略。
📌 二、模型框架 #2.1 定价模型（Pricing） #基于 Avellaneda &amp;amp; Stoikov (2008)：
股票价格服从布朗运动： $dS_t = \sigma dW_t$ 市场深度与成交概率关系：$\lambda(\delta) = A e^{-\kappa \delta}$ 做市商目标是最大化终端时刻 $T$ 时的指数效用函数： $$ \max_{\delta_a, \delta_b} \mathbb{E}[-e^{-\gamma (X_T + q_T S_T)}] $$
推导结果是：
中间价（Indifference Price）： $$ r(s, t) = s - q\gamma\sigma^2(T - t) $$
最优总挂单价差（Spread）： $$ \delta_a + \delta_b = \gamma\sigma^2(T - t) + \ln\left(1 + \frac{\gamma}{\kappa} \right) $$</description></item><item><title>行情数据解析优化最佳实践</title><link>https://code-agree.github.io/blog/perf/</link><pubDate>Wed, 30 Apr 2025 03:54:56 +0800</pubDate><guid>https://code-agree.github.io/blog/perf/</guid><description>行情数据解析优化最佳实践 #原始解析方案的性能瓶颈 #原始的 Binance 聚合交易数据解析实现存在多个性能瓶颈，这在高频交易系统中尤为关键。主要问题包括：
使用 std::stod 进行字符串到浮点数转换：
result.data.price = std::stod(std::string(price_str)); result.data.quantity = std::stod(std::string(qty_str)); 这里存在两个严重问题：
std::stod 在底层实现中需要处理各种格式和本地化，导致计算开销大 每次调用都创建了临时 std::string 对象，增加了内存分配和释放的开销 创建临时的 padded_string 对象：
simdjson::padded_string padded_json{json}; simdjson::dom::element doc = parser.parse(padded_json); 这会导致额外的内存分配和复制，特别是在高频率处理消息时变得非常明显。
使用低效的字符串复制方法：
strncpy(result.data.symbol, doc[&amp;#34;s&amp;#34;].get_string().value().data(), sizeof(result.data.symbol) - 1); 标准的 strncpy 没有利用现代 CPU 的 SIMD 指令集优势。
异常处理成本：在解析热路径中大量使用 try-catch 结构，这会导致编译器生成额外代码，影响性能。
重复获取 JSON 节点：多次访问相同的 JSON 节点，每次都需要进行字符串哈希查找。
优化方案 #为了解决上述问题，我们实施了多层次的优化策略：
1. 自定义快速解析路径 #创建了一个专门针对 Binance 聚合交易数据格式的快速解析函数，完全跳过通用 JSON 解析器：
bool fastParseAggTrade(const std::string_view&amp;amp; json, Common::QuoteData::AggTradeData&amp;amp; data) noexcept { // 快速检查消息类型 const char* type_pattern = &amp;#34;\&amp;#34;e\&amp;#34;:\&amp;#34;aggTrade\&amp;#34;&amp;#34;; if (json.</description></item><item><title>TLS会话恢复（Session Resumption）</title><link>https://code-agree.github.io/blog/session_resumption/</link><pubDate>Fri, 07 Mar 2025 19:24:12 +0800</pubDate><guid>https://code-agree.github.io/blog/session_resumption/</guid><description>1. 会话恢复简介 #什么是会话恢复？ #TLS会话恢复是TLS协议的一项优化特性，允许客户端和服务器基于之前建立的安全会话快速恢复通信，跳过完整的握手过程。在TLS 1.3中，会话恢复主要通过**PSK（Pre-Shared Key，预共享密钥）**机制实现，而在TLS 1.2及更早版本中，也可以通过Session ID或Session Ticket实现。
为什么需要会话恢复？ # 性能优化： 完整握手（TLS 1.3）：1-RTT 会话恢复：1-RTT（或0-RTT） 显著减少连接建立时间 资源节省： 降低CPU开销（避免重复密钥交换） 减少网络带宽占用 2. TLS 1.3中的会话恢复机制 #工作流程对比 #完整握手（TLS 1.3） #Client Server | ClientHello | |--------------------&amp;gt;| | ServerHello | | EncryptedExt | | Certificate | | CertVerify | | Finished | |&amp;lt;--------------------| | Finished | |--------------------&amp;gt;| | NewSessionTicket | |&amp;lt;--------------------| RTT：1次往返 服务器在握手后发送NewSessionTicket，包含PSK和有效期信息。 会话恢复（1-RTT） #Client Server | ClientHello | | (with PSK) | |--------------------&amp;gt;| | ServerHello | | Finished | |&amp;lt;--------------------| | Finished | |--------------------&amp;gt;| RTT：1次往返 客户端使用之前保存的PSK直接恢复会话。 0-RTT（可选） #Client Server | ClientHello | | (with PSK + Early Data) | |--------------------&amp;gt;| | ServerHello | | Finished | |&amp;lt;--------------------| | Finished | |--------------------&amp;gt;| RTT：0次往返（早期数据随首次请求发送） 注意：0-RTT有重放攻击风险，仅适用于幂等请求。 3.</description></item><item><title>使用 Tailscale 实现 MacOS 设备远程连接教程</title><link>https://code-agree.github.io/blog/share_screen/</link><pubDate>Sun, 19 Jan 2025 11:15:08 +0800</pubDate><guid>https://code-agree.github.io/blog/share_screen/</guid><description>我来帮你编写一份详细的技术教程，介绍如何使用 Tailscale 在 MacOS 设备间实现远程连接。
使用 Tailscale 实现 MacOS 设备远程连接教程 #准备工作 # 确保两台 MacOS 设备都能正常访问互联网 准备一个 Tailscale 账号（可以使用 Google、GitHub 等账号登录） 详细步骤 #第一步：安装 Tailscale #在两台 MacOS 设备上分别安装 Tailscale：
访问 Tailscale 官网 (https://tailscale.com/download) 下载 MacOS 版本的安装包 打开下载的 .dmg 文件，将 Tailscale 拖入应用程序文件夹 第二步：登录和配置 # 在两台设备上启动 Tailscale 点击菜单栏的 Tailscale 图标 使用相同的账号登录 登录成功后，Tailscale 会自动为设备分配 IP 地址 点击菜单栏图标可以查看分配的 IP 地址（通常格式为 100.xx.xx.xx） 第三步：开启远程访问 #在被控制的 MacOS 设备上：
打开系统偏好设置 选择&amp;quot;共享&amp;quot; 勾选&amp;quot;远程管理&amp;quot;或&amp;quot;屏幕共享&amp;quot; 配置访问权限，可以选择： 允许所有用户 仅允许特定用户 第四步：建立连接 #在控制端 MacOS 设备上：
打开访达（Finder） 在菜单栏选择&amp;quot;前往&amp;quot; → &amp;ldquo;连接服务器&amp;rdquo;（或按下 Command + K） 在服务器地址栏输入：vnc://100.</description></item><item><title>共享内存多进程通信中的页面切换同步问题分析与解决</title><link>https://code-agree.github.io/blog/fix_share_page_position/</link><pubDate>Fri, 17 Jan 2025 04:21:23 +0800</pubDate><guid>https://code-agree.github.io/blog/fix_share_page_position/</guid><description>问题现象 #在多进程共享内存通信中，发现读取进程出现异常：
写入进程（线程3002707）正常写入数据
读取进程（线程3002791）卡在固定位置：
page: 0 write_pos: 134209160 read_pos: 134199368 问题定位过程 #1. 初步分析 #首先观察到一个关键现象：
Binance的读写正常 Bitget的读取卡在固定位置 两个交易所使用相同的共享内存机制 2. 代码分析 #检查共享内存管理的核心类：
写入机制： template&amp;lt;typename T&amp;gt; bool write(const TypedFrame&amp;lt;T&amp;gt;&amp;amp; frame) { // ... if (write_pos + frame_size &amp;gt; page_size_) { switchToNextPage(); write_pos = current_write_pos_.load(std::memory_order_relaxed); continue; } // ... std::atomic&amp;lt;size_t&amp;gt;* shared_write_pos = reinterpret_cast&amp;lt;std::atomic&amp;lt;size_t&amp;gt;*&amp;gt;(current_page_-&amp;gt;getData()); shared_write_pos-&amp;gt;store(write_pos + frame_size, std::memory_order_release); } 页面切换： void Journal::switchToNextPage() { current_page_ = page_engine_-&amp;gt;getNextPage(); current_write_pos_.store(0, std::memory_order_relaxed); } Page* PageEngine::getNextPage() { current_page_index_++; if (current_page_index_ &amp;gt;= pages_.</description></item><item><title>Solana_monitor</title><link>https://code-agree.github.io/blog/solana_monitor/</link><pubDate>Fri, 20 Dec 2024 03:08:38 +0800</pubDate><guid>https://code-agree.github.io/blog/solana_monitor/</guid><description>Solana链上交易监控最佳实践：从logsSubscribe到全方位监控 #背景介绍 #在Solana链上开发中，实时监控特定账户的交易活动是一个常见需求，特别是在构建跟单机器人这类对时效性要求较高的应用场景中。最初，我们可能会想到使用Solana提供的logsSubscribe WebSocket API来实现这个功能，因为它看起来是最直接的解决方案。然而，在实际应用中，我们发现这种方案存在一些限制和问题。
问题发现 #在使用logsSubscribe进行账户监控时，我们发现一个关键问题：某些确实发生的交易并没有被我们的监控系统捕获到。这个问题的发现促使我们深入研究Solana的交易日志机制，并最终设计了一个更全面的监控方案。
为什么会遗漏交易？ # 日志记录机制的局限性
程序可能不会在日志中明确记录所有涉及的账户地址 交易可能使用了PDA(Program Derived Address)或其他派生地址 某些DEX采用内部账户映射，而不是直接记录用户地址 mentions过滤器的限制
只能捕获在日志中明确提到目标地址的交易 无法捕获通过间接方式影响目标账户的交易 解决方案 #针对上述问题，我们设计了一个多维度监控方案，通过组合多种订阅方式来确保不会遗漏任何相关交易。
1. 三重订阅机制 #pub struct EnhancedTradeWatcher { target_account: Pubkey, ws_client: WebSocketClient, } impl EnhancedTradeWatcher { async fn setup_comprehensive_monitoring(&amp;amp;mut self) -&amp;gt; Result&amp;lt;()&amp;gt; { // 1. logsSubscribe - 捕获显式提及 let logs_sub = json!({ &amp;#34;jsonrpc&amp;#34;: &amp;#34;2.0&amp;#34;, &amp;#34;method&amp;#34;: &amp;#34;logsSubscribe&amp;#34;, &amp;#34;params&amp;#34;: [ { &amp;#34;mentions&amp;#34;: [self.target_account.to_string()], }, { &amp;#34;commitment&amp;#34;: &amp;#34;processed&amp;#34; } ] }); // 2. programSubscribe - 监控DEX程序 let dex_program_sub = json!</description></item><item><title>Solana链上交易监控技术分析</title><link>https://code-agree.github.io/blog/solana/</link><pubDate>Thu, 19 Dec 2024 01:32:32 +0800</pubDate><guid>https://code-agree.github.io/blog/solana/</guid><description>Solana链上交易监控技术分析 #1. Solana DEX 交易形式 #1.1 直接 DEX 交易 #用户直接与 DEX 合约交互，交易流程简单直接。
用户钱包 -&amp;gt; DEX程序 (如Raydium/Orca) -&amp;gt; Token Program 特点：
交易日志简洁，主要包含单个 DEX 程序的调用 容易识别交易平台和交易对 Token Program 的 transfer 指令较少 1.2 聚合器交易（Jupiter） #通过聚合器路由到单个或多个 DEX。
用户钱包 -&amp;gt; Jupiter -&amp;gt; DEX1/DEX2/... -&amp;gt; Token Program 特点：
包含 Jupiter 合约调用 可能涉及多个 DEX 交易日志较长，包含多个内部指令 可能有复杂的代币交换路径 1.3 智能路由交易 #一笔交易通过多个 DEX 串联完成。
用户钱包 -&amp;gt; 聚合器 -&amp;gt; DEX1 -&amp;gt; DEX2 -&amp;gt; DEX3 -&amp;gt; Token Program 特点：
交易路径最复杂 涉及多次代币交换 目的是获得最优价格 包含多个 Token Program 的 transfer 指令 2.</description></item><item><title>WebSocket消息处理线程CPU亲和性导致的消息阻塞故障分析</title><link>https://code-agree.github.io/blog/message_overstocked/</link><pubDate>Fri, 13 Dec 2024 05:15:51 +0800</pubDate><guid>https://code-agree.github.io/blog/message_overstocked/</guid><description>一、故障现象 #1.1 单endpoint模式故障 # 单个WebSocket连接时消息接收完全阻塞 日志显示消息处理线程启动后无法接收新消息 [2024-12-12 20:31:29.455] [error] [setThreadAffinity] Error calling pthread_setaffinity_np: 22 [2024-12-12 20:31:29.697] [info] Message thread started for endpoint: OkxPublic // 之后无消息接收日志 1.2 多endpoint模式部分正常 # 多个WebSocket连接时只有一个线程能正常接收消息 日志显示消息处理情况： [20:54:50.542] [thread 91374] Processing message for OkxPublic [20:54:50.640] [thread 91374] Processing message for OkxPublic // 只有一个线程在持续处理消息 二、系统架构分析 #2.1 WebSocket消息接收机制 #void WebSocketClient::receiveMessages(const MessageHandler&amp;amp; handler) { while (true) { try { // 1. 阻塞式接收WebSocket消息 int n = ws_-&amp;gt;receiveFrame(buffer.data(), buffer.size(), flags); // 2. 同步回调处理消息 if (n &amp;gt; 0) { handler(buffer.</description></item><item><title>高频交易系统中的大吞吐量订单发送机制</title><link>https://code-agree.github.io/blog/sendingorder/</link><pubDate>Thu, 12 Dec 2024 02:17:32 +0800</pubDate><guid>https://code-agree.github.io/blog/sendingorder/</guid><description>1. 需求背景 #在高频交易系统中，我们面临一个典型场景：需要同时处理三个关联订单（三角套利）。这些订单必须几乎同时发出以确保套利的有效性。
关键挑战：
订单必须同时或几乎同时发出 系统需要处理高并发的订单组 需要保证订单处理的稳定性和可靠性 2. 当前使用的两种处理订单的机制 # 无锁队列机制 订单生成后进入一个无锁队列 多个线程从队列中取订单进行处理 订单的发送通过RestClient进行，RestClient负责管理HTTP连接池并发送请求 分片机制 订单生成后根据某种规则分配到不同的分片 每个分片由固定的线程处理 同一组的订单被分配到同一个分片，确保组内订单的处理一致性 RestClient同样负责订单的发送 class OrderShard { private: struct OrderGroup { uint64_t groupId; uint64_t timestamp; std::vector&amp;lt;Order&amp;gt; orders; }; std::queue&amp;lt;OrderGroup&amp;gt; orderQueue_; std::mutex mutex_; std::condition_variable cv_; RestClient restClient_; public: void addOrderGroup(OrderGroup group) { { std::lock_guard&amp;lt;std::mutex&amp;gt; lock(mutex_); orderQueue_.push(std::move(group)); } cv_.notify_one(); } void processOrders() { while (running_) { OrderGroup group; { std::unique_lock&amp;lt;std::mutex&amp;gt; lock(mutex_); cv_.wait(lock, [this] { return !orderQueue_.empty() || !</description></item><item><title>高性能订单执行系统设计方案1</title><link>https://code-agree.github.io/blog/batch_order/</link><pubDate>Fri, 06 Dec 2024 17:45:16 +0800</pubDate><guid>https://code-agree.github.io/blog/batch_order/</guid><description>1. 背景问题 #1.1 性能挑战 # 高吞吐量订单处理需求 每个订单都需要 HTTP 请求 JWT Token 生成开销大 网络延迟敏感 1.2 主要痛点 # 单个订单发送造成网络请求过多 JWT Token 频繁生成浪费资源 大量订单并发可能导致系统瓶颈 2. 解决方案 #2.1 JWT Token 缓存机制 #class RestClient { private: static constexpr auto JWT_REFRESH_INTERVAL = std::chrono::seconds(110); // 预留刷新窗口 std::string getOrCreateJWT(const std::string&amp;amp; uri) { auto now = std::chrono::steady_clock::now(); if (!cache.token.empty() &amp;amp;&amp;amp; now &amp;lt; cache.expiryTime) { return cache.token; } cache.token = generateJWT(uri); cache.expiryTime = now + JWT_REFRESH_INTERVAL; return cache.token; } }; 优点：</description></item><item><title>高性能网络编程：io_uring 与内存优化技术详解</title><link>https://code-agree.github.io/blog/io_uring/</link><pubDate>Fri, 06 Dec 2024 06:04:25 +0800</pubDate><guid>https://code-agree.github.io/blog/io_uring/</guid><description>0. 内存管理优化 #0.1 大页内存 (Huge Pages) #大页内存是一种内存管理优化技术，主要优势：
减少 TLB (Translation Lookaside Buffer) 缺失 减少页表项数量 提高内存访问效率 系统配置和检查：
# 检查系统大页配置 cat /proc/meminfo | grep Huge # 配置大页 echo 20 &amp;gt; /proc/sys/vm/nr_hugepages # 分配20个大页 0.2 内存锁定 (Memory Locking) #防止内存被交换到磁盘，确保数据始终在物理内存中：
# 检查内存锁定限制 ulimit -l # 修改限制（需要root权限） echo &amp;#34;* soft memlock unlimited&amp;#34; &amp;gt;&amp;gt; /etc/security/limits.conf 0.3 内存优化实现 #struct IOBuffer { char* data; size_t size; explicit IOBuffer(size_t s) : size(s) { // 1. 尝试使用大页内存 data = static_cast&amp;lt;char*&amp;gt;(mmap(nullptr, size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS | MAP_HUGETLB, -1, 0)); if (data == MAP_FAILED) { // 2.</description></item><item><title>高频交易场景下的多WS连接低延时方案设计</title><link>https://code-agree.github.io/blog/multiquotedata/</link><pubDate>Tue, 03 Dec 2024 01:01:26 +0800</pubDate><guid>https://code-agree.github.io/blog/multiquotedata/</guid><description>1. 业务背景与挑战 #在高频交易系统中，需要同时维护多个WebSocket连接以订阅不同交易所的行情数据。主要挑战包括：
需要处理多个交易所的并发连接 对消息处理延迟有严格要求 需要保证数据处理的稳定性 系统资源（CPU、内存）的高效利用 2. 传统方案的局限 #2.1 传统消息队列方案 #// 常见的消息处理流程 WebSocket接收 -&amp;gt; 消息队列 -&amp;gt; 处理线程池 -&amp;gt; 业务处理 存在的问题：
消息经过队列带来额外延迟 线程切换开销大 内存拷贝次数多 资源竞争导致性能不稳定 3. 优化方案设计 #3.1 核心设计理念 # 零拷贝数据处理 CPU亲和性绑定 预分配内存 每个连接独立处理 3.2 关键组件设计 #struct ConnectionContext { // 连接基础信息 std::shared_ptr&amp;lt;WebSocketClient&amp;gt; client; std::string endpoint_name; // 性能优化相关 int cpu_core{-1}; // CPU核心绑定 char* direct_buffer{nullptr}; // 预分配缓冲区 static constexpr size_t BUFFER_SIZE = 64 * 1024; std::shared_ptr&amp;lt;MessageProcessor&amp;gt; dedicated_processor; // 资源管理 ~ConnectionContext() { if (direct_buffer) { munlock(direct_buffer, BUFFER_SIZE); munmap(direct_buffer, BUFFER_SIZE); } } // 禁用拷贝以保证资源安全 ConnectionContext(const ConnectionContext&amp;amp;) = delete; ConnectionContext&amp;amp; operator=(const ConnectionContext&amp;amp;) = delete; }; 3.</description></item><item><title>付鹏HSBC</title><link>https://code-agree.github.io/blog/fupeng/</link><pubDate>Sun, 01 Dec 2024 21:06:34 +0800</pubDate><guid>https://code-agree.github.io/blog/fupeng/</guid><description>HSBC 速记 汇丰私人财富规划
玺越世家 · 臻享沙龙 上海站
（速记稿）
时间：2024 年 11 月 24 日
地点：上海浦东文华东方酒店 LG1 层东方厅
主持人：女士们，先生们，各位尊敬的来宾，我是陈佳昊（音），我是汇丰私人财富规划上海分区总经理，我代表上海汇丰私人财富规划欢迎各位的莅临。
今天有很多新朋友，也有很多老朋友，我在周五的时候问过后台同事报名报了多少了，他告诉我们已经快要接近 200 人了，但从今天的规模来看，我感觉好像今天的人数还要再超过一些。
当然了，有一些是原先的老客户，也有很多是慕名而来，看到这次邀请的是付鹏先生，所以慕名而来。也有一些新朋友。在付鹏先生上台之前，请允许我对汇丰私人财富规划做简短的介绍。
汇丰私人财富规划是全球的战略重点之一，老朋友都知道，汇丰私人财富规划成立于 2020 年，距今刚好四年，在四年的过程中集团一直在给我们大力注资，也是集团里最重要的项目之一。
为什么聚焦在中国市场上？大家很多人都明白，中国中产阶级的人数在世界上占有量是最庞大的，随着中国经济的高速发展，中国人财富管理的需求逐步提升到很高的水准。所以，私人财富规划也会变成汇丰的重要战略之一。
介绍一下发展历史，从 2020 年汇丰私人财富规划成立，先是在上海和广州，总部离这里不远，汇丰总部就在国金，欢迎大家去坐一坐。逐步进入到杭州、深圳、北京、佛山，今年在苏州、成都开立了分支机构。
2020 年汇丰私人财富规划才刚刚成立，那汇丰的历史又是怎么样的？汇丰简称叫 HSBC，很多人会问 HSBC 四个字母分别代表着什么，可以跟大家简单介绍一下，H 代表的是香港的意思，S 代表的是上海的意思。很多人印象中以为汇丰是一家外资银行，但其实大家有所不知，其实汇丰在清朝的时候就在外滩已经设立了总部，现在这栋楼交给了浦发银行。1949 年之后，汇丰因为历史的原因退出了中国，在 WTO 之后回到了中国。
汇丰 1865 年成立至今已经有 100 多年了，那时候还是清朝的同治年间，同时已经在全球的 62 个国家还有 3900 多名客户，这段历史和这么大的分布也是汇丰很多同事内心的骄傲。我们跟很多客户做沟通的时候，经常会把这段历史拿出来跟大家讲一讲，就像这头石狮子，很多人都见过，但很多人都不知道它的历史，很多人在海报、广告、港元大钞上看过这个石狮子，原来在外滩上也有两座，现在放在上海博物馆里，前一阵儿我在博物馆参观的时候还看到了这两只石狮子，上面还有很多历史的痕迹，比如说战争而留下的弹孔，就在人民广场的博物馆里，大家有兴趣的话可以去看一下。
财富大矩阵与中国内地市场，汇丰集团对于中国私人财富规划业务的重视程度，在大矩阵中承担了很重要的地位。
每 100 位客户中，会有 87 位客户将汇丰私人财富规划视作为提供财富重要的主要品牌，提出了很多好评，82% 的调研者打出 9-10 分的高分。
也有一些比较有意思的话，如：“对产品内容的保障满意，公司大有保障；甄汇生活有一定的吸引力，汇丰的产品较贵但也愿意买，因为对汇丰私人财富规划师的认可。”
这两年提出一句比较新的 Slogan“懂你关心的，给你安心的”。
今天的活动我们邀请到了一位重量级嘉宾，他曾任职于雷曼兄弟、所罗门投资集团等全球顶尖金融机构，从事对冲基金等相关工作。他就是东北证券首席经济学家付鹏先生。让我们欢迎付鹏先生为我们带来《2024 年年终回顾和 2025 年展望——对冲风险 VS 软着陆》主题分享，有请付鹏先生！
付鹏：正值年底，虽然刚才汇丰一直强调大家不录音不录像，但大概率你挡不住。我在这儿讲话会谨慎一些，非常小心谨慎，大概率会有人透露出去，放到 YouTube 上，基本上所有见我都说付总我在 YouTube 上看过你的视频，我说那都是盗版的，靠盗版发财的也不少。</description></item><item><title>OrderBook 本地维护方案设计</title><link>https://code-agree.github.io/blog/orderbook/</link><pubDate>Wed, 27 Nov 2024 02:35:19 +0800</pubDate><guid>https://code-agree.github.io/blog/orderbook/</guid><description>OrderBook 本地维护方案设计 #一、业务背景 #OrderBook（订单簿）是反映市场深度和流动性的核心数据结构，其维护质量直接影响：
策略交易决策的准确性 风险控制的有效性 市场定价的及时性 1.1 业务价值 # 价格发现
实时反映市场供需状态 提供多层次价格信息 展示市场深度分布 交易决策支持
最优价格确定（NBBO） 流动性评估 交易成本估算 风险管理
市场异常监控 流动性风险评估 价格波动追踪 二、技术方案 #2.1 核心数据结构 #class LockFreeOrderBook { private: // 基础信息 std::string symbol_; // 状态管理 std::atomic&amp;lt;uint64_t&amp;gt; last_update_time_{0}; std::atomic&amp;lt;uint64_t&amp;gt; last_sequence_{0}; std::atomic&amp;lt;bool&amp;gt; initialized_{false}; // 价格档位存储 using PriceLevelMap = tbb::concurrent_map&amp;lt;double, PriceLevel, std::greater&amp;lt;&amp;gt;&amp;gt;; PriceLevelMap bids_; // 买盘 - 降序 PriceLevelMap asks_; // 卖盘 - 升序 }; // 价格档位结构 struct PriceLevel { double price; double quantity; uint64_t update_time; }; // 深度数据结构 struct DepthData { std::vector&amp;lt;PriceLevel&amp;gt; bids; std::vector&amp;lt;PriceLevel&amp;gt; asks; uint64_t sequence_num; uint64_t timestamp; }; 2.</description></item><item><title>内存映射（mmap）与零拷贝技术：深入理解和实践</title><link>https://code-agree.github.io/blog/zero_copy/</link><pubDate>Tue, 22 Oct 2024 01:23:46 +0800</pubDate><guid>https://code-agree.github.io/blog/zero_copy/</guid><description>1. 概述 #内存映射（mmap）是一种将文件或设备映射到内存的方法，而零拷贝是一种减少或避免数据在内核空间和用户空间之间不必要复制的技术。这两个概念密切相关，但又有所不同。
2. mmap 是零拷贝吗？ #答案是：mmap 本身不是零拷贝技术，但它可以实现零拷贝的效果。
2.1 mmap 的工作原理 # 当调用 mmap 时，操作系统会在虚拟内存中创建一个新的内存区域。 这个内存区域会映射到文件系统缓存（page cache）中的物理页面。 当程序访问这个内存区域时，如果相应的页面不在内存中，会触发缺页中断，操作系统会从磁盘加载数据到内存。 2.2 为什么 mmap 可以实现零拷贝 # 一旦映射建立，用户进程可以直接读写这个内存区域，而无需在用户空间和内核空间之间进行数据复制。 对于读操作，数据从磁盘读入 page cache 后，可以直接被用户进程访问，无需额外复制。 对于写操作，修改直接发生在 page cache 上，操作系统会在适当的时候将修改同步到磁盘。 3. mmap 与传统 I/O 的比较 #3.1 传统 read 系统调用 #char buffer[4096]; ssize_t bytes_read = read(fd, buffer, sizeof(buffer)); 这个过程涉及两次数据拷贝：
从磁盘到内核缓冲区 从内核缓冲区到用户空间缓冲区 3.2 使用 mmap #void* addr = mmap(NULL, file_size, PROT_READ, MAP_PRIVATE, fd, 0); // 直接访问 addr 指向的内存 mmap 减少了一次数据拷贝，数据直接从磁盘到用户可访问的内存。</description></item><item><title>GitHub私有仓库协同开发指南</title><link>https://code-agree.github.io/blog/project_manage/</link><pubDate>Wed, 16 Oct 2024 02:04:51 +0800</pubDate><guid>https://code-agree.github.io/blog/project_manage/</guid><description>目录 # 简介 仓库结构和分支策略 协作者权限管理 保护主分支 Pull Request 和代码审查流程 持续集成与部署 (CI/CD) 文档和沟通 最佳实践和注意事项 简介 #在没有高级 GitHub 功能的私有仓库中进行协同开发可能具有挑战性，但通过正确的实践和工具，我们可以建立一个高效、安全的开发环境。本指南总结了我们讨论的主要策略和技术。
仓库结构和分支策略 # 主分支：main（稳定、可部署的代码） 开发分支：main_for_dev（日常开发工作） 特性分支：从 main_for_dev 分出，用于开发新功能 工作流程：
从 main_for_dev 创建特性分支 在特性分支上开发 完成后，创建 Pull Request 到 main_for_dev 代码审查和测试 合并到 main_for_dev 定期将 main_for_dev 合并到 main 协作者权限管理 #GitHub 私有仓库提供以下权限级别：
Read Triage Write Maintain Admin 设置步骤：
进入仓库 &amp;ldquo;Settings&amp;rdquo; &amp;gt; &amp;ldquo;Collaborators and teams&amp;rdquo; 点击 &amp;ldquo;Add people&amp;rdquo; 或 &amp;ldquo;Add teams&amp;rdquo; 输入用户名并选择适当的权限级别 最佳实践：
遵循最小权限原则 定期审查和更新权限 保护主分支 #由于缺乏高级分支保护功能，我们采用以下策略：
团队约定：
禁止直接推送到 main 分支 所有更改通过 PR 进行 Git Hooks： 创建 pre-push hook（.</description></item><item><title>Fork机制详解：从基础到高级应用</title><link>https://code-agree.github.io/blog/fork/</link><pubDate>Tue, 15 Oct 2024 02:45:13 +0800</pubDate><guid>https://code-agree.github.io/blog/fork/</guid><description>1. 引言 #Fork是Unix/Linux系统中最基本也是最强大的系统调用之一。它允许一个进程创建一个新的进程,这个新进程是原进程的一个几乎完全相同的副本。本次技术分享将深入探讨fork机制,从基本概念到高级应用。
2. Fork的基本原理 #2.1 什么是Fork #Fork是一个系统调用,用于创建一个新的进程。新进程（称为子进程）是调用进程（称为父进程）的一个几乎完全相同的副本。
2.2 Fork的工作原理 #当一个进程调用fork时:
系统会创建一个新的进程。 新进程是父进程的一个副本,包括代码段、数据段、堆栈等。 子进程获得父进程数据空间、堆和栈的副本。 父进程和子进程继续执行fork调用之后的代码。 2.3 Fork的返回值 #Fork调用会返回两次:
在父进程中,返回子进程的PID。 在子进程中,返回0。 这允许程序区分父进程和子进程。
pid_t pid = fork(); if (pid &amp;gt; 0) { printf(&amp;#34;父进程\n&amp;#34;); } else if (pid == 0) { printf(&amp;#34;子进程\n&amp;#34;); } else { perror(&amp;#34;fork失败&amp;#34;); exit(1); } 3. Fork的高级特性 #3.1 写时复制 (Copy-on-Write) #为了提高效率,现代操作系统使用&amp;quot;写时复制&amp;quot;技术:
初始时,子进程与父进程共享同一物理内存。 只有当其中一个进程尝试修改内存时,才会创建该部分内存的副本。 这大大减少了fork的开销和内存使用。
3.2 文件描述符的继承 #子进程继承父进程的文件描述符。这意味着:
子进程可以访问父进程打开的文件。 父子进程共享文件偏移量。 int fd = open(&amp;#34;example.txt&amp;#34;, O_RDWR); if (fork() == 0) { // 子进程 write(fd, &amp;#34;Hello from child&amp;#34;, 16); } else { // 父进程 write(fd, &amp;#34;Hello from parent&amp;#34;, 17); } 3.</description></item><item><title>高频交易系统中的位域压缩技术</title><link>https://code-agree.github.io/blog/bit_field_compression/</link><pubDate>Sun, 13 Oct 2024 03:18:35 +0800</pubDate><guid>https://code-agree.github.io/blog/bit_field_compression/</guid><description>1. 基础概念 #1.1 二进制表示 # 计算机使用二进制（0和1）存储和处理数据 1 byte = 8 bits 32位整数可以表示从 0 到 2^32 - 1 的数值 1.2 位操作基础 # 与操作 (&amp;amp;): 两位都为1时结果为1，否则为0 或操作 (|): 至少一位为1时结果为1，否则为0 异或操作 (^): 两位不同时结果为1，相同时为0 非操作 (~): 将每一位取反 左移 (&amp;laquo;): 将所有位向左移动，右侧补0 右移 (&amp;raquo;): 将所有位向右移动，左侧补0或符号位 示例：
unsigned int a = 5; // 0101 unsigned int b = 3; // 0011 unsigned int and_result = a &amp;amp; b; // 0001 (1) unsigned int or_result = a | b; // 0111 (7) unsigned int xor_result = a ^ b; // 0110 (6) unsigned int not_result = ~a; // 11111111111111111111111111111010 (-6 in 2&amp;#39;s complement) unsigned int left_shift = a &amp;lt;&amp;lt; 1; // 1010 (10) unsigned int right_shift = a &amp;gt;&amp;gt; 1;// 0010 (2) 2.</description></item><item><title>高频交易系统中的市场数据存储优化</title><link>https://code-agree.github.io/blog/read/</link><pubDate>Sun, 29 Sep 2024 01:36:04 +0800</pubDate><guid>https://code-agree.github.io/blog/read/</guid><description>1. 背景介绍 #在高频交易系统中，市场数据的快速读取和处理是关键性能指标之一。我们的系统使用共享内存来存储和访问实时市场数据，其中 MarketDataStore 类负责管理这些数据。本文将讨论如何优化 MarketDataStore 中的 readLatestData 函数，以提高数据读取的效率。
2. 初始实现 #最初的 readLatestData 函数实现如下：
std::optional&amp;lt;MappedTickerData&amp;gt; MarketDataStore::readLatestData(const std::string&amp;amp; symbol) const { std::shared_lock&amp;lt;std::shared_mutex&amp;gt; lock(mutex); size_t offset = calculateOffset(symbol); MappedTickerData data; if (dataFile-&amp;gt;read(&amp;amp;data, offset, sizeof(MappedTickerData))) { if (data.timestamp != 0 &amp;amp;&amp;amp; std::string(data.product_id) == symbol) { return data; } else { LOG_WARN(&amp;#34;readLatestData symbol = {} failed&amp;#34;, symbol); return std::nullopt; } } else { LOG_ERROR(&amp;#34;Failed to read data for symbol = {}&amp;#34;, symbol); return std::nullopt; } } 这个实现存在几个性能瓶颈：</description></item><item><title>高频交易系统中的重连机制最佳实践</title><link>https://code-agree.github.io/blog/atom/</link><pubDate>Fri, 27 Sep 2024 01:35:21 +0800</pubDate><guid>https://code-agree.github.io/blog/atom/</guid><description>高频交易系统中的重连机制最佳实践 #背景 #在高频交易系统中，网络连接的稳定性至关重要。然而，由于网络波动或其他原因，连接可能会中断。为了确保系统的连续性和可靠性，需要实现一个高效的重连机制。然而，频繁的重连检查和处理可能导致重复重连，影响系统性能。
问题描述 #在现有实现中，主循环频繁检查 m_client-&amp;gt;needsReconnection()，如果需要重连，则调用 handleReconnect()。然而，由于主循环速度很快，可能在 resetReconnectionFlag() 生效前再次检查 needsReconnection()，导致重复调用 handleReconnect()。
解决方案 #通过使用原子操作和双重检查机制，确保重连过程的原子性和一致性，避免重复重连。
1. 定义连接状态管理 #使用原子变量来管理连接状态，确保线程安全。
class WebSocketClient { private: std::atomic&amp;lt;bool&amp;gt; isReconnecting{false}; std::atomic&amp;lt;bool&amp;gt; needsReconnection{false}; public: bool needsReconnection() const { return needsReconnection.load(std::memory_order_acquire); } bool tryInitiateReconnection() { bool expected = false; return isReconnecting.compare_exchange_strong(expected, true, std::memory_order_acq_rel); } void setNeedsReconnection(bool value) { needsReconnection.store(value, std::memory_order_release); } void resetReconnectionFlag() { needsReconnection.store(false, std::memory_order_release); isReconnecting.store(false, std::memory_order_release); } }; 2. 修改主循环 #在主循环中使用双重检查机制，确保重连过程的原子性。
void StrategyAndTrading::run() { initializeConnection(); marketDataReader-&amp;gt;start(); positionManager-&amp;gt;updatePositionsThread(); m_commonLib-&amp;gt;getConfigManager().configWatcher(); while (running_) { if (m_client-&amp;gt;needsReconnection() &amp;amp;&amp;amp; m_client-&amp;gt;tryInitiateReconnection()) { handleReconnect(); } // 执行其他高频交易逻辑 std::this_thread::sleep_for(std::chrono::microseconds(100)); // 微秒级的睡眠 } } 3.</description></item><item><title>高频交易系统优化：从数据读取到系统平衡的思考过程</title><link>https://code-agree.github.io/blog/datareader_design/</link><pubDate>Wed, 25 Sep 2024 01:04:59 +0800</pubDate><guid>https://code-agree.github.io/blog/datareader_design/</guid><description>1. 初始问题：数据读取效率 #最初，我们关注的是市场数据读取器本身的效率问题。
1.1 轮询方式（初始状态） #void MarketDataReader::readingLoop() { while (running) { for (const auto&amp;amp; symbol : symbols_) { processSymbol(symbol); } std::this_thread::sleep_for(std::chrono::milliseconds(100)); } } 问题：持续轮询即使在没有新数据时也会消耗资源。
1.2 条件控制方式 #void MarketDataReader::readingLoop() { while (running) { std::unique_lock&amp;lt;std::mutex&amp;gt; lock(conditionMutex); dataCondition.wait(lock, [this] { return !running || !symbols_.empty(); }); for (const auto&amp;amp; symbol : symbols_) { processSymbol(symbol); } } } 改进：减少了不必要的CPU使用，但可能会在高频数据更新时引入延迟。
思考转变：这个阶段，我们主要关注如何提高单个组件（数据读取器）的效率。
2. 扩展考虑：数据读取对其他系统组件的影响 #随着对系统的深入思考，我们开始考虑数据读取器的行为如何影响整个系统，特别是订单流的执行效率。
2.1 资源竞争问题 #观察：尽管我们优化了数据读取器的效率，但数据读取线程占据太多的计算资源，也会进而影响订单处理的性能。即使在没有新数据可读时，频繁的检查也会占用宝贵的计算资源。
思考：
数据读取和订单处理是否在竞争同样的系统资源（CPU、内存、I/O）？ 如何在保证数据及时性的同时，不影响订单处理的响应速度？ 如何协调各个线程，使系统达到最低的时延？ 2.2 自适应间隔机制 #引入动态调整处理间隔的机制，以平衡数据读取和系统资源使用。
void MarketDataReader::readingLoop() { while (running) { auto start = std::chrono::steady_clock::now(); for (const auto&amp;amp; symbol : symbols_) { processSymbol(symbol); } auto end = std::chrono::steady_clock::now(); auto duration = std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(end - start); if (duration &amp;lt; currentInterval) { std::this_thread::sleep_for(currentInterval - duration); } adjustInterval(); } } 思考转变：从单纯的效率优化转向了资源使用的平衡，考虑到了系统的整体性能。</description></item><item><title>实现高性能低延迟的交易系统设计</title><link>https://code-agree.github.io/blog/high_performance/</link><pubDate>Fri, 20 Sep 2024 22:32:08 +0800</pubDate><guid>https://code-agree.github.io/blog/high_performance/</guid><description>高性能低延迟交易系统设计：技术分享 update #在高频交易和实时金融系统中，性能和延迟是关键因素。本文将分享一些设计和实现高性能低延迟交易系统的关键技术和策略。
1. 数据结构优化 #1.1 内存映射（Memory-Mapped）文件 #使用内存映射文件可以显著提高I/O性能，减少系统调用，并允许快速的进程间通信。
class MmapOrderBook { // 使用内存映射文件存储订单簿数据 }; 1.2 自定义内存池 #实现自定义内存池可以减少内存分配和释放的开销，提高内存使用效率。
template&amp;lt;typename T, size_t MaxSize&amp;gt; class MemoryPool { // 实现高效的内存分配和回收 }; 2. 并发控制 #2.1 细粒度锁 #使用细粒度锁可以减少锁竞争，提高并发性能。
std::array&amp;lt;std::shared_mutex, MAX_POSITIONS&amp;gt; m_positionMutexes; 2.2 无锁数据结构 #在关键路径上使用无锁数据结构可以进一步减少同步开销。
std::atomic&amp;lt;double&amp;gt; quantity; std::atomic&amp;lt;double&amp;gt; averagePrice; 3. 高效的更新策略 #3.1 增量更新 vs 全量更新 #根据具体场景选择合适的更新策略。增量更新适合频繁的小幅度变化，全量更新适合大幅度变化或定期同步。
void updatePosition(const char* instId, AssetType type, PositionSide side, double quantityDelta, double price); void syncPositionWithExchange(const char* instId, AssetType type, PositionSide side, double quantity, double price); 3.</description></item><item><title>高频交易系统中的高层锁定：必要性与实现</title><link>https://code-agree.github.io/blog/mutex/</link><pubDate>Wed, 18 Sep 2024 17:29:59 +0800</pubDate><guid>https://code-agree.github.io/blog/mutex/</guid><description>在高频交易系统的开发中，我们经常面临着性能和正确性之间的权衡。最近，我们在优化订单处理流程时，发现了一个有趣的问题：是否需要在高层组件中实现锁定？本文将深入探讨这个问题，分析其必要性，并展示优化前后的实现。
背景 我们的系统主要由以下组件构成：
MmapOrderBook：核心数据存储，使用内存映射文件实现 PositionManager：负责仓位管理 OrderValidator：负责订单验证 OrderManager：负责订单处理流程 最初，我们的实现如下：
// OrderManager.cpp bool OrderManager::processOrder(const MmapOrderBook::Order&amp;amp; order) { if (!orderValidator_-&amp;gt;validateOrder(order)) { return false; } if (orderBook_-&amp;gt;addOrder(order)) { auto position = positionManager_-&amp;gt;getPosition(order.accountId, /* instrumentId */); if (position) { position-&amp;gt;quantity += order.isBuy ? order.quantity : -order.quantity; positionManager_-&amp;gt;updatePosition(*position); } // 发布订单已处理事件 return true; } return false; } 问题分析 虽然 MmapOrderBook 内部使用了分片锁来保证单个操作的线程安全，但我们发现这种方法在处理复合操作时可能存在问题。主要原因如下：
a) 复合操作的原子性： processOrder 方法包含多个相关操作（验证、添加、更新仓位），这些操作需要作为一个原子单元执行。
b) 避免竞态条件： 在验证订单和添加订单之间，系统状态可能发生变化，导致基于过时信息做出决策。
c) 保持不变量： 某些业务逻辑依赖于多个相关数据的一致状态，需要在整个操作过程中维护这些不变量。
d) 简化并发模型： 高层锁定可以简化并发模型，使代码更易于理解和维护。
e) 防止死锁： 复杂操作中可能需要获取多个低层锁，增加死锁风险。高层锁可以降低这种风险。</description></item><item><title>高频交易系统优化：从WebSocket到市场数据处理的全面解析</title><link>https://code-agree.github.io/blog/queue_usage2/</link><pubDate>Sun, 15 Sep 2024 04:03:51 +0800</pubDate><guid>https://code-agree.github.io/blog/queue_usage2/</guid><description>高频交易系统优化：从WebSocket到市场数据处理的全面解析 #在当今竞争激烈的金融市场中,高频交易(HFT)系统的性能直接关系到交易策略的成功与否。本文将深入探讨高频交易系统中两个关键环节的优化：WebSocket消息接收机制和市场数据处理。我们将分析当前最佳实践,探讨潜在的优化方向,并提供具体的代码示例。
1. WebSocket消息接收机制优化 #在高频交易系统中,每一毫秒的延迟都可能导致巨大的经济损失。因此,优化WebSocket消息的接收机制对于系统的整体性能至关重要。
1.1 WebSocketClient类设计与实现 #以下是一个高效的WebSocketClient类的实现示例：
class WebSocketClient { public: using MessageHandler = std::function&amp;lt;void(const char*, size_t)&amp;gt;; WebSocketClient(/* 构造函数参数 */) : ws_(nullptr), running_(false) {} void receiveMessages(MessageHandler handler) { if (!ws_) { throw std::runtime_error(&amp;#34;WebSocket is not connected&amp;#34;); } constexpr size_t BUFFER_SIZE = 1024 * 1024; // 1MB buffer std::array&amp;lt;char, BUFFER_SIZE&amp;gt; buffer; int flags; while (running_) { try { int n = ws_-&amp;gt;receiveFrame(buffer.data(), buffer.size(), flags); if (n &amp;gt; 0) { handler(buffer.data(), n); } else if (n == 0) { // 连接关闭 break; } } catch (const Poco::Exception&amp;amp; e) { // 仅在关键错误时记录日志 // 考虑添加重连逻辑 } } } void start() { running_ = true; } void stop() { running_ = false; } private: std::unique_ptr&amp;lt;Poco::Net::WebSocket&amp;gt; ws_; std::atomic&amp;lt;bool&amp;gt; running_; }; 1.</description></item><item><title>高频交易系统中市场数据处理：队列的利弊分析</title><link>https://code-agree.github.io/blog/queue_usage/</link><pubDate>Sun, 15 Sep 2024 03:57:13 +0800</pubDate><guid>https://code-agree.github.io/blog/queue_usage/</guid><description>高频交易系统中市场数据处理：队列的利弊分析 #在高频交易（HFT）系统中，处理市场数据的方式直接影响着系统的性能和延迟。使用队列是一种常见的数据处理方法，但在追求极低延迟的HFT系统中，这种选择是否合适需要仔细考虑。本文将分析使用队列的利弊，并探讨可能的替代方案。
1. 使用队列的优势 # 解耦和缓冲：队列可以有效地解耦数据生产者（如市场数据源）和消费者（如策略引擎），提供一个缓冲区来处理突发的数据流。
负载均衡：在多线程处理中，队列可以帮助分配工作负载，防止某个处理单元过载。
简化设计：队列提供了一个直观的数据流模型，可以简化系统的整体设计。
容错性：队列可以帮助系统更好地处理暂时的处理速度不匹配，增强系统的稳定性。
2. 使用队列的劣势 # 额外延迟：队列操作（入队和出队）会引入额外的延迟，即使是几微秒的延迟在HFT中也可能造成显著影响。
内存开销：队列需要额外的内存分配，这可能导致缓存未命中，进一步增加延迟。
上下文切换：在多线程环境中，队列操作可能导致频繁的上下文切换，增加系统开销。
顺序处理限制：队列通常按FIFO顺序处理数据，这可能不适合需要优先处理某些关键数据的场景。
潜在的锁竞争：在高并发情况下，队列可能成为竞争热点，导致性能下降。
3. 替代方案 #考虑到队列可能引入的延迟，以下是一些可能的替代方案：
3.1 无锁环形缓冲区（Lock-free Ring Buffer） #template&amp;lt;typename T, size_t Size&amp;gt; class LockFreeRingBuffer { private: std::array&amp;lt;T, Size&amp;gt; buffer_; std::atomic&amp;lt;size_t&amp;gt; head_{0}; std::atomic&amp;lt;size_t&amp;gt; tail_{0}; public: bool push(const T&amp;amp; item) { size_t current_tail = tail_.load(std::memory_order_relaxed); size_t next_tail = (current_tail + 1) % Size; if (next_tail == head_.load(std::memory_order_acquire)) return false; // Buffer is full buffer_[current_tail] = item; tail_.</description></item><item><title>Segmentation Fault Caused by std::string in Memory-Mapped File</title><link>https://code-agree.github.io/blog/string_mmap/</link><pubDate>Thu, 12 Sep 2024 15:23:23 +0800</pubDate><guid>https://code-agree.github.io/blog/string_mmap/</guid><description>故障复盘报告：内存映射文件中的 std::string 导致的段错误 #1. 问题描述 #在使用内存映射文件存储订单数据的过程中，程序在重启后出现段错误。具体表现为在尝试访问存储在内存映射文件中的 Order 结构体的 id 字段时，程序崩溃。
2. 错误信息 #程序崩溃时的 GDB 调试信息如下：
Thread 2 &amp;#34;strategyandtrad&amp;#34; received signal SIGSEGV, Segmentation fault. [Switching to Thread 0x7ffff6f4c6c0 (LWP 446582)] __memcmp_sse2 () at ../sysdeps/x86_64/multiarch/memcmp-sse2.S:258 258 ../sysdeps/x86_64/multiarch/memcmp-sse2.S: No such file or directory. (gdb) bt #0 __memcmp_sse2 () at ../sysdeps/x86_64/multiarch/memcmp-sse2.S:258 #1 0x000055555556d79b in std::char_traits&amp;lt;char&amp;gt;::compare (__s1=0x7f4710000eb0 &amp;lt;error: Cannot access memory at address 0x7f4710000eb0&amp;gt;, __s2=0x7fffe8000c80 &amp;#34;ORD-1726124231791862593&amp;#34;, __n=23) at /usr/include/c++/12/bits/char_traits.h:385 #2 0x000055555559c599 in std::operator==&amp;lt;char&amp;gt; (__lhs=&amp;lt;error: Cannot access memory at address 0x7f4710000eb0&amp;gt;, __rhs=&amp;#34;ORD-1726124231791862593&amp;#34;) at /usr/include/c++/12/bits/basic_string.</description></item><item><title>Analysis of Configuration Management in High-Frequency Trading System</title><link>https://code-agree.github.io/blog/config_managemeng_in_hft_system/</link><pubDate>Fri, 06 Sep 2024 01:47:52 +0800</pubDate><guid>https://code-agree.github.io/blog/config_managemeng_in_hft_system/</guid><description>高频交易系统配置管理方案分析 #当前方案概述 # graph TB CommonLib[&amp;#34;Common Library (MMAP)&amp;#34;] Exchange[&amp;#34;Exchange&amp;#34;] subgraph StrategyAndTrading[&amp;#34;StrategyAndTrading Component&amp;#34;] MDR[&amp;#34;MarketDataReader&amp;#34;] MDN[&amp;#34;MarketDataNormalizer&amp;#34;] SM[&amp;#34;StrategyManager&amp;#34;] subgraph Strategies[&amp;#34;Strategies&amp;#34;] S1[&amp;#34;Strategy 1&amp;#34;] S2[&amp;#34;Strategy 2&amp;#34;] SN[&amp;#34;Strategy N&amp;#34;] end OG[&amp;#34;OrderGenerator&amp;#34;] OV[&amp;#34;OrderValidator&amp;#34;] RP[&amp;#34;RiskProfiler&amp;#34;] RE[&amp;#34;RiskEvaluator&amp;#34;] OM[&amp;#34;OrderManager&amp;#34;] OE[&amp;#34;OrderExecutor&amp;#34;] OMO[&amp;#34;OrderMonitor&amp;#34;] PM[&amp;#34;PositionManager&amp;#34;] end CommonLib --&amp;gt;|1. Read MMAP| MDR MDR --&amp;gt;|2. Raw Market Data| MDN MDN --&amp;gt;|3. Normalized Data| SM SM --&amp;gt;|4. Distribute Data| Strategies Strategies --&amp;gt;|5. Generate Signals| OG OG --&amp;gt;|6. Create Orders| OV OV --&amp;gt;|7. Validated Orders| RP RP --&amp;gt;|8.</description></item><item><title>How to publish new blog</title><link>https://code-agree.github.io/blog/how_to_publish_new_blog/</link><pubDate>Mon, 02 Sep 2024 12:36:27 +0800</pubDate><guid>https://code-agree.github.io/blog/how_to_publish_new_blog/</guid><description>workflow #目前已经实现GitHub Action，自动编译静态文件, Push到GitHub Page。
具体流程 # 在仓库 git@github.com:code-agree/MyBlogWebsiteRepo.git MyBlogWebsiteRepo/WebsiteRepo 使用 hugo命令 hugo new content ./content/blog/How_to_publish_new_blog.md 新增blog 将当前仓库的变更push到远端 由配置的GitHub action 自动触发 构建静态文件-&amp;gt;push到GitHub Page仓库 成功发布</description></item><item><title>Lock Free Queue Application</title><link>https://code-agree.github.io/blog/lockfree/</link><pubDate>Mon, 02 Sep 2024 02:10:33 +0800</pubDate><guid>https://code-agree.github.io/blog/lockfree/</guid><description>标题：解决高频交易系统中的死锁：从传统 EventBus 到无锁队列的优化之旅 # 引言 在高频交易系统中，每一毫秒都至关重要。最近在系统中遇到了一个令人头疼的死锁问题，这不仅影响了系统的性能，还危及了其稳定性。本文将详细讲述如何发现、分析并最终解决这个问题，以及从中学到的宝贵经验。
问题发现 在一次例行的系统监控中，注意到系统偶尔会出现短暂的停顿。通过日志分析，发现 MarketDataReader 的 readingLoop() 函数只执行了一次就停止了。这引起了的警觉。
问题分析 首先查看了 MarketDataReader 的日志：
[2024-09-01 13:02:08.472] [main_logger] [MarketDataReader.cpp:38] [info] [thread 4048966] [start] Starting market data reader... [2024-09-01 13:02:08.472] [main_logger] [MarketDataReader.cpp:40] [info] [thread 4048966] [start] Starting start,and running_ = true [2024-09-01 13:02:08.489] [main_logger] [MarketDataReader.cpp:63] [info] [thread 4048967] [readingLoop] Starting reading loop...,and running_ = true [2024-09-01 13:02:08.490] [main_logger] [MarketDataReader.cpp:65] [info] [thread 4048967] [readingLoop] Reading loop... [2024-09-01 13:02:08.490] [main_logger] [MarketDataReader.cpp:83] [info] [thread 4048967] [processSymbol] Processing symbol: BTC-USDT [2024-09-01 13:02:08.</description></item><item><title>First Post</title><link>https://code-agree.github.io/blog/two/</link><pubDate>Sun, 04 Aug 2024 00:13:28 +0800</pubDate><guid>https://code-agree.github.io/blog/two/</guid><description>Const #Owner: More_surface Ted Created time: July 25, 2024 4:59 PM
const 可以用来修饰变量、函数、指针等。
修饰变量 当修饰变量时，意味着该变量为只读变量，即不能被修改。
例如
const int a = 10; a = 20; //编译报错，a为只读，不可修改 但是可以通过一些指针类型转换操作const_cast ，修改这个变量。
例如
int main(){ const int a = 10; const int* p = &amp;amp;a; // p是指向const int类型的对象 int* q = const_cast&amp;lt;int*&amp;gt;(p); // 类型转换，将p转换成指向int型对象的指针 *q = 20; // 通过指针操作修改 const a的值 std::cout &amp;lt;&amp;lt; a &amp;lt;&amp;lt; std::ends; // 输出结果 仍然是10 return 0; } 输出结果不变，归功于编译器醉做了优化，编译时把代码替换为了如下所示。
std::cout &amp;lt;&amp;lt; &amp;quot;a = &amp;quot; &amp;lt;&amp;lt; 10 &amp;lt;&amp;lt; std::endl;</description></item><item><title>two First Post</title><link>https://code-agree.github.io/blog/two-first-post/</link><pubDate>Sat, 03 Aug 2024 00:13:28 +0800</pubDate><guid>https://code-agree.github.io/blog/two-first-post/</guid><description>This is my first blog post
int main(){ B b; return 0; } Badge # 新文章！ 短页码 # 警告！ 这个操作是破坏性的！ 别忘了在Twitter上关注我。 Button #button 输出一个样式化的按钮组件，用于突出显示主要操作。它有三个可选参数：
参数	描述 href	按钮应链接到的 URL。 target	链接的目标。 download	浏览器是否应下载资源而不是导航到 URL。此参数的值将是下载文件的名称。 示例:
Call to action 差分数组的主要适用场景是频繁对原始数组的某个区间的元素进行增减
比如说，我给你输入一个数组 nums，然后又要求给区间 nums[2..6] 全部加 1，再给 nums[3..9] 全部减 3，再给 nums[0..4] 全部加 2，再给&amp;hellip;
差分数组
diff[i] = nums[i] - nums[i - 1]; 构造差分数组
vector&amp;lt;int&amp;gt;diff(nums.size()); diff[0] = nums[0]; for (int i = 1; i &amp;lt; nums.</description></item><item><title>My First Post</title><link>https://code-agree.github.io/blog/firstpost/</link><pubDate>Sat, 03 Aug 2024 00:11:28 +0800</pubDate><guid>https://code-agree.github.io/blog/firstpost/</guid><description>这是我的第一篇blog，希望能分享更多的技术，生活、兴趣在这个Blog上。欢迎大家查看评论。
Welcome to my inaugural blog post! I&amp;rsquo;m excited to share more about technology, life experiences, and personal interests through this platform. Feel free to check out the comments section and join the conversation!</description></item><item><title>Prompt manager</title><link>https://code-agree.github.io/projects/first/</link><pubDate>Sat, 03 Aug 2024 00:00:00 +0800</pubDate><guid>https://code-agree.github.io/projects/first/</guid><description>project description #Prompt Manager is a Chrome extension designed to help users save, manage, and quickly access frequently used prompts. It&amp;rsquo;s perfect for writers, customer service representatives, or anyone who often uses repetitive text snippets in their daily work.
Main features #Save and manage text prompts Search through saved prompts Sort prompts by time or custom order Edit existing prompts Delete prompts One-click copy of prompts Import and export prompts for backup or transfer</description></item><item><title>Quant system</title><link>https://code-agree.github.io/projects/quant_system/</link><pubDate>Sat, 03 Aug 2024 00:00:00 +0800</pubDate><guid>https://code-agree.github.io/projects/quant_system/</guid><description>High-Frequency Trading System #Project Overview #Independently designed and developed a cutting-edge high-frequency trading system with industry-leading performance.
Key Features # Modular Architecture: Utilizing advanced C++17 and key design patterns Observer pattern for event-driven architecture Factory method for flexible algorithm creation Strategy pattern for interchangeable trading strategies Ultra-Low Latency Event Bus: Implemented using lock-free queues Optimized WebSocket: For high-throughput market data and order execution Memory-Mapped File I/O: Leveraging kernel-level page cache for asynchronous, low-latency disk operations Performance Metrics # Metric Performance Order Execution Latency &amp;lt; 50 μs Message Processing Throughput &amp;gt; 1,000 messages/second Technical Stack # C++ (C++17) WebSockets Lock-free algorithms Memory-mapped I/O SIMD optimization Event-driven architecture Specializations # Ultra-low latency systems Concurrent programming Design patterns Market microstructure Kernel-level optimizations Project Highlights # Advanced C++ Implementation: Leveraged cutting-edge C++17 features to create a robust and efficient system architecture.</description></item><item><title>About</title><link>https://code-agree.github.io/aboutme/</link><pubDate>Wed, 03 Apr 2024 00:00:00 +0000</pubDate><guid>https://code-agree.github.io/aboutme/</guid><description>Hey there! I&amp;rsquo;m Andrea, freshly minted with a Master&amp;rsquo;s degree in Mathematics and a passion for the applied side of things! With a strong focus on the applied math track, I&amp;rsquo;m all about cracking codes and uncovering quantitative solutions in real-world scenarios.
I’ve created this simple site to organise my online space and to share a bit more about what I’m interested in.</description></item></channel></rss>