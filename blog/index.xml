<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog on Yu's Space</title><link>https://code-agree.github.io/blog/</link><description>Recent content in Blog on Yu's Space</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sun, 01 Jan 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://code-agree.github.io/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>深入理解无锁队列：从原理到实践的完整指南</title><link>https://code-agree.github.io/blog/2025-06-24-lock_free_queue_implementation/</link><pubDate>Wed, 11 Jun 2025 20:59:00 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-lock_free_queue_implementation/</guid><description>目录 # 为什么需要无锁队列？ 硬件基础：理解现代CPU的行为 内存序：无锁编程的核心武器 SPSC队列：最简单的无锁实现 进阶：多生产者多消费者的挑战 性能分析与最佳实践 实际应用场景与选择指南 1. 为什么需要无锁队列？ #传统锁机制的痛点 #想象一个高频交易系统，每秒需要处理数百万笔订单。传统的基于锁的队列会带来什么问题？
// 传统锁机制的队列 class ThreadSafeQueue { std::mutex mtx; std::queue&amp;lt;Order&amp;gt; orders; public: void push(Order order) { std::lock_guard&amp;lt;std::mutex&amp;gt; lock(mtx); // 可能阻塞！ orders.push(order); } Order pop() { std::lock_guard&amp;lt;std::mutex&amp;gt; lock(mtx); // 可能阻塞！ // ... 取数据 } }; 核心问题：
上下文切换开销：线程阻塞时需要保存/恢复CPU状态 锁竞争：多个线程同时访问时，只有一个能获得锁 优先级反转：高优先级线程可能被低优先级线程阻塞 不可预测的延迟：延迟取决于锁的竞争情况 无锁编程的承诺 #无锁编程通过原子操作和精心设计的算法，让多个线程能够无阻塞地协作：
// 无锁队列的理想状态 class LockFreeQueue { public: bool push(T item) { // 原子操作，永不阻塞 // 要么成功，要么失败，但不会等待 } std::optional&amp;lt;T&amp;gt; pop() { // 同样是原子操作 // 要么返回数据，要么返回空，但不会阻塞 } }; 关键优势：</description></item><item><title>高频交易系统中的背压机制设计讨论</title><link>https://code-agree.github.io/blog/2025-07-15-backpress/</link><pubDate>Tue, 15 Jul 2025 19:36:31 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-07-15-backpress/</guid><description>摘要 #在高频交易（HFT）系统中，当市场数据突发性爆增时，如何在保证超低延迟的前提下防止系统过载是一个关键技术挑战。本文深入分析了背压机制的原理、常见实现方式，并针对HFT系统的特殊需求，设计了一套基于数据优先级分层的混合背压策略。通过理论分析证明，该方案在保证关键数据零丢失的同时，能够有效应对trade数据的burst场景。
1. 背景与问题定义 #1.1 HFT系统的数据特征 #高频交易系统通常需要处理三类核心市场数据：
BBO（Best Bid Offer）数据：实时更新，对策略决策至关重要，频率约1000-10000次/秒 Orderbook数据：通常100ms更新一次，提供市场深度信息，数据量中等 Trade数据：实时更新，频率极高且具有突发性（burst）特征，正常情况下1000-5000次/秒，burst时可达50000+次/秒 1.2 Burst问题的本质 #在某些市场事件（如重大新闻发布、大单成交）触发下，trade数据可能在毫秒级时间窗口内激增至正常流量的10-100倍。这种突发性负载会导致：
内存溢出：缓冲区被大量trade数据填满 延迟恶化：处理延迟从微秒级恶化到毫秒级 数据丢失：关键的BBO和orderbook更新被遗漏 系统崩溃：极端情况下导致OOM或死锁 2. 背压机制理论基础 #2.1 背压的定义与数学模型 #背压（Backpressure）是一种流控制机制，当系统下游处理能力不足时，向上游传递&amp;quot;减缓输入&amp;quot;的信号，从而维持系统稳定性。
设系统输入速率为λ（events/second），处理速率为μ，缓冲区大小为B：
稳定条件：λ ≤ μ 缓冲区利用率：ρ = λ/μ 背压触发阈值：当缓冲区占用率 &amp;gt; θ（通常θ = 0.8）时启动 当λ &amp;gt; μ时，缓冲区积压量呈线性增长：
积压量(t) = (λ - μ) × t + 初始积压 背压机制的目标是通过动态调整有效输入速率λ&amp;rsquo;，使得λ&amp;rsquo; ≤ μ，从而保证系统稳定性。
2.2 背压的质量评估指标 # 延迟保障：P99延迟 &amp;lt; 目标阈值 吞吐保持：关键数据处理率 ≥ 99% 系统稳定性：内存使用率 &amp;lt; 安全阈值 数据完整性：重要数据丢失率 &amp;lt; 0.01% 3. 常见背压机制分析 #3.1 阻塞式背压（Blocking Backpressure） #原理：当缓冲区满时，阻塞生产者直到有空间可用。</description></item><item><title>深度解析：Asio在Linux平台的I/O模型本质</title><link>https://code-agree.github.io/blog/2025-07-09-asio/</link><pubDate>Wed, 09 Jul 2025 02:19:26 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-07-09-asio/</guid><description>在现代C++网络编程中，Boost.Asio（或standalone asio）是使用最广泛的异步I/O库之一。然而，关于Asio的I/O模型本质，特别是在Linux平台上的实现机制，存在很多误解。本文将深入剖析Asio在Linux平台的真实面目。
本质定位 #Asio的真实身份 #Asio在Linux平台上的本质：同步非阻塞I/O + I/O多路复用 + 回调机制的高级封装
这意味着：
✅ 不是传统的阻塞I/O：提供了异步编程接口 ❌ 不是真正的异步I/O：底层仍使用同步系统调用 ✅ 是异步编程框架：通过回调机制模拟异步编程体验 核心理解 #// Asio给你的印象（异步风格API） socket.async_read_some(buffer(data), [](error_code ec, size_t bytes) { // 看起来像异步回调 process_data(data, bytes); }); // 但Linux下的实际执行（简化） epoll_wait(epfd, events, 128, -1); // 同步等待事件 ssize_t n = read(fd, buffer, size); // 同步读取 callback(n); // 调用用户回调 关键洞察：Asio提供了异步的编程体验，但不是异步的执行机制。
工作原理 #事件驱动的执行模型 #Asio在Linux上实现了Reactor模式，而不是Proactor模式：
// Reactor模式的典型流程 class AsioReactor { public: void async_read(socket&amp;amp; s, buffer b, handler h) { // 1. 注册读取意图 register_read_intent(s.</description></item><item><title>I/O模型深度解析：多路复用、同步与异步的本质区别</title><link>https://code-agree.github.io/blog/2025-07-09-bio_nio/</link><pubDate>Wed, 09 Jul 2025 01:57:53 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-07-09-bio_nio/</guid><description>在高性能网络编程中，I/O模型的选择往往决定了系统的并发能力和性能表现。然而，关于I/O多路复用、同步I/O、异步I/O等概念，许多开发者存在理解上的误区。本文将深入剖析这些概念的本质区别，澄清常见的混淆点。
常见的概念混淆 #误区一：I/O多路复用就是异步I/O #这是最常见的误解。实际上，I/O多路复用本质上仍然是同步I/O。准确地说，多路复用的事件检测阶段是阻塞的（epoll_wait会阻塞），而实际的I/O读写阶段仍是同步操作。它只是提供了&amp;quot;等待多个同步I/O事件 + 显式事件通知&amp;quot;的机制，而不是真正的异步执行。
误区二：非阻塞I/O就是异步I/O #非阻塞I/O（NIO）虽然不会让线程阻塞等待，但仍然是同步I/O，因为应用程序需要主动调用系统调用并立即处理返回结果（包括&amp;quot;暂时无数据&amp;quot;的情况）。
系统层面的I/O模型分类 #1. 同步阻塞I/O (BIO) #特点：应用程序发起I/O调用后，线程阻塞等待操作完成。
int sockfd = socket(AF_INET, SOCK_STREAM, 0); char buffer[1024]; // 线程会阻塞在这里，直到有数据到达 ssize_t n = read(sockfd, buffer, sizeof(buffer)); if (n &amp;gt; 0) { process_data(buffer, n); } 应用场景：
连接数较少的服务 对实时性要求不高的应用 通常配合多线程使用 2. 同步非阻塞I/O (NIO) #特点：应用程序发起I/O调用后立即返回，需要主动检查操作状态。
int sockfd = socket(AF_INET, SOCK_STREAM, 0); // 设置为非阻塞模式 int flags = fcntl(sockfd, F_GETFL, 0); fcntl(sockfd, F_SETFL, flags | O_NONBLOCK); char buffer[1024]; ssize_t n = read(sockfd, buffer, sizeof(buffer)); if (n &amp;gt; 0) { // 成功读取数据 process_data(buffer, n); } else if (n == -1 &amp;amp;&amp;amp; errno == EAGAIN) { // 暂时无数据，需要稍后重试 // 这是关键：应用程序需要处理&amp;#34;未完成&amp;#34;状态 } else { // 发生错误 handle_error(); } 关键理解：read()调用立即返回，但返回的可能是&amp;quot;操作状态&amp;quot;而不是&amp;quot;完成的数据&amp;quot;。</description></item><item><title>DPDK + WebSocket客户端内存管理故障深度定位实录</title><link>https://code-agree.github.io/blog/2025-07-05-dpdk_application/</link><pubDate>Sat, 05 Jul 2025 01:38:06 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-07-05-dpdk_application/</guid><description>问题背景 #在开发基于DPDK的高性能WebSocket客户端时，遇到了典型的内存管理问题。该客户端使用了QuickWS框架，集成F-Stack网络栈和OpenSSL，在连接Binance WebSocket API进行高频数据接收测试时出现段错误。
技术栈概览 # 网络栈: DPDK + F-Stack WebSocket库: QuickWS (自定义高性能框架) SSL/TLS: OpenSSL 3.x 内存分配器: Flash Allocator (自定义分配器) 缓冲区: Ring Buffer with Flash Allocator 目标: 高吞吐量实时数据接收性能测试 故障现象 #Connected to Binance WebSocket stream! fd: 1 Accepted protocols: , extensions: Thread 1 &amp;#34;binance_client&amp;#34; received signal SIGSEGV, Segmentation fault. 定位过程 #第一阶段：环境问题排查 #初始现象: 程序在DPDK初始化阶段就出现问题
EAL: Auto-detected process type: SECONDARY EAL: Fail to recv reply for request /var/run/dpdk/rte/mp_socket:bus_vdev_mp 解决方案: 清理DPDK残留资源
sudo rm -rf /var/run/dpdk/rte/mp_socket* sudo rm -rf /dev/hugepages/* 关键发现: DPDK多进程模式的资源竞争会导致初始化挂起。</description></item><item><title>strace 完全使用指南</title><link>https://code-agree.github.io/blog/2025-07-03-strace/</link><pubDate>Thu, 03 Jul 2025 05:00:56 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-07-03-strace/</guid><description>strace 完全使用指南 #目录 # strace 简介 基础语法 核心参数详解 过滤和跟踪选项 输出格式控制 性能分析参数 实用场景示例 输出解读指南 性能调优技巧 最佳实践 1. strace 简介 #1.1 什么是 strace #strace 是 Linux 系统下的系统调用跟踪工具，它可以：
监控进程执行的所有系统调用 显示系统调用的参数和返回值 统计系统调用的执行时间和频率 跟踪信号传递过程 分析程序的系统级行为 1.2 主要用途 #性能分析 → 找出系统调用瓶颈 故障排查 → 定位程序异常原因 安全审计 → 监控程序系统访问 逆向分析 → 理解程序运行机制 系统调优 → 优化系统调用使用 2. 基础语法 #2.1 命令格式 ## 基础语法 strace [选项] [命令] strace [选项] -p &amp;lt;进程ID&amp;gt; # 示例 strace ls /tmp # 跟踪 ls 命令 strace -p 1234 # 跟踪进程ID为1234的进程 strace -e trace=network curl baidu.</description></item><item><title>DPDK性能验证技术分享</title><link>https://code-agree.github.io/blog/2025-07-03-dpdk_check/</link><pubDate>Thu, 03 Jul 2025 04:46:05 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-07-03-dpdk_check/</guid><description>目录 # DPDK性能优势概述 性能验证维度 系统调用分析 上下文切换监控 CPU使用效率分析 内存访问优化验证 网络性能基准测试 性能指标解读 验证方法总结 1. DPDK性能优势概述 #1.1 传统网络栈 vs DPDK架构 #传统网络栈流程：
应用程序 → Socket API → 内核网络栈 → 网卡驱动 → 硬件 ↑ 系统调用开销 ↑ 内核态/用户态切换 ↑ 数据拷贝 ↑ 中断处理 DPDK流程：
应用程序 → DPDK API → PMD → 硬件 ↑ 用户态直接操作 ↑ 零拷贝 ↑ 轮询模式 ↑ CPU绑定 1.2 理论性能提升 # 优化点 传统方式 DPDK方式 预期提升 延迟 50-100μs 5-20μs 3-10倍 吞吐量 1-5 Gbps 10-100 Gbps 10-20倍 CPU效率 50-70% 80-95% 1.</description></item><item><title>高频交易系统中的WebSocket网络缓冲区优化技术</title><link>https://code-agree.github.io/blog/2025-07-01-tcp_perf/</link><pubDate>Tue, 01 Jul 2025 18:06:02 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-07-01-tcp_perf/</guid><description>摘要 #本文深入探讨了高频交易系统中WebSocket连接的网络缓冲区优化技术，重点关注极低延迟性能优化。文章详细分析了TCP层优化、Socket缓冲区调优、大页内存应用以及网络栈各层次的性能优化策略，为构建微秒级延迟的交易系统提供了全面的技术指南。
1. 引言 #在现代金融市场中，高频交易系统的竞争优势很大程度上取决于其网络栈的性能。WebSocket作为一种全双工通信协议，已成为高频交易系统连接交易所和市场数据提供商的重要技术。然而，标准WebSocket实现通常无法满足高频交易对极低延迟的苛刻要求，这些系统需要微秒级别的响应时间。
本文旨在提供一个全面的网络缓冲区优化框架，从TCP底层协议到WebSocket应用层，系统性地探讨如何将延迟降至最低，尤其是通过优化网络缓冲区结构和内存访问模式。
2. 网络栈基础概念与缓冲区架构 #2.1 TCP与Socket的关系与区别 #在深入优化之前，需要明确TCP与Socket这两个核心概念的区别与联系：
概念层面 #TCP (传输控制协议):
是一种通信协议，定义了数据如何在网络上可靠传输的规则 是OSI模型中的传输层协议 规定了如何建立连接、传输数据、处理丢包、确保顺序、流量控制等机制 是一组规则和标准，而非具体实现 Socket (套接字):
是一个编程接口/抽象，是应用程序与网络协议交互的途径 可以看作是网络通信的&amp;quot;端点&amp;quot; 是操作系统提供的API，让应用程序能够使用网络功能 Socket不仅可以使用TCP，还可以使用UDP、Unix域等协议 比喻说明 #可以通过这个比喻理解：
TCP是一种语言和交流规则(如中文+礼仪规范) Socket是允许人们使用这种语言交流的电话机 代码层面区别 #TCP体现为协议参数和行为：
// 这些是TCP协议相关的选项 setsockopt(sockfd, IPPROTO_TCP, TCP_NODELAY, &amp;amp;flag, sizeof(flag)); setsockopt(sockfd, IPPROTO_TCP, TCP_KEEPALIVE, &amp;amp;flag, sizeof(flag)); Socket体现为创建和管理通信端点：
// 创建套接字 int sockfd = socket(AF_INET, SOCK_STREAM, 0); // SOCK_STREAM指定TCP协议 // 设置套接字选项 setsockopt(sockfd, SOL_SOCKET, SO_RCVBUF, &amp;amp;rcvbuf, sizeof(rcvbuf)); // 连接、发送、接收数据 connect(sockfd, ...); send(sockfd, ...); recv(sockfd, ...); 缓冲区层面的区别 #TCP缓冲区:</description></item><item><title>C++中inline函数为何比普通函数调用更快：深入解析</title><link>https://code-agree.github.io/blog/2025-06-24-inline_function_optimization/</link><pubDate>Tue, 24 Jun 2025 16:16:15 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-inline_function_optimization/</guid><description>目录 # 普通函数调用的开销 inline函数的优化 inline函数的局限性与权衡 示例代码与分析 什么时候使用inline函数？ 现代编译器的优化 总结 1. 普通函数调用的开销 #在C++中，普通函数调用涉及以下步骤，这些步骤会引入性能开销：
栈帧的创建与销毁： 调用函数时，程序需要保存当前函数的状态（例如寄存器中的值），为被调用函数分配栈空间，设置栈帧（包括返回地址、参数传递、局部变量等）。 函数返回时，需要恢复调用者的栈帧状态。 这些操作涉及栈指针（SP）和基指针（BP）的调整，以及内存的读写操作。 参数传递与返回值： 参数需要通过栈或寄存器传递到被调用函数，这可能涉及内存拷贝（尤其是对于较大的结构体或对象）。 返回值也需要通过寄存器或内存传递回调用者。 跳转开销： 函数调用需要将程序计数器（PC）跳转到被调用函数的地址（通过call指令），返回时再跳回调用者（通过ret指令）。 这种跳转可能会导致CPU指令流水线的刷新（pipeline flush），尤其是在分支预测失败的情况下。 寄存器上下文保存/恢复： 调用函数可能导致寄存器内容的保存与恢复（例如调用者保存的寄存器或被调用者保存的寄存器），增加额外的指令开销。 这些步骤虽然在现代CPU上非常快，但对于频繁调用的函数（例如小型、简单函数），这些开销可能占函数执行时间的显著比例。
2. inline函数的优化 #inline关键字建议编译器将函数的代码直接嵌入到调用处，而不是生成函数调用。这种内联（inlining）优化可以显著减少上述开销，原因如下：
消除函数调用开销： 内联函数的代码直接嵌入到调用处，省去了栈帧的创建与销毁、参数传递、返回值的处理以及跳转指令。 程序无需执行call和ret指令，也避免了可能的流水线刷新。 优化机会增加： 编译器在优化阶段可以看到内联函数的完整代码上下文，可以应用更多的优化技术，例如： 常量折叠：如果内联函数的参数是常量，编译器可以直接计算结果。 死代码消除：如果内联函数中某些分支在调用上下文中永远不会执行，编译器可以剔除这些代码。 循环展开或指令重排：内联后，编译器可以更好地调整指令顺序，优化CPU缓存利用率或减少分支跳转。 减少指令数： 对于小型函数，函数调用的开销可能比函数体本身的执行时间还长。内联后，函数体的代码直接嵌入，减少了额外的指令（如push、pop、call、ret等）。 3. inline函数的局限性与权衡 #虽然inline函数通常更快，但它并非总是最佳选择，以下是一些需要注意的点：
代码膨胀： 内联函数会将函数代码复制到每个调用点，如果函数体较大或调用点很多，可能导致生成的机器代码体积显著增加。这可能导致： 指令缓存（I-Cache）效率下降：代码体积过大可能无法完全放入CPU的指令缓存，增加缓存未命中（cache miss）。 可执行文件变大：增加编译后二进制文件的大小。 编译器的自主决定： inline关键字只是一个建议，现代编译器（如GCC、Clang、MSVC）会根据自己的优化策略决定是否内联。 编译器可能忽略inline关键字（例如函数体过大或过于复杂），也可能自动内联未标记为inline的函数（称为自动内联）。 例如，O2或O3优化级别下，编译器会根据函数的大小、调用频率等因素智能选择是否内联。 递归函数： 递归函数通常无法完全内联，因为内联会导致无限展开。编译器可能只内联部分递归调用（例如尾递归优化）。 调试难度： 内联函数的代码在调试时可能不可见，因为它们被展开后不再作为独立的函数存在，可能影响调试体验。 4. 示例代码与分析 #以下是一个简单的例子，展示普通函数调用与内联函数的差异：
#include &amp;lt;iostream&amp;gt; // 普通函数 int add(int a, int b) { return a + b; } // 内联函数 inline int inline_add(int a, int b) { return a + b; } int main() { int x = 5, y = 10; int result1 = add(x, y); // 普通函数调用 int result2 = inline_add(x, y); // 内联函数调用 std::cout &amp;lt;&amp;lt; result1 &amp;lt;&amp;lt; &amp;#34; &amp;#34; &amp;lt;&amp;lt; result2 &amp;lt;&amp;lt; std::endl; return 0; } 普通函数调用（add）：</description></item><item><title>深入理解 False Sharing：实测原子操作与缓存行对齐对性能的影响</title><link>https://code-agree.github.io/blog/2025-06-23-cache_false_sharing_analysis/</link><pubDate>Mon, 23 Jun 2025 15:39:27 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-23-cache_false_sharing_analysis/</guid><description>目录 #1. 引言 # False Sharing概念介绍 文章研究目标 2. 测试设计概览 # 测试用例矩阵 测试方法说明 3. 样例运行结果 # 普通变量 + False Sharing 普通变量 + 无False Sharing 原子变量 + False Sharing 原子变量 + 无False Sharing 4. 现象分析与原理解释 # False Sharing如何降低性能 alignas(64)避免False Sharing的原理 cache miss升高的原因分析 原子变量性能开销分析 5. 深入理解缓存一致性与原子操作 # MESI缓存一致性协议详解 普通变量与原子变量的对比 原子变量 + False sharing的性能影响 CPU指令层面的差异 缓存一致性协议的影响 微架构层面的详细分析 6. 实战优化建议 # 不同场景的优化策略 7. 总结 # False Sharing的关键要点 核心结论 8. 参考资料与相关阅读 #9. 附录：完整测试代码 # 引言 #在现代多核处理器架构中，缓存系统在性能中扮演着至关重要的角色。然而，当多个线程同时操作位于同一缓存行（Cache Line）内的不同变量时，即使它们并未共享变量本身，也可能导致频繁的缓存一致性协议交互，这就是著名的性能杀手——False Sharing。</description></item><item><title>C++原子操作内存序性能分析：seq_cst vs relaxed</title><link>https://code-agree.github.io/blog/2025-06-21-memory_order_performance_analysis/</link><pubDate>Sat, 21 Jun 2025 00:47:52 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-21-memory_order_performance_analysis/</guid><description>摘要 #本文分析了C++原子操作中不同内存序(memory ordering)对性能的影响，特别是比较了默认的顺序一致性(seq_cst)与宽松(relaxed)内存序在x86-64架构上的性能差异。通过实验测试、性能分析和汇编代码检查，我们发现即使在内存模型较强的x86架构上，不同内存序的选择仍然会产生可测量的性能差异。
1. 实验设计 #1.1 测试程序 #我们设计了两个版本的测试程序，它们在固定时间内执行原子变量的读取和计数操作，唯一区别是原子变量读取时使用的内存序不同：
seq_cst版本 (默认内存序):
void worker_seq_cst() { while (running_) { // 默认使用 seq_cst counter_.fetch_add(1, std::memory_order_relaxed); busy_loop(); } } relaxed版本 (显式指定宽松内存序):
void worker_relaxed_load() { while (running_.load(std::memory_order_relaxed)) { counter_.fetch_add(1, std::memory_order_relaxed); busy_loop(); } } 1.2 编译与执行环境 #测试程序使用以下命令编译：
g++ -std=c++11 -O0 -pthread atomic_test_seq_cst.cpp -o test_gcc_seq_cst g++ -std=c++11 -O0 -pthread atomic_test_relaxed.cpp -o test_gcc_relaxed 每个程序运行5秒钟，记录在此期间完成的操作次数。同时使用perf工具收集性能数据：
perf record -e cpu-clock:pppH ./test_gcc_seq_cst perf record -e cpu-clock:pppH ./test_gcc_relaxed 2. 实验结果 #2.1 执行计数结果 # 版本 操作计数 seq_cst 26,494,108 relaxed 26,660,082 性能差异：</description></item><item><title>LockFreeEventBus技术剖析：工作机制与性能瓶颈分析</title><link>https://code-agree.github.io/blog/2025-06-20-lockfree_eventbus_performance_analysis/</link><pubDate>Fri, 20 Jun 2025 14:38:58 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-20-lockfree_eventbus_performance_analysis/</guid><description>概述 #本文针对现有的LockFreeEventBus实现进行深入的性能分析和优化建议。当前实现采用了以下核心设计：
事件与处理函数映射：使用std::unordered_map建立事件类型到处理函数的映射关系 处理函数存储：使用std::vector存储每种事件类型对应的处理函数列表 事件分发机制：在高频调用场景下使用RTTI（运行时类型识别）机制进行事件分发 内存管理：大量使用智能指针进行事件对象的生命周期管理 虽然这种设计在功能上完整可靠，但在高频交易等对延迟极度敏感的场景下存在显著的性能瓶颈。本文将详细分析这些瓶颈的根本原因，并提出针对性的优化建议。
注意：本文是深入理解无锁队列：从原理到实践的完整指南的配套性能分析文章，建议先阅读该文章了解无锁队列的基本原理。
1. 核心工作机制 #1.1 基本架构 #LockFreeEventBus采用无锁队列和工作线程的组合，实现事件的异步处理：
class LockFreeEventBus { private: LockFreeQueueEvent&amp;lt;std::shared_ptr&amp;lt;Event&amp;gt;&amp;gt; event_queue_; std::unordered_map&amp;lt;std::type_index, std::vector&amp;lt;std::function&amp;lt;void(std::shared_ptr&amp;lt;Event&amp;gt;)&amp;gt;&amp;gt;&amp;gt; handlers_; std::atomic&amp;lt;bool&amp;gt; running_; std::thread worker_thread_; // ... }; 关键组件：
event_queue_：无锁队列，存储待处理事件 handlers_：以事件类型为键的处理函数映射表 worker_thread_：单独工作线程，循环处理事件队列 1.2 事件发布流程 #void publish(std::shared_ptr&amp;lt;Event&amp;gt; event) { // 设置发布时间 event-&amp;gt;setPublishTime(std::chrono::high_resolution_clock::now()); // 更新队列统计 auto current_size = queue_size_.fetch_add(1) + 1; // ... // 入队 event_queue_.enqueue(std::move(event)); } 重要说明：发布事件只涉及队列操作，不会修改handlers_映射表。每次publish调用只是将事件对象加入队列，不涉及对处理函数映射表的任何读写操作。事件类型作为key在subscribe阶段已经确定，运行时的publish操作与handlers_映射表完全解耦。
1.3 事件处理流程 #void process_events() { while (running_) { std::shared_ptr&amp;lt;Event&amp;gt; event; if (event_queue_.dequeue(event)) { // 计算处理延迟 // .</description></item><item><title>高频交易中的订单数据结构设计与性能优化实战</title><link>https://code-agree.github.io/blog/2025-06-19-how_to_design_order_inlocalmemory/</link><pubDate>Thu, 19 Jun 2025 19:58:31 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-19-how_to_design_order_inlocalmemory/</guid><description>主题：基于并发读写性能优化的订单数据结构重构与底层机制剖析
目录 # 一、业务背景：订单状态的高并发维护 二、常见设计陷阱：char[] 字符串 ID 与哈希表的性能瓶颈 三、优化目标：极致的并发 + O(1) 访问性能 四、核心优化：整数 ID + array 映射结构 五、底层原理解析：为什么 array + int ID 更快? 1. 内存寻址机制(指针偏移) 2. CPU Cache Line 利用与伪共享问题 3. 避免堆分配与内存碎片 4. 内存序(Memory Ordering)选择与原子操作 5. 整数ID分配和回收机制 六、性能测试数据 七、关键组件优化示例 1. OrderBook实现优化 2. RingBuffer优化 八、NUMA架构下的内存访问优化 九、最终方案优势对比总结 九、结语：高频系统的设计哲学 一、业务背景：订单状态的高并发维护 #在高频交易(HFT)系统中，我们需要对数百万级别的订单状态进行并发读写，以支撑如下操作：
✅ 新增订单(add_order(order_id)) ✅ 修改订单状态(如 fill_qty, status 等) ✅ 高频查询订单状态(如成交均价、当前剩余量等) 这些操作高并发、延迟敏感，需要 O(1) 级别的响应，并且不能产生性能抖动或不可控的锁竞争。
二、常见设计陷阱：char[] 字符串 ID 与哈希表的性能瓶颈 #在早期系统中，常见的设计是以字符串 ID 作为订单主键，例如：
struct Order { char id[32]; char instId[16]; .</description></item><item><title>编译器优化级别技术解析</title><link>https://code-agree.github.io/blog/2025-06-19-compile_perf/</link><pubDate>Thu, 19 Jun 2025 04:00:00 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-19-compile_perf/</guid><description>1. 优化级别的本质与编译过程 #编译器优化是将源代码转换为更高效机器码的系统性过程，每个优化级别代表了不同的转换策略集合。要理解这些级别，首先需要了解编译器的工作流程：
词法分析 → 2. 语法分析 → 3. 语义分析 → 4. 中间表示生成 → 5. 优化 → 6. 代码生成 优化级别主要影响第5步，决定应用哪些转换算法及其激进程度。
2. -O0：零优化的底层机制 #核心原理 #-O0的本质是直接映射：保持源代码与生成的机器码之间的一一对应关系，几乎不进行任何转换。
底层实现机制 # 变量分配策略：
每个变量都分配独立的栈空间 即使是临时变量也会写回内存 不进行寄存器重用优化 指令生成逻辑：
严格按照源代码顺序生成指令 保留所有中间计算步骤 不合并冗余操作 函数调用处理：
严格遵循标准调用约定 保存和恢复所有可能被修改的寄存器 不进行任何内联或尾调用优化 技术深度剖析 #int calculate(int a, int b) { int temp = a * 2; return temp + b; } 在-O0级别，编译器生成的伪汇编代码：
calculate: push rbp ; 保存基址指针 mov rbp, rsp ; 建立新的栈帧 mov DWORD PTR [rbp-20], edi ; 存储参数a mov DWORD PTR [rbp-24], esi ; 存储参数b mov eax, DWORD PTR [rbp-20] ; 加载a add eax, eax ; a*2 mov DWORD PTR [rbp-4], eax ; 存储temp mov edx, DWORD PTR [rbp-4] ; 加载temp到edx mov eax, DWORD PTR [rbp-24] ; 加载b到eax add eax, edx ; b+temp pop rbp ; 恢复基址指针 ret ; 返回 这种实现方式的内存访问模式是：</description></item><item><title>Perf Report 分析完全指南 - 高频交易系统性能优化</title><link>https://code-agree.github.io/blog/2025-06-18-how_to_use_perf/</link><pubDate>Wed, 18 Jun 2025 03:03:07 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-18-how_to_use_perf/</guid><description>目录 # 高频交易系统性能优化思路 Perf 基础知识 perf record 命令参数详解 采样事件类型 Perf 能分析的关键指标 Perf Report 输出解析 列含义详解 分析方法论 高级分析技巧 实际优化流程 关键指标解读 使用Perf分析内存性能指标 高频交易系统案例分析 高频交易系统性能优化思路 #在高频交易系统中，微秒级的延迟差异可能直接影响交易策略的有效性和盈利能力。使用perf进行性能分析是优化高频交易系统的关键步骤。以下是一个系统化的优化思路：
1. 性能基准建立 #关键指标:
端到端延迟: 从行情接收到下单的完整路径时间 吞吐量: 每秒处理的订单/行情数量 尾延迟: 95/99/99.9百分位延迟 CPU利用率: 核心交易路径的CPU使用情况 # 建立基准性能数据 perf stat -e cycles,instructions,cache-references,cache-misses,branches,branch-misses -o perf_base.data -a -g ./strategyTrade 命令参数解释:
cycles: CPU周期数，用于测量程序执行所需的处理器周期总量 instructions: 执行的指令数，结合cycles可计算IPC(每周期指令数)，评估CPU利用效率 cache-references: 缓存访问次数，表示程序对CPU缓存的总访问量 cache-misses: 缓存未命中次数，高缓存未命中率会导致处理器等待内存，增加延迟 branches: 分支指令执行次数，反映程序中条件判断和跳转的频率 branch-misses: 分支预测失败次数，高失败率会导致流水线刷新，降低CPU效率 -o: 指定输出文件名 -a: 收集所有CPU核心的数据，全系统视图 -g: 收集调用图信息，便于分析函数调用关系 输出示例及解读:
Performance counter stats for &amp;#39;./strategyTrade&amp;#39;: 12,345,678,901 cycles # 总CPU周期数 24,680,046,512 instructions # 总指令数，指令/周期比约为2.</description></item><item><title>内存序</title><link>https://code-agree.github.io/blog/2025-06-24-memory_ordering_in_cpp/</link><pubDate>Wed, 11 Jun 2025 02:15:43 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-memory_ordering_in_cpp/</guid><description>C++内存序与无锁编程 #引言 #在现代多核处理器上，高性能并发编程已经成为一项关键技能。C++11引入的原子操作和内存序模型为开发者提供了构建高效无锁数据结构的工具，但同时也带来了显著的复杂性。本文将深入探讨内存序的概念、不同内存序的语义差异，以及如何在实际应用中正确使用它们来构建高性能的无锁数据结构。
内存模型基础 #什么是内存模型 #内存模型定义了多线程程序中内存操作的可见性和顺序性规则。C++内存模型主要关注三个方面：
原子性(Atomicity): 操作是否可以被视为不可分割的整体 可见性(Visibility): 一个线程的写入何时对其他线程可见 顺序性(Ordering): 多个操作之间的执行顺序约束 重排序来源 #在现代计算机系统中，内存操作重排序可能来自三个层面：
编译器重排序: 编译器为了优化可能改变指令顺序 CPU重排序: 处理器可能乱序执行指令或延迟写入主存 缓存一致性: 多核系统中每个核心的缓存可能暂时不一致 happens-before关系 #C++内存模型的核心是建立操作间的happens-before关系：
如果操作A happens-before操作B，则A的结果对B可见 同一线程内的操作之间自动建立happens-before关系 跨线程的happens-before关系需要通过同步操作建立 内存栅栏(Memory Fence) #内存栅栏是一种同步原语，用于限制内存操作的重排序：
// 完整内存栅栏 std::atomic_thread_fence(std::memory_order_seq_cst); // 获取栅栏 std::atomic_thread_fence(std::memory_order_acquire); // 释放栅栏 std::atomic_thread_fence(std::memory_order_release); 栅栏与原子操作的区别在于，栅栏影响所有内存操作，而不仅限于特定的原子变量。
#pragma once #include &amp;lt;atomic&amp;gt; #include &amp;lt;array&amp;gt; #include &amp;lt;optional&amp;gt; #include &amp;lt;memory&amp;gt; #include &amp;lt;vector&amp;gt; namespace LockFreeQueues { // ============================================================================ // 1. 内存序详细演示 // ============================================================================ class MemoryOrderingDemo { private: std::atomic&amp;lt;int&amp;gt; data{0}; std::atomic&amp;lt;bool&amp;gt; flag{false}; public: // 演示不同内存序的行为差异 void demonstrateRelaxed() { // relaxed: 只保证原子性，允许重排序 data.</description></item><item><title>c++ 模版</title><link>https://code-agree.github.io/blog/2025-06-24-cpp_template_class_guide/</link><pubDate>Tue, 10 Jun 2025 22:48:21 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-cpp_template_class_guide/</guid><description>1. 分类 #有三种不同的模版类型，
Function templates class templates Variable templates 1.1. function templates #template&amp;lt;typename T&amp;gt; T max(T a, T b) { return (a &amp;gt; b) ? a : b; } // 使用：编译器自动推导类型 int x = max(3, 7); // T = int double y = max(3.14, 2.71); // T = double 多参数模版 template&amp;lt;typename T, typename U&amp;gt; auto add(T a, U b) { return a + b; } 函数模板的显式实例化 // 声明模板函数 template&amp;lt;typename T&amp;gt; void process(T value) { // 实现.</description></item><item><title>MmAvellaneda Stoikov</title><link>https://code-agree.github.io/blog/2025-06-24-avellaneda_stoikov_market_making/</link><pubDate>Mon, 19 May 2025 13:38:50 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-avellaneda_stoikov_market_making/</guid><description>这篇论文 《Optimal High-Frequency Market Making》 实现并分析了 Avellaneda-Stoikov (2008) 的高频做市定价模型，并引入了一个动态库存控制模块，用于优化限价单的挂单量，以在保证盈利的同时控制库存风险。下面是详细解读：
📌 一、研究背景与动机 #高频做市商（HFT market makers）通过在订单簿中持续挂出买卖限价单来提供流动性，赚取 买卖价差（spread） 和 交易所提供的挂单返利（rebate）。但这同时会产生库存风险（inventory risk），即买入或卖出过多后，价格波动带来的风险。
Avellaneda-Stoikov 模型是其中一个经典的高频做市定价框架，它在假设股票价格服从布朗运动的基础上，通过求解最优控制问题得出最优报价策略。
📌 二、模型框架 #2.1 定价模型（Pricing） #基于 Avellaneda &amp;amp; Stoikov (2008)：
股票价格服从布朗运动： $dS_t = \sigma dW_t$ 市场深度与成交概率关系：$\lambda(\delta) = A e^{-\kappa \delta}$ 做市商目标是最大化终端时刻 $T$ 时的指数效用函数： $$ \max_{\delta_a, \delta_b} \mathbb{E}[-e^{-\gamma (X_T + q_T S_T)}] $$
推导结果是：
中间价（Indifference Price）： $$ r(s, t) = s - q\gamma\sigma^2(T - t) $$
最优总挂单价差（Spread）： $$ \delta_a + \delta_b = \gamma\sigma^2(T - t) + \ln\left(1 + \frac{\gamma}{\kappa} \right) $$</description></item><item><title>行情数据解析优化最佳实践</title><link>https://code-agree.github.io/blog/2025-06-24-perf_tool_usage_guide/</link><pubDate>Wed, 30 Apr 2025 03:54:56 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-perf_tool_usage_guide/</guid><description>行情数据解析优化最佳实践 #原始解析方案的性能瓶颈 #原始的 Binance 聚合交易数据解析实现存在多个性能瓶颈，这在高频交易系统中尤为关键。主要问题包括：
使用 std::stod 进行字符串到浮点数转换：
result.data.price = std::stod(std::string(price_str)); result.data.quantity = std::stod(std::string(qty_str)); 这里存在两个严重问题：
std::stod 在底层实现中需要处理各种格式和本地化，导致计算开销大 每次调用都创建了临时 std::string 对象，增加了内存分配和释放的开销 创建临时的 padded_string 对象：
simdjson::padded_string padded_json{json}; simdjson::dom::element doc = parser.parse(padded_json); 这会导致额外的内存分配和复制，特别是在高频率处理消息时变得非常明显。
使用低效的字符串复制方法：
strncpy(result.data.symbol, doc[&amp;#34;s&amp;#34;].get_string().value().data(), sizeof(result.data.symbol) - 1); 标准的 strncpy 没有利用现代 CPU 的 SIMD 指令集优势。
异常处理成本：在解析热路径中大量使用 try-catch 结构，这会导致编译器生成额外代码，影响性能。
重复获取 JSON 节点：多次访问相同的 JSON 节点，每次都需要进行字符串哈希查找。
优化方案 #为了解决上述问题，我们实施了多层次的优化策略：
1. 自定义快速解析路径 #创建了一个专门针对 Binance 聚合交易数据格式的快速解析函数，完全跳过通用 JSON 解析器：
bool fastParseAggTrade(const std::string_view&amp;amp; json, Common::QuoteData::AggTradeData&amp;amp; data) noexcept { // 快速检查消息类型 const char* type_pattern = &amp;#34;\&amp;#34;e\&amp;#34;:\&amp;#34;aggTrade\&amp;#34;&amp;#34;; if (json.</description></item><item><title>TLS会话恢复（Session Resumption）</title><link>https://code-agree.github.io/blog/2025-06-24-session_resumption_techniques/</link><pubDate>Fri, 07 Mar 2025 19:24:12 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-session_resumption_techniques/</guid><description>1. 会话恢复简介 #什么是会话恢复？ #TLS会话恢复是TLS协议的一项优化特性，允许客户端和服务器基于之前建立的安全会话快速恢复通信，跳过完整的握手过程。在TLS 1.3中，会话恢复主要通过**PSK（Pre-Shared Key，预共享密钥）**机制实现，而在TLS 1.2及更早版本中，也可以通过Session ID或Session Ticket实现。
为什么需要会话恢复？ # 性能优化： 完整握手（TLS 1.3）：1-RTT 会话恢复：1-RTT（或0-RTT） 显著减少连接建立时间 资源节省： 降低CPU开销（避免重复密钥交换） 减少网络带宽占用 2. TLS 1.3中的会话恢复机制 #工作流程对比 #完整握手（TLS 1.3） #Client Server | ClientHello | |--------------------&amp;gt;| | ServerHello | | EncryptedExt | | Certificate | | CertVerify | | Finished | |&amp;lt;--------------------| | Finished | |--------------------&amp;gt;| | NewSessionTicket | |&amp;lt;--------------------| RTT：1次往返 服务器在握手后发送NewSessionTicket，包含PSK和有效期信息。 会话恢复（1-RTT） #Client Server | ClientHello | | (with PSK) | |--------------------&amp;gt;| | ServerHello | | Finished | |&amp;lt;--------------------| | Finished | |--------------------&amp;gt;| RTT：1次往返 客户端使用之前保存的PSK直接恢复会话。 0-RTT（可选） #Client Server | ClientHello | | (with PSK + Early Data) | |--------------------&amp;gt;| | ServerHello | | Finished | |&amp;lt;--------------------| | Finished | |--------------------&amp;gt;| RTT：0次往返（早期数据随首次请求发送） 注意：0-RTT有重放攻击风险，仅适用于幂等请求。 3.</description></item><item><title>使用 Tailscale 实现 MacOS 设备远程连接教程</title><link>https://code-agree.github.io/blog/2025-06-24-screen_sharing_techniques/</link><pubDate>Sun, 19 Jan 2025 11:15:08 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-screen_sharing_techniques/</guid><description>我来帮你编写一份详细的技术教程，介绍如何使用 Tailscale 在 MacOS 设备间实现远程连接。
使用 Tailscale 实现 MacOS 设备远程连接教程 #准备工作 # 确保两台 MacOS 设备都能正常访问互联网 准备一个 Tailscale 账号（可以使用 Google、GitHub 等账号登录） 详细步骤 #第一步：安装 Tailscale #在两台 MacOS 设备上分别安装 Tailscale：
访问 Tailscale 官网 (https://tailscale.com/download) 下载 MacOS 版本的安装包 打开下载的 .dmg 文件，将 Tailscale 拖入应用程序文件夹 第二步：登录和配置 # 在两台设备上启动 Tailscale 点击菜单栏的 Tailscale 图标 使用相同的账号登录 登录成功后，Tailscale 会自动为设备分配 IP 地址 点击菜单栏图标可以查看分配的 IP 地址（通常格式为 100.xx.xx.xx） 第三步：开启远程访问 #在被控制的 MacOS 设备上：
打开系统偏好设置 选择&amp;quot;共享&amp;quot; 勾选&amp;quot;远程管理&amp;quot;或&amp;quot;屏幕共享&amp;quot; 配置访问权限，可以选择： 允许所有用户 仅允许特定用户 第四步：建立连接 #在控制端 MacOS 设备上：
打开访达（Finder） 在菜单栏选择&amp;quot;前往&amp;quot; → &amp;ldquo;连接服务器&amp;rdquo;（或按下 Command + K） 在服务器地址栏输入：vnc://100.</description></item><item><title>共享内存多进程通信中的页面切换同步问题分析与解决</title><link>https://code-agree.github.io/blog/2025-06-24-fix_shared_page_position/</link><pubDate>Fri, 17 Jan 2025 04:21:23 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-fix_shared_page_position/</guid><description>问题现象 #在多进程共享内存通信中，发现读取进程出现异常：
写入进程（线程3002707）正常写入数据
读取进程（线程3002791）卡在固定位置：
page: 0 write_pos: 134209160 read_pos: 134199368 问题定位过程 #1. 初步分析 #首先观察到一个关键现象：
Binance的读写正常 Bitget的读取卡在固定位置 两个交易所使用相同的共享内存机制 2. 代码分析 #检查共享内存管理的核心类：
写入机制： template&amp;lt;typename T&amp;gt; bool write(const TypedFrame&amp;lt;T&amp;gt;&amp;amp; frame) { // ... if (write_pos + frame_size &amp;gt; page_size_) { switchToNextPage(); write_pos = current_write_pos_.load(std::memory_order_relaxed); continue; } // ... std::atomic&amp;lt;size_t&amp;gt;* shared_write_pos = reinterpret_cast&amp;lt;std::atomic&amp;lt;size_t&amp;gt;*&amp;gt;(current_page_-&amp;gt;getData()); shared_write_pos-&amp;gt;store(write_pos + frame_size, std::memory_order_release); } 页面切换： void Journal::switchToNextPage() { current_page_ = page_engine_-&amp;gt;getNextPage(); current_write_pos_.store(0, std::memory_order_relaxed); } Page* PageEngine::getNextPage() { current_page_index_++; if (current_page_index_ &amp;gt;= pages_.</description></item><item><title>Solana_monitor</title><link>https://code-agree.github.io/blog/2025-06-24-solana_monitoring_system/</link><pubDate>Fri, 20 Dec 2024 03:08:38 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-solana_monitoring_system/</guid><description>Solana链上交易监控最佳实践：从logsSubscribe到全方位监控 #背景介绍 #在Solana链上开发中，实时监控特定账户的交易活动是一个常见需求，特别是在构建跟单机器人这类对时效性要求较高的应用场景中。最初，我们可能会想到使用Solana提供的logsSubscribe WebSocket API来实现这个功能，因为它看起来是最直接的解决方案。然而，在实际应用中，我们发现这种方案存在一些限制和问题。
问题发现 #在使用logsSubscribe进行账户监控时，我们发现一个关键问题：某些确实发生的交易并没有被我们的监控系统捕获到。这个问题的发现促使我们深入研究Solana的交易日志机制，并最终设计了一个更全面的监控方案。
为什么会遗漏交易？ # 日志记录机制的局限性
程序可能不会在日志中明确记录所有涉及的账户地址 交易可能使用了PDA(Program Derived Address)或其他派生地址 某些DEX采用内部账户映射，而不是直接记录用户地址 mentions过滤器的限制
只能捕获在日志中明确提到目标地址的交易 无法捕获通过间接方式影响目标账户的交易 解决方案 #针对上述问题，我们设计了一个多维度监控方案，通过组合多种订阅方式来确保不会遗漏任何相关交易。
1. 三重订阅机制 #pub struct EnhancedTradeWatcher { target_account: Pubkey, ws_client: WebSocketClient, } impl EnhancedTradeWatcher { async fn setup_comprehensive_monitoring(&amp;amp;mut self) -&amp;gt; Result&amp;lt;()&amp;gt; { // 1. logsSubscribe - 捕获显式提及 let logs_sub = json!({ &amp;#34;jsonrpc&amp;#34;: &amp;#34;2.0&amp;#34;, &amp;#34;method&amp;#34;: &amp;#34;logsSubscribe&amp;#34;, &amp;#34;params&amp;#34;: [ { &amp;#34;mentions&amp;#34;: [self.target_account.to_string()], }, { &amp;#34;commitment&amp;#34;: &amp;#34;processed&amp;#34; } ] }); // 2. programSubscribe - 监控DEX程序 let dex_program_sub = json!</description></item><item><title>Solana链上交易监控技术分析</title><link>https://code-agree.github.io/blog/2025-06-24-solana_blockchain_analysis/</link><pubDate>Thu, 19 Dec 2024 01:32:32 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-solana_blockchain_analysis/</guid><description>Solana链上交易监控技术分析 #1. Solana DEX 交易形式 #1.1 直接 DEX 交易 #用户直接与 DEX 合约交互，交易流程简单直接。
用户钱包 -&amp;gt; DEX程序 (如Raydium/Orca) -&amp;gt; Token Program 特点：
交易日志简洁，主要包含单个 DEX 程序的调用 容易识别交易平台和交易对 Token Program 的 transfer 指令较少 1.2 聚合器交易（Jupiter） #通过聚合器路由到单个或多个 DEX。
用户钱包 -&amp;gt; Jupiter -&amp;gt; DEX1/DEX2/... -&amp;gt; Token Program 特点：
包含 Jupiter 合约调用 可能涉及多个 DEX 交易日志较长，包含多个内部指令 可能有复杂的代币交换路径 1.3 智能路由交易 #一笔交易通过多个 DEX 串联完成。
用户钱包 -&amp;gt; 聚合器 -&amp;gt; DEX1 -&amp;gt; DEX2 -&amp;gt; DEX3 -&amp;gt; Token Program 特点：
交易路径最复杂 涉及多次代币交换 目的是获得最优价格 包含多个 Token Program 的 transfer 指令 2.</description></item><item><title>WebSocket消息处理线程CPU亲和性导致的消息阻塞故障分析</title><link>https://code-agree.github.io/blog/2025-06-24-message_queue_overstocking_solutions/</link><pubDate>Fri, 13 Dec 2024 05:15:51 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-message_queue_overstocking_solutions/</guid><description>一、故障现象 #1.1 单endpoint模式故障 # 单个WebSocket连接时消息接收完全阻塞 日志显示消息处理线程启动后无法接收新消息 [2024-12-12 20:31:29.455] [error] [setThreadAffinity] Error calling pthread_setaffinity_np: 22 [2024-12-12 20:31:29.697] [info] Message thread started for endpoint: OkxPublic // 之后无消息接收日志 1.2 多endpoint模式部分正常 # 多个WebSocket连接时只有一个线程能正常接收消息 日志显示消息处理情况： [20:54:50.542] [thread 91374] Processing message for OkxPublic [20:54:50.640] [thread 91374] Processing message for OkxPublic // 只有一个线程在持续处理消息 二、系统架构分析 #2.1 WebSocket消息接收机制 #void WebSocketClient::receiveMessages(const MessageHandler&amp;amp; handler) { while (true) { try { // 1. 阻塞式接收WebSocket消息 int n = ws_-&amp;gt;receiveFrame(buffer.data(), buffer.size(), flags); // 2. 同步回调处理消息 if (n &amp;gt; 0) { handler(buffer.</description></item><item><title>高频交易系统中的大吞吐量订单发送机制</title><link>https://code-agree.github.io/blog/2025-06-24-order_sending_optimization/</link><pubDate>Thu, 12 Dec 2024 02:17:32 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-order_sending_optimization/</guid><description>1. 需求背景 #在高频交易系统中，我们面临一个典型场景：需要同时处理三个关联订单（三角套利）。这些订单必须几乎同时发出以确保套利的有效性。
关键挑战：
订单必须同时或几乎同时发出 系统需要处理高并发的订单组 需要保证订单处理的稳定性和可靠性 2. 当前使用的两种处理订单的机制 # 无锁队列机制 订单生成后进入一个无锁队列 多个线程从队列中取订单进行处理 订单的发送通过RestClient进行，RestClient负责管理HTTP连接池并发送请求 分片机制 订单生成后根据某种规则分配到不同的分片 每个分片由固定的线程处理 同一组的订单被分配到同一个分片，确保组内订单的处理一致性 RestClient同样负责订单的发送 class OrderShard { private: struct OrderGroup { uint64_t groupId; uint64_t timestamp; std::vector&amp;lt;Order&amp;gt; orders; }; std::queue&amp;lt;OrderGroup&amp;gt; orderQueue_; std::mutex mutex_; std::condition_variable cv_; RestClient restClient_; public: void addOrderGroup(OrderGroup group) { { std::lock_guard&amp;lt;std::mutex&amp;gt; lock(mutex_); orderQueue_.push(std::move(group)); } cv_.notify_one(); } void processOrders() { while (running_) { OrderGroup group; { std::unique_lock&amp;lt;std::mutex&amp;gt; lock(mutex_); cv_.wait(lock, [this] { return !orderQueue_.empty() || !</description></item><item><title>高性能订单执行系统设计方案1</title><link>https://code-agree.github.io/blog/2025-06-24-batch_order_processing/</link><pubDate>Fri, 06 Dec 2024 17:45:16 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-batch_order_processing/</guid><description>1. 背景问题 #1.1 性能挑战 # 高吞吐量订单处理需求 每个订单都需要 HTTP 请求 JWT Token 生成开销大 网络延迟敏感 1.2 主要痛点 # 单个订单发送造成网络请求过多 JWT Token 频繁生成浪费资源 大量订单并发可能导致系统瓶颈 2. 解决方案 #2.1 JWT Token 缓存机制 #class RestClient { private: static constexpr auto JWT_REFRESH_INTERVAL = std::chrono::seconds(110); // 预留刷新窗口 std::string getOrCreateJWT(const std::string&amp;amp; uri) { auto now = std::chrono::steady_clock::now(); if (!cache.token.empty() &amp;amp;&amp;amp; now &amp;lt; cache.expiryTime) { return cache.token; } cache.token = generateJWT(uri); cache.expiryTime = now + JWT_REFRESH_INTERVAL; return cache.token; } }; 优点：</description></item><item><title>高性能网络编程：io_uring 与内存优化技术详解</title><link>https://code-agree.github.io/blog/2025-06-24-io_uring_basics/</link><pubDate>Fri, 06 Dec 2024 06:04:25 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-io_uring_basics/</guid><description>0. 内存管理优化 #0.1 大页内存 (Huge Pages) #大页内存是一种内存管理优化技术，主要优势：
减少 TLB (Translation Lookaside Buffer) 缺失 减少页表项数量 提高内存访问效率 系统配置和检查：
# 检查系统大页配置 cat /proc/meminfo | grep Huge # 配置大页 echo 20 &amp;gt; /proc/sys/vm/nr_hugepages # 分配20个大页 0.2 内存锁定 (Memory Locking) #防止内存被交换到磁盘，确保数据始终在物理内存中：
# 检查内存锁定限制 ulimit -l # 修改限制（需要root权限） echo &amp;#34;* soft memlock unlimited&amp;#34; &amp;gt;&amp;gt; /etc/security/limits.conf 0.3 内存优化实现 #struct IOBuffer { char* data; size_t size; explicit IOBuffer(size_t s) : size(s) { // 1. 尝试使用大页内存 data = static_cast&amp;lt;char*&amp;gt;(mmap(nullptr, size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS | MAP_HUGETLB, -1, 0)); if (data == MAP_FAILED) { // 2.</description></item><item><title>高频交易场景下的多WS连接低延时方案设计</title><link>https://code-agree.github.io/blog/2025-06-24-multi_quote_data_processing/</link><pubDate>Tue, 03 Dec 2024 01:01:26 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-multi_quote_data_processing/</guid><description>1. 业务背景与挑战 #在高频交易系统中，需要同时维护多个WebSocket连接以订阅不同交易所的行情数据。主要挑战包括：
需要处理多个交易所的并发连接 对消息处理延迟有严格要求 需要保证数据处理的稳定性 系统资源（CPU、内存）的高效利用 2. 传统方案的局限 #2.1 传统消息队列方案 #// 常见的消息处理流程 WebSocket接收 -&amp;gt; 消息队列 -&amp;gt; 处理线程池 -&amp;gt; 业务处理 存在的问题：
消息经过队列带来额外延迟 线程切换开销大 内存拷贝次数多 资源竞争导致性能不稳定 3. 优化方案设计 #3.1 核心设计理念 # 零拷贝数据处理 CPU亲和性绑定 预分配内存 每个连接独立处理 3.2 关键组件设计 #struct ConnectionContext { // 连接基础信息 std::shared_ptr&amp;lt;WebSocketClient&amp;gt; client; std::string endpoint_name; // 性能优化相关 int cpu_core{-1}; // CPU核心绑定 char* direct_buffer{nullptr}; // 预分配缓冲区 static constexpr size_t BUFFER_SIZE = 64 * 1024; std::shared_ptr&amp;lt;MessageProcessor&amp;gt; dedicated_processor; // 资源管理 ~ConnectionContext() { if (direct_buffer) { munlock(direct_buffer, BUFFER_SIZE); munmap(direct_buffer, BUFFER_SIZE); } } // 禁用拷贝以保证资源安全 ConnectionContext(const ConnectionContext&amp;amp;) = delete; ConnectionContext&amp;amp; operator=(const ConnectionContext&amp;amp;) = delete; }; 3.</description></item><item><title>付鹏HSBC</title><link>https://code-agree.github.io/blog/2025-06-24-fupeng_trading_system/</link><pubDate>Sun, 01 Dec 2024 21:06:34 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-fupeng_trading_system/</guid><description>HSBC 速记 汇丰私人财富规划
玺越世家 · 臻享沙龙 上海站
（速记稿）
时间：2024 年 11 月 24 日
地点：上海浦东文华东方酒店 LG1 层东方厅
主持人：女士们，先生们，各位尊敬的来宾，我是陈佳昊（音），我是汇丰私人财富规划上海分区总经理，我代表上海汇丰私人财富规划欢迎各位的莅临。
今天有很多新朋友，也有很多老朋友，我在周五的时候问过后台同事报名报了多少了，他告诉我们已经快要接近 200 人了，但从今天的规模来看，我感觉好像今天的人数还要再超过一些。
当然了，有一些是原先的老客户，也有很多是慕名而来，看到这次邀请的是付鹏先生，所以慕名而来。也有一些新朋友。在付鹏先生上台之前，请允许我对汇丰私人财富规划做简短的介绍。
汇丰私人财富规划是全球的战略重点之一，老朋友都知道，汇丰私人财富规划成立于 2020 年，距今刚好四年，在四年的过程中集团一直在给我们大力注资，也是集团里最重要的项目之一。
为什么聚焦在中国市场上？大家很多人都明白，中国中产阶级的人数在世界上占有量是最庞大的，随着中国经济的高速发展，中国人财富管理的需求逐步提升到很高的水准。所以，私人财富规划也会变成汇丰的重要战略之一。
介绍一下发展历史，从 2020 年汇丰私人财富规划成立，先是在上海和广州，总部离这里不远，汇丰总部就在国金，欢迎大家去坐一坐。逐步进入到杭州、深圳、北京、佛山，今年在苏州、成都开立了分支机构。
2020 年汇丰私人财富规划才刚刚成立，那汇丰的历史又是怎么样的？汇丰简称叫 HSBC，很多人会问 HSBC 四个字母分别代表着什么，可以跟大家简单介绍一下，H 代表的是香港的意思，S 代表的是上海的意思。很多人印象中以为汇丰是一家外资银行，但其实大家有所不知，其实汇丰在清朝的时候就在外滩已经设立了总部，现在这栋楼交给了浦发银行。1949 年之后，汇丰因为历史的原因退出了中国，在 WTO 之后回到了中国。
汇丰 1865 年成立至今已经有 100 多年了，那时候还是清朝的同治年间，同时已经在全球的 62 个国家还有 3900 多名客户，这段历史和这么大的分布也是汇丰很多同事内心的骄傲。我们跟很多客户做沟通的时候，经常会把这段历史拿出来跟大家讲一讲，就像这头石狮子，很多人都见过，但很多人都不知道它的历史，很多人在海报、广告、港元大钞上看过这个石狮子，原来在外滩上也有两座，现在放在上海博物馆里，前一阵儿我在博物馆参观的时候还看到了这两只石狮子，上面还有很多历史的痕迹，比如说战争而留下的弹孔，就在人民广场的博物馆里，大家有兴趣的话可以去看一下。
财富大矩阵与中国内地市场，汇丰集团对于中国私人财富规划业务的重视程度，在大矩阵中承担了很重要的地位。
每 100 位客户中，会有 87 位客户将汇丰私人财富规划视作为提供财富重要的主要品牌，提出了很多好评，82% 的调研者打出 9-10 分的高分。
也有一些比较有意思的话，如：“对产品内容的保障满意，公司大有保障；甄汇生活有一定的吸引力，汇丰的产品较贵但也愿意买，因为对汇丰私人财富规划师的认可。”
这两年提出一句比较新的 Slogan“懂你关心的，给你安心的”。
今天的活动我们邀请到了一位重量级嘉宾，他曾任职于雷曼兄弟、所罗门投资集团等全球顶尖金融机构，从事对冲基金等相关工作。他就是东北证券首席经济学家付鹏先生。让我们欢迎付鹏先生为我们带来《2024 年年终回顾和 2025 年展望——对冲风险 VS 软着陆》主题分享，有请付鹏先生！
付鹏：正值年底，虽然刚才汇丰一直强调大家不录音不录像，但大概率你挡不住。我在这儿讲话会谨慎一些，非常小心谨慎，大概率会有人透露出去，放到 YouTube 上，基本上所有见我都说付总我在 YouTube 上看过你的视频，我说那都是盗版的，靠盗版发财的也不少。</description></item><item><title>OrderBook 本地维护方案设计</title><link>https://code-agree.github.io/blog/2025-06-24-orderbook_implementation/</link><pubDate>Wed, 27 Nov 2024 02:35:19 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-orderbook_implementation/</guid><description>OrderBook 本地维护方案设计 #一、业务背景 #OrderBook（订单簿）是反映市场深度和流动性的核心数据结构，其维护质量直接影响：
策略交易决策的准确性 风险控制的有效性 市场定价的及时性 1.1 业务价值 # 价格发现
实时反映市场供需状态 提供多层次价格信息 展示市场深度分布 交易决策支持
最优价格确定（NBBO） 流动性评估 交易成本估算 风险管理
市场异常监控 流动性风险评估 价格波动追踪 二、技术方案 #2.1 核心数据结构 #class LockFreeOrderBook { private: // 基础信息 std::string symbol_; // 状态管理 std::atomic&amp;lt;uint64_t&amp;gt; last_update_time_{0}; std::atomic&amp;lt;uint64_t&amp;gt; last_sequence_{0}; std::atomic&amp;lt;bool&amp;gt; initialized_{false}; // 价格档位存储 using PriceLevelMap = tbb::concurrent_map&amp;lt;double, PriceLevel, std::greater&amp;lt;&amp;gt;&amp;gt;; PriceLevelMap bids_; // 买盘 - 降序 PriceLevelMap asks_; // 卖盘 - 升序 }; // 价格档位结构 struct PriceLevel { double price; double quantity; uint64_t update_time; }; // 深度数据结构 struct DepthData { std::vector&amp;lt;PriceLevel&amp;gt; bids; std::vector&amp;lt;PriceLevel&amp;gt; asks; uint64_t sequence_num; uint64_t timestamp; }; 2.</description></item><item><title>内存映射（mmap）与零拷贝技术：深入理解和实践</title><link>https://code-agree.github.io/blog/2025-06-24-zero_copy_optimization/</link><pubDate>Tue, 22 Oct 2024 01:23:46 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-zero_copy_optimization/</guid><description>1. 概述 #内存映射（mmap）是一种将文件或设备映射到内存的方法，而零拷贝是一种减少或避免数据在内核空间和用户空间之间不必要复制的技术。这两个概念密切相关，但又有所不同。
2. mmap 是零拷贝吗？ #答案是：mmap 本身不是零拷贝技术，但它可以实现零拷贝的效果。
2.1 mmap 的工作原理 # 当调用 mmap 时，操作系统会在虚拟内存中创建一个新的内存区域。 这个内存区域会映射到文件系统缓存（page cache）中的物理页面。 当程序访问这个内存区域时，如果相应的页面不在内存中，会触发缺页中断，操作系统会从磁盘加载数据到内存。 2.2 为什么 mmap 可以实现零拷贝 # 一旦映射建立，用户进程可以直接读写这个内存区域，而无需在用户空间和内核空间之间进行数据复制。 对于读操作，数据从磁盘读入 page cache 后，可以直接被用户进程访问，无需额外复制。 对于写操作，修改直接发生在 page cache 上，操作系统会在适当的时候将修改同步到磁盘。 3. mmap 与传统 I/O 的比较 #3.1 传统 read 系统调用 #char buffer[4096]; ssize_t bytes_read = read(fd, buffer, sizeof(buffer)); 这个过程涉及两次数据拷贝：
从磁盘到内核缓冲区 从内核缓冲区到用户空间缓冲区 3.2 使用 mmap #void* addr = mmap(NULL, file_size, PROT_READ, MAP_PRIVATE, fd, 0); // 直接访问 addr 指向的内存 mmap 减少了一次数据拷贝，数据直接从磁盘到用户可访问的内存。</description></item><item><title>GitHub私有仓库协同开发指南</title><link>https://code-agree.github.io/blog/2025-06-24-project_management_best_practices/</link><pubDate>Wed, 16 Oct 2024 02:04:51 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-project_management_best_practices/</guid><description>目录 # 简介 仓库结构和分支策略 协作者权限管理 保护主分支 Pull Request 和代码审查流程 持续集成与部署 (CI/CD) 文档和沟通 最佳实践和注意事项 简介 #在没有高级 GitHub 功能的私有仓库中进行协同开发可能具有挑战性，但通过正确的实践和工具，我们可以建立一个高效、安全的开发环境。本指南总结了我们讨论的主要策略和技术。
仓库结构和分支策略 # 主分支：main（稳定、可部署的代码） 开发分支：main_for_dev（日常开发工作） 特性分支：从 main_for_dev 分出，用于开发新功能 工作流程：
从 main_for_dev 创建特性分支 在特性分支上开发 完成后，创建 Pull Request 到 main_for_dev 代码审查和测试 合并到 main_for_dev 定期将 main_for_dev 合并到 main 协作者权限管理 #GitHub 私有仓库提供以下权限级别：
Read Triage Write Maintain Admin 设置步骤：
进入仓库 &amp;ldquo;Settings&amp;rdquo; &amp;gt; &amp;ldquo;Collaborators and teams&amp;rdquo; 点击 &amp;ldquo;Add people&amp;rdquo; 或 &amp;ldquo;Add teams&amp;rdquo; 输入用户名并选择适当的权限级别 最佳实践：
遵循最小权限原则 定期审查和更新权限 保护主分支 #由于缺乏高级分支保护功能，我们采用以下策略：
团队约定：
禁止直接推送到 main 分支 所有更改通过 PR 进行 Git Hooks： 创建 pre-push hook（.</description></item><item><title>Fork机制详解：从基础到高级应用</title><link>https://code-agree.github.io/blog/2025-06-24-fork_system_call_analysis/</link><pubDate>Tue, 15 Oct 2024 02:45:13 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-fork_system_call_analysis/</guid><description>1. 引言 #Fork是Unix/Linux系统中最基本也是最强大的系统调用之一。它允许一个进程创建一个新的进程,这个新进程是原进程的一个几乎完全相同的副本。本次技术分享将深入探讨fork机制,从基本概念到高级应用。
2. Fork的基本原理 #2.1 什么是Fork #Fork是一个系统调用,用于创建一个新的进程。新进程（称为子进程）是调用进程（称为父进程）的一个几乎完全相同的副本。
2.2 Fork的工作原理 #当一个进程调用fork时:
系统会创建一个新的进程。 新进程是父进程的一个副本,包括代码段、数据段、堆栈等。 子进程获得父进程数据空间、堆和栈的副本。 父进程和子进程继续执行fork调用之后的代码。 2.3 Fork的返回值 #Fork调用会返回两次:
在父进程中,返回子进程的PID。 在子进程中,返回0。 这允许程序区分父进程和子进程。
pid_t pid = fork(); if (pid &amp;gt; 0) { printf(&amp;#34;父进程\n&amp;#34;); } else if (pid == 0) { printf(&amp;#34;子进程\n&amp;#34;); } else { perror(&amp;#34;fork失败&amp;#34;); exit(1); } 3. Fork的高级特性 #3.1 写时复制 (Copy-on-Write) #为了提高效率,现代操作系统使用&amp;quot;写时复制&amp;quot;技术:
初始时,子进程与父进程共享同一物理内存。 只有当其中一个进程尝试修改内存时,才会创建该部分内存的副本。 这大大减少了fork的开销和内存使用。
3.2 文件描述符的继承 #子进程继承父进程的文件描述符。这意味着:
子进程可以访问父进程打开的文件。 父子进程共享文件偏移量。 int fd = open(&amp;#34;example.txt&amp;#34;, O_RDWR); if (fork() == 0) { // 子进程 write(fd, &amp;#34;Hello from child&amp;#34;, 16); } else { // 父进程 write(fd, &amp;#34;Hello from parent&amp;#34;, 17); } 3.</description></item><item><title>高频交易系统中的位域压缩技术</title><link>https://code-agree.github.io/blog/2025-06-24-bit_field_compression_techniques/</link><pubDate>Sun, 13 Oct 2024 03:18:35 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-bit_field_compression_techniques/</guid><description>1. 基础概念 #1.1 二进制表示 # 计算机使用二进制（0和1）存储和处理数据 1 byte = 8 bits 32位整数可以表示从 0 到 2^32 - 1 的数值 1.2 位操作基础 # 与操作 (&amp;amp;): 两位都为1时结果为1，否则为0 或操作 (|): 至少一位为1时结果为1，否则为0 异或操作 (^): 两位不同时结果为1，相同时为0 非操作 (~): 将每一位取反 左移 (&amp;laquo;): 将所有位向左移动，右侧补0 右移 (&amp;raquo;): 将所有位向右移动，左侧补0或符号位 示例：
unsigned int a = 5; // 0101 unsigned int b = 3; // 0011 unsigned int and_result = a &amp;amp; b; // 0001 (1) unsigned int or_result = a | b; // 0111 (7) unsigned int xor_result = a ^ b; // 0110 (6) unsigned int not_result = ~a; // 11111111111111111111111111111010 (-6 in 2&amp;#39;s complement) unsigned int left_shift = a &amp;lt;&amp;lt; 1; // 1010 (10) unsigned int right_shift = a &amp;gt;&amp;gt; 1;// 0010 (2) 2.</description></item><item><title>高频交易系统中的市场数据存储优化</title><link>https://code-agree.github.io/blog/2025-06-24-efficient_reading_techniques/</link><pubDate>Sun, 29 Sep 2024 01:36:04 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-efficient_reading_techniques/</guid><description>1. 背景介绍 #在高频交易系统中，市场数据的快速读取和处理是关键性能指标之一。我们的系统使用共享内存来存储和访问实时市场数据，其中 MarketDataStore 类负责管理这些数据。本文将讨论如何优化 MarketDataStore 中的 readLatestData 函数，以提高数据读取的效率。
2. 初始实现 #最初的 readLatestData 函数实现如下：
std::optional&amp;lt;MappedTickerData&amp;gt; MarketDataStore::readLatestData(const std::string&amp;amp; symbol) const { std::shared_lock&amp;lt;std::shared_mutex&amp;gt; lock(mutex); size_t offset = calculateOffset(symbol); MappedTickerData data; if (dataFile-&amp;gt;read(&amp;amp;data, offset, sizeof(MappedTickerData))) { if (data.timestamp != 0 &amp;amp;&amp;amp; std::string(data.product_id) == symbol) { return data; } else { LOG_WARN(&amp;#34;readLatestData symbol = {} failed&amp;#34;, symbol); return std::nullopt; } } else { LOG_ERROR(&amp;#34;Failed to read data for symbol = {}&amp;#34;, symbol); return std::nullopt; } } 这个实现存在几个性能瓶颈：</description></item><item><title>高频交易系统中的重连机制最佳实践</title><link>https://code-agree.github.io/blog/2025-06-24-atomic_operations_reconnection_mechanism/</link><pubDate>Fri, 27 Sep 2024 01:35:21 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-atomic_operations_reconnection_mechanism/</guid><description>高频交易系统中的重连机制最佳实践 #背景 #在高频交易系统中，网络连接的稳定性至关重要。然而，由于网络波动或其他原因，连接可能会中断。为了确保系统的连续性和可靠性，需要实现一个高效的重连机制。然而，频繁的重连检查和处理可能导致重复重连，影响系统性能。
问题描述 #在现有实现中，主循环频繁检查 m_client-&amp;gt;needsReconnection()，如果需要重连，则调用 handleReconnect()。然而，由于主循环速度很快，可能在 resetReconnectionFlag() 生效前再次检查 needsReconnection()，导致重复调用 handleReconnect()。
解决方案 #通过使用原子操作和双重检查机制，确保重连过程的原子性和一致性，避免重复重连。
1. 定义连接状态管理 #使用原子变量来管理连接状态，确保线程安全。
class WebSocketClient { private: std::atomic&amp;lt;bool&amp;gt; isReconnecting{false}; std::atomic&amp;lt;bool&amp;gt; needsReconnection{false}; public: bool needsReconnection() const { return needsReconnection.load(std::memory_order_acquire); } bool tryInitiateReconnection() { bool expected = false; return isReconnecting.compare_exchange_strong(expected, true, std::memory_order_acq_rel); } void setNeedsReconnection(bool value) { needsReconnection.store(value, std::memory_order_release); } void resetReconnectionFlag() { needsReconnection.store(false, std::memory_order_release); isReconnecting.store(false, std::memory_order_release); } }; 2. 修改主循环 #在主循环中使用双重检查机制，确保重连过程的原子性。
void StrategyAndTrading::run() { initializeConnection(); marketDataReader-&amp;gt;start(); positionManager-&amp;gt;updatePositionsThread(); m_commonLib-&amp;gt;getConfigManager().configWatcher(); while (running_) { if (m_client-&amp;gt;needsReconnection() &amp;amp;&amp;amp; m_client-&amp;gt;tryInitiateReconnection()) { handleReconnect(); } // 执行其他高频交易逻辑 std::this_thread::sleep_for(std::chrono::microseconds(100)); // 微秒级的睡眠 } } 3.</description></item><item><title>高频交易系统优化：从数据读取到系统平衡的思考过程</title><link>https://code-agree.github.io/blog/2025-06-24-datareader_design_patterns/</link><pubDate>Wed, 25 Sep 2024 01:04:59 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-datareader_design_patterns/</guid><description>1. 初始问题：数据读取效率 #最初，我们关注的是市场数据读取器本身的效率问题。
1.1 轮询方式（初始状态） #void MarketDataReader::readingLoop() { while (running) { for (const auto&amp;amp; symbol : symbols_) { processSymbol(symbol); } std::this_thread::sleep_for(std::chrono::milliseconds(100)); } } 问题：持续轮询即使在没有新数据时也会消耗资源。
1.2 条件控制方式 #void MarketDataReader::readingLoop() { while (running) { std::unique_lock&amp;lt;std::mutex&amp;gt; lock(conditionMutex); dataCondition.wait(lock, [this] { return !running || !symbols_.empty(); }); for (const auto&amp;amp; symbol : symbols_) { processSymbol(symbol); } } } 改进：减少了不必要的CPU使用，但可能会在高频数据更新时引入延迟。
思考转变：这个阶段，我们主要关注如何提高单个组件（数据读取器）的效率。
2. 扩展考虑：数据读取对其他系统组件的影响 #随着对系统的深入思考，我们开始考虑数据读取器的行为如何影响整个系统，特别是订单流的执行效率。
2.1 资源竞争问题 #观察：尽管我们优化了数据读取器的效率，但数据读取线程占据太多的计算资源，也会进而影响订单处理的性能。即使在没有新数据可读时，频繁的检查也会占用宝贵的计算资源。
思考：
数据读取和订单处理是否在竞争同样的系统资源（CPU、内存、I/O）？ 如何在保证数据及时性的同时，不影响订单处理的响应速度？ 如何协调各个线程，使系统达到最低的时延？ 2.2 自适应间隔机制 #引入动态调整处理间隔的机制，以平衡数据读取和系统资源使用。
void MarketDataReader::readingLoop() { while (running) { auto start = std::chrono::steady_clock::now(); for (const auto&amp;amp; symbol : symbols_) { processSymbol(symbol); } auto end = std::chrono::steady_clock::now(); auto duration = std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(end - start); if (duration &amp;lt; currentInterval) { std::this_thread::sleep_for(currentInterval - duration); } adjustInterval(); } } 思考转变：从单纯的效率优化转向了资源使用的平衡，考虑到了系统的整体性能。</description></item><item><title>实现高性能低延迟的交易系统设计</title><link>https://code-agree.github.io/blog/2025-06-24-high_performance_computing_principles/</link><pubDate>Fri, 20 Sep 2024 22:32:08 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-high_performance_computing_principles/</guid><description>高性能低延迟交易系统设计：技术分享 update #在高频交易和实时金融系统中，性能和延迟是关键因素。本文将分享一些设计和实现高性能低延迟交易系统的关键技术和策略。
1. 数据结构优化 #1.1 内存映射（Memory-Mapped）文件 #使用内存映射文件可以显著提高I/O性能，减少系统调用，并允许快速的进程间通信。
class MmapOrderBook { // 使用内存映射文件存储订单簿数据 }; 1.2 自定义内存池 #实现自定义内存池可以减少内存分配和释放的开销，提高内存使用效率。
template&amp;lt;typename T, size_t MaxSize&amp;gt; class MemoryPool { // 实现高效的内存分配和回收 }; 2. 并发控制 #2.1 细粒度锁 #使用细粒度锁可以减少锁竞争，提高并发性能。
std::array&amp;lt;std::shared_mutex, MAX_POSITIONS&amp;gt; m_positionMutexes; 2.2 无锁数据结构 #在关键路径上使用无锁数据结构可以进一步减少同步开销。
std::atomic&amp;lt;double&amp;gt; quantity; std::atomic&amp;lt;double&amp;gt; averagePrice; 3. 高效的更新策略 #3.1 增量更新 vs 全量更新 #根据具体场景选择合适的更新策略。增量更新适合频繁的小幅度变化，全量更新适合大幅度变化或定期同步。
void updatePosition(const char* instId, AssetType type, PositionSide side, double quantityDelta, double price); void syncPositionWithExchange(const char* instId, AssetType type, PositionSide side, double quantity, double price); 3.</description></item><item><title>高频交易系统中的高层锁定：必要性与实现</title><link>https://code-agree.github.io/blog/2025-06-24-mutex_performance_analysis/</link><pubDate>Wed, 18 Sep 2024 17:29:59 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-mutex_performance_analysis/</guid><description>在高频交易系统的开发中，我们经常面临着性能和正确性之间的权衡。最近，我们在优化订单处理流程时，发现了一个有趣的问题：是否需要在高层组件中实现锁定？本文将深入探讨这个问题，分析其必要性，并展示优化前后的实现。
背景 我们的系统主要由以下组件构成：
MmapOrderBook：核心数据存储，使用内存映射文件实现 PositionManager：负责仓位管理 OrderValidator：负责订单验证 OrderManager：负责订单处理流程 最初，我们的实现如下：
// OrderManager.cpp bool OrderManager::processOrder(const MmapOrderBook::Order&amp;amp; order) { if (!orderValidator_-&amp;gt;validateOrder(order)) { return false; } if (orderBook_-&amp;gt;addOrder(order)) { auto position = positionManager_-&amp;gt;getPosition(order.accountId, /* instrumentId */); if (position) { position-&amp;gt;quantity += order.isBuy ? order.quantity : -order.quantity; positionManager_-&amp;gt;updatePosition(*position); } // 发布订单已处理事件 return true; } return false; } 问题分析 虽然 MmapOrderBook 内部使用了分片锁来保证单个操作的线程安全，但我们发现这种方法在处理复合操作时可能存在问题。主要原因如下：
a) 复合操作的原子性： processOrder 方法包含多个相关操作（验证、添加、更新仓位），这些操作需要作为一个原子单元执行。
b) 避免竞态条件： 在验证订单和添加订单之间，系统状态可能发生变化，导致基于过时信息做出决策。
c) 保持不变量： 某些业务逻辑依赖于多个相关数据的一致状态，需要在整个操作过程中维护这些不变量。
d) 简化并发模型： 高层锁定可以简化并发模型，使代码更易于理解和维护。
e) 防止死锁： 复杂操作中可能需要获取多个低层锁，增加死锁风险。高层锁可以降低这种风险。</description></item><item><title>高频交易系统优化：从WebSocket到市场数据处理的全面解析</title><link>https://code-agree.github.io/blog/2025-06-24-advanced_queue_usage_patterns/</link><pubDate>Sun, 15 Sep 2024 04:03:51 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-advanced_queue_usage_patterns/</guid><description>高频交易系统优化：从WebSocket到市场数据处理的全面解析 #在当今竞争激烈的金融市场中,高频交易(HFT)系统的性能直接关系到交易策略的成功与否。本文将深入探讨高频交易系统中两个关键环节的优化：WebSocket消息接收机制和市场数据处理。我们将分析当前最佳实践,探讨潜在的优化方向,并提供具体的代码示例。
1. WebSocket消息接收机制优化 #在高频交易系统中,每一毫秒的延迟都可能导致巨大的经济损失。因此,优化WebSocket消息的接收机制对于系统的整体性能至关重要。
1.1 WebSocketClient类设计与实现 #以下是一个高效的WebSocketClient类的实现示例：
class WebSocketClient { public: using MessageHandler = std::function&amp;lt;void(const char*, size_t)&amp;gt;; WebSocketClient(/* 构造函数参数 */) : ws_(nullptr), running_(false) {} void receiveMessages(MessageHandler handler) { if (!ws_) { throw std::runtime_error(&amp;#34;WebSocket is not connected&amp;#34;); } constexpr size_t BUFFER_SIZE = 1024 * 1024; // 1MB buffer std::array&amp;lt;char, BUFFER_SIZE&amp;gt; buffer; int flags; while (running_) { try { int n = ws_-&amp;gt;receiveFrame(buffer.data(), buffer.size(), flags); if (n &amp;gt; 0) { handler(buffer.data(), n); } else if (n == 0) { // 连接关闭 break; } } catch (const Poco::Exception&amp;amp; e) { // 仅在关键错误时记录日志 // 考虑添加重连逻辑 } } } void start() { running_ = true; } void stop() { running_ = false; } private: std::unique_ptr&amp;lt;Poco::Net::WebSocket&amp;gt; ws_; std::atomic&amp;lt;bool&amp;gt; running_; }; 1.</description></item><item><title>高频交易系统中市场数据处理：队列的利弊分析</title><link>https://code-agree.github.io/blog/2025-06-24-queue_usage_patterns/</link><pubDate>Sun, 15 Sep 2024 03:57:13 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-queue_usage_patterns/</guid><description>高频交易系统中市场数据处理：队列的利弊分析 #在高频交易（HFT）系统中，处理市场数据的方式直接影响着系统的性能和延迟。使用队列是一种常见的数据处理方法，但在追求极低延迟的HFT系统中，这种选择是否合适需要仔细考虑。本文将分析使用队列的利弊，并探讨可能的替代方案。
1. 使用队列的优势 # 解耦和缓冲：队列可以有效地解耦数据生产者（如市场数据源）和消费者（如策略引擎），提供一个缓冲区来处理突发的数据流。
负载均衡：在多线程处理中，队列可以帮助分配工作负载，防止某个处理单元过载。
简化设计：队列提供了一个直观的数据流模型，可以简化系统的整体设计。
容错性：队列可以帮助系统更好地处理暂时的处理速度不匹配，增强系统的稳定性。
2. 使用队列的劣势 # 额外延迟：队列操作（入队和出队）会引入额外的延迟，即使是几微秒的延迟在HFT中也可能造成显著影响。
内存开销：队列需要额外的内存分配，这可能导致缓存未命中，进一步增加延迟。
上下文切换：在多线程环境中，队列操作可能导致频繁的上下文切换，增加系统开销。
顺序处理限制：队列通常按FIFO顺序处理数据，这可能不适合需要优先处理某些关键数据的场景。
潜在的锁竞争：在高并发情况下，队列可能成为竞争热点，导致性能下降。
3. 替代方案 #考虑到队列可能引入的延迟，以下是一些可能的替代方案：
3.1 无锁环形缓冲区（Lock-free Ring Buffer） #template&amp;lt;typename T, size_t Size&amp;gt; class LockFreeRingBuffer { private: std::array&amp;lt;T, Size&amp;gt; buffer_; std::atomic&amp;lt;size_t&amp;gt; head_{0}; std::atomic&amp;lt;size_t&amp;gt; tail_{0}; public: bool push(const T&amp;amp; item) { size_t current_tail = tail_.load(std::memory_order_relaxed); size_t next_tail = (current_tail + 1) % Size; if (next_tail == head_.load(std::memory_order_acquire)) return false; // Buffer is full buffer_[current_tail] = item; tail_.</description></item><item><title>Segmentation Fault Caused by std::string in Memory-Mapped File</title><link>https://code-agree.github.io/blog/2025-06-24-string_memory_mapping_techniques/</link><pubDate>Thu, 12 Sep 2024 15:23:23 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-string_memory_mapping_techniques/</guid><description>故障复盘报告：内存映射文件中的 std::string 导致的段错误 #1. 问题描述 #在使用内存映射文件存储订单数据的过程中，程序在重启后出现段错误。具体表现为在尝试访问存储在内存映射文件中的 Order 结构体的 id 字段时，程序崩溃。
2. 错误信息 #程序崩溃时的 GDB 调试信息如下：
Thread 2 &amp;#34;strategyandtrad&amp;#34; received signal SIGSEGV, Segmentation fault. [Switching to Thread 0x7ffff6f4c6c0 (LWP 446582)] __memcmp_sse2 () at ../sysdeps/x86_64/multiarch/memcmp-sse2.S:258 258 ../sysdeps/x86_64/multiarch/memcmp-sse2.S: No such file or directory. (gdb) bt #0 __memcmp_sse2 () at ../sysdeps/x86_64/multiarch/memcmp-sse2.S:258 #1 0x000055555556d79b in std::char_traits&amp;lt;char&amp;gt;::compare (__s1=0x7f4710000eb0 &amp;lt;error: Cannot access memory at address 0x7f4710000eb0&amp;gt;, __s2=0x7fffe8000c80 &amp;#34;ORD-1726124231791862593&amp;#34;, __n=23) at /usr/include/c++/12/bits/char_traits.h:385 #2 0x000055555559c599 in std::operator==&amp;lt;char&amp;gt; (__lhs=&amp;lt;error: Cannot access memory at address 0x7f4710000eb0&amp;gt;, __rhs=&amp;#34;ORD-1726124231791862593&amp;#34;) at /usr/include/c++/12/bits/basic_string.</description></item><item><title>Analysis of Configuration Management in High-Frequency Trading System</title><link>https://code-agree.github.io/blog/2025-06-24-config_management_in_hft_systems/</link><pubDate>Fri, 06 Sep 2024 01:47:52 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-config_management_in_hft_systems/</guid><description>高频交易系统配置管理方案分析 #当前方案概述 # graph TB CommonLib[&amp;#34;Common Library (MMAP)&amp;#34;] Exchange[&amp;#34;Exchange&amp;#34;] subgraph StrategyAndTrading[&amp;#34;StrategyAndTrading Component&amp;#34;] MDR[&amp;#34;MarketDataReader&amp;#34;] MDN[&amp;#34;MarketDataNormalizer&amp;#34;] SM[&amp;#34;StrategyManager&amp;#34;] subgraph Strategies[&amp;#34;Strategies&amp;#34;] S1[&amp;#34;Strategy 1&amp;#34;] S2[&amp;#34;Strategy 2&amp;#34;] SN[&amp;#34;Strategy N&amp;#34;] end OG[&amp;#34;OrderGenerator&amp;#34;] OV[&amp;#34;OrderValidator&amp;#34;] RP[&amp;#34;RiskProfiler&amp;#34;] RE[&amp;#34;RiskEvaluator&amp;#34;] OM[&amp;#34;OrderManager&amp;#34;] OE[&amp;#34;OrderExecutor&amp;#34;] OMO[&amp;#34;OrderMonitor&amp;#34;] PM[&amp;#34;PositionManager&amp;#34;] end CommonLib --&amp;gt;|1. Read MMAP| MDR MDR --&amp;gt;|2. Raw Market Data| MDN MDN --&amp;gt;|3. Normalized Data| SM SM --&amp;gt;|4. Distribute Data| Strategies Strategies --&amp;gt;|5. Generate Signals| OG OG --&amp;gt;|6. Create Orders| OV OV --&amp;gt;|7. Validated Orders| RP RP --&amp;gt;|8.</description></item><item><title>How to publish new blog</title><link>https://code-agree.github.io/blog/2025-06-24-how_to_publish_new_blog/</link><pubDate>Mon, 02 Sep 2024 12:36:27 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-how_to_publish_new_blog/</guid><description>workflow #目前已经实现GitHub Action，自动编译静态文件, Push到GitHub Page。
具体流程 # 在仓库 git@github.com:code-agree/MyBlogWebsiteRepo.git MyBlogWebsiteRepo/WebsiteRepo 使用 hugo命令 hugo new content ./content/blog/How_to_publish_new_blog.md 新增blog 将当前仓库的变更push到远端 由配置的GitHub action 自动触发 构建静态文件-&amp;gt;push到GitHub Page仓库 成功发布</description></item><item><title>Lock Free Queue Application</title><link>https://code-agree.github.io/blog/2025-06-24-lockfree_programming_techniques/</link><pubDate>Mon, 02 Sep 2024 02:10:33 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-lockfree_programming_techniques/</guid><description>标题：解决高频交易系统中的死锁：从传统 EventBus 到无锁队列的优化之旅 # 引言 在高频交易系统中，每一毫秒都至关重要。最近在系统中遇到了一个令人头疼的死锁问题，这不仅影响了系统的性能，还危及了其稳定性。本文将详细讲述如何发现、分析并最终解决这个问题，以及从中学到的宝贵经验。
问题发现 在一次例行的系统监控中，注意到系统偶尔会出现短暂的停顿。通过日志分析，发现 MarketDataReader 的 readingLoop() 函数只执行了一次就停止了。这引起了的警觉。
问题分析 首先查看了 MarketDataReader 的日志：
[2024-09-01 13:02:08.472] [main_logger] [MarketDataReader.cpp:38] [info] [thread 4048966] [start] Starting market data reader... [2024-09-01 13:02:08.472] [main_logger] [MarketDataReader.cpp:40] [info] [thread 4048966] [start] Starting start,and running_ = true [2024-09-01 13:02:08.489] [main_logger] [MarketDataReader.cpp:63] [info] [thread 4048967] [readingLoop] Starting reading loop...,and running_ = true [2024-09-01 13:02:08.490] [main_logger] [MarketDataReader.cpp:65] [info] [thread 4048967] [readingLoop] Reading loop... [2024-09-01 13:02:08.490] [main_logger] [MarketDataReader.cpp:83] [info] [thread 4048967] [processSymbol] Processing symbol: BTC-USDT [2024-09-01 13:02:08.</description></item><item><title>First Post</title><link>https://code-agree.github.io/blog/two/</link><pubDate>Sun, 04 Aug 2024 00:13:28 +0800</pubDate><guid>https://code-agree.github.io/blog/two/</guid><description>Const #Owner: More_surface Ted Created time: July 25, 2024 4:59 PM
const 可以用来修饰变量、函数、指针等。
修饰变量 当修饰变量时，意味着该变量为只读变量，即不能被修改。
例如
const int a = 10; a = 20; //编译报错，a为只读，不可修改 但是可以通过一些指针类型转换操作const_cast ，修改这个变量。
例如
int main(){ const int a = 10; const int* p = &amp;amp;a; // p是指向const int类型的对象 int* q = const_cast&amp;lt;int*&amp;gt;(p); // 类型转换，将p转换成指向int型对象的指针 *q = 20; // 通过指针操作修改 const a的值 std::cout &amp;lt;&amp;lt; a &amp;lt;&amp;lt; std::ends; // 输出结果 仍然是10 return 0; } 输出结果不变，归功于编译器醉做了优化，编译时把代码替换为了如下所示。
std::cout &amp;lt;&amp;lt; &amp;quot;a = &amp;quot; &amp;lt;&amp;lt; 10 &amp;lt;&amp;lt; std::endl;</description></item><item><title>two First Post</title><link>https://code-agree.github.io/blog/2025-06-24-getting_started_guide/</link><pubDate>Sat, 03 Aug 2024 00:13:28 +0800</pubDate><guid>https://code-agree.github.io/blog/2025-06-24-getting_started_guide/</guid><description>This is my first blog post
int main(){ B b; return 0; } Badge # 新文章！ 短页码 # 警告！ 这个操作是破坏性的！ 别忘了在Twitter上关注我。 Button #button 输出一个样式化的按钮组件，用于突出显示主要操作。它有三个可选参数：
参数	描述 href	按钮应链接到的 URL。 target	链接的目标。 download	浏览器是否应下载资源而不是导航到 URL。此参数的值将是下载文件的名称。 示例:
Call to action 差分数组的主要适用场景是频繁对原始数组的某个区间的元素进行增减
比如说，我给你输入一个数组 nums，然后又要求给区间 nums[2..6] 全部加 1，再给 nums[3..9] 全部减 3，再给 nums[0..4] 全部加 2，再给&amp;hellip;
差分数组
diff[i] = nums[i] - nums[i - 1]; 构造差分数组
vector&amp;lt;int&amp;gt;diff(nums.size()); diff[0] = nums[0]; for (int i = 1; i &amp;lt; nums.</description></item><item><title>My First Post</title><link>https://code-agree.github.io/blog/firstpost/</link><pubDate>Sat, 03 Aug 2024 00:11:28 +0800</pubDate><guid>https://code-agree.github.io/blog/firstpost/</guid><description>这是我的第一篇blog，希望能分享更多的技术，生活、兴趣在这个Blog上。欢迎大家查看评论。
Welcome to my inaugural blog post! I&amp;rsquo;m excited to share more about technology, life experiences, and personal interests through this platform. Feel free to check out the comments section and join the conversation!</description></item></channel></rss>